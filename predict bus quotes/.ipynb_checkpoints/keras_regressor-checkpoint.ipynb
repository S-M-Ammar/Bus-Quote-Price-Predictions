{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import backend as k\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "      <th>Number of MiniBus</th>\n",
       "      <th>Number of Large MiniBus</th>\n",
       "      <th>Number of Small Coach</th>\n",
       "      <th>Number of Medium Coach</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "      <th>Extra Large Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>431.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>517.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>889.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>1518.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>490.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>530.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>224.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>985.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  \\\n",
       "0                     21                       0.35   \n",
       "1                     36                       5.37   \n",
       "2                     84                       7.45   \n",
       "3                     25                       7.72   \n",
       "4                     26                       3.18   \n",
       "..                   ...                        ...   \n",
       "448                   23                       7.43   \n",
       "449                   28                       2.98   \n",
       "450                   28                       2.98   \n",
       "451                  103                       9.85   \n",
       "452                  143                      12.18   \n",
       "\n",
       "     Supplier Quote(including GST)  Number of MiniBus  \\\n",
       "0                           431.25                  0   \n",
       "1                           517.50                  0   \n",
       "2                           889.04                  0   \n",
       "3                          1518.00                  0   \n",
       "4                           490.00                  0   \n",
       "..                             ...                ...   \n",
       "448                         530.00                  0   \n",
       "449                         224.75                  0   \n",
       "450                         500.00                  0   \n",
       "451                         985.00                  0   \n",
       "452                         900.00                  0   \n",
       "\n",
       "     Number of Large MiniBus  Number of Small Coach  Number of Medium Coach  \\\n",
       "0                          0                      1                       0   \n",
       "1                          0                      1                       0   \n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          0                      0                       0   \n",
       "..                       ...                    ...                     ...   \n",
       "448                        0                      1                       0   \n",
       "449                        0                      1                       0   \n",
       "450                        0                      1                       0   \n",
       "451                        0                      0                       0   \n",
       "452                        0                      0                       0   \n",
       "\n",
       "     Number of Large Coach  Extra Large Coach  \n",
       "0                        0                  0  \n",
       "1                        0                  0  \n",
       "2                        0                  0  \n",
       "3                        0                  1  \n",
       "4                        0                  1  \n",
       "..                     ...                ...  \n",
       "448                      0                  0  \n",
       "449                      0                  0  \n",
       "450                      0                  0  \n",
       "451                      1                  0  \n",
       "452                      0                  1  \n",
       "\n",
       "[453 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv(\"./final_dataset.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(labels=['Supplier Quote(including GST)','Number of MiniBus','Number of Medium Coach','Number of Large MiniBus','Number of Small Coach','Extra Large Coach'],axis=1)\n",
    "target = df[['Supplier Quote(including GST)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  Number of Large Coach  \n",
       "0                     21                       0.35                      0  \n",
       "1                     36                       5.37                      0  \n",
       "2                     84                       7.45                      0  \n",
       "3                     25                       7.72                      0  \n",
       "4                     26                       3.18                      0  \n",
       "..                   ...                        ...                    ...  \n",
       "448                   23                       7.43                      0  \n",
       "449                   28                       2.98                      0  \n",
       "450                   28                       2.98                      0  \n",
       "451                  103                       9.85                      1  \n",
       "452                  143                      12.18                      0  \n",
       "\n",
       "[453 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>889.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1518.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>530.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>224.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>985.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>900.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Supplier Quote(including GST)\n",
       "0                           431.25\n",
       "1                           517.50\n",
       "2                           889.04\n",
       "3                          1518.00\n",
       "4                           490.00\n",
       "..                             ...\n",
       "448                         530.00\n",
       "449                         224.75\n",
       "450                         500.00\n",
       "451                         985.00\n",
       "452                         900.00\n",
       "\n",
       "[453 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.reshape(target, (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               2000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 40,271\n",
      "Trainable params: 40,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2541782.0000 - mae: 1091.2938 - val_loss: 3607072.2500 - val_mae: 1270.7083\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2529665.0000 - mae: 1088.6818 - val_loss: 3586549.7500 - val_mae: 1266.9628\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2520126.0000 - mae: 1086.6740 - val_loss: 3569929.7500 - val_mae: 1263.8679\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2512241.2500 - mae: 1084.9930 - val_loss: 3556927.7500 - val_mae: 1261.3046\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2505915.5000 - mae: 1083.5176 - val_loss: 3544214.2500 - val_mae: 1258.5861\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2500407.7500 - mae: 1082.1270 - val_loss: 3525912.0000 - val_mae: 1254.8822\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2492491.2500 - mae: 1080.3103 - val_loss: 3503681.0000 - val_mae: 1250.3009\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2482511.0000 - mae: 1078.0205 - val_loss: 3479217.0000 - val_mae: 1245.1384\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2470824.2500 - mae: 1075.3414 - val_loss: 3453748.5000 - val_mae: 1239.6228\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2458240.2500 - mae: 1072.4053 - val_loss: 3425931.2500 - val_mae: 1233.3925\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2444126.2500 - mae: 1069.0728 - val_loss: 3396408.0000 - val_mae: 1226.4877\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2428669.7500 - mae: 1065.3583 - val_loss: 3363423.0000 - val_mae: 1218.6090\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2410607.5000 - mae: 1061.0305 - val_loss: 3326620.2500 - val_mae: 1209.5072\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2389720.7500 - mae: 1056.0242 - val_loss: 3286710.7500 - val_mae: 1199.2761\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2366149.2500 - mae: 1050.3402 - val_loss: 3242848.2500 - val_mae: 1188.1667\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2338999.7500 - mae: 1043.7687 - val_loss: 3195107.2500 - val_mae: 1182.2192\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2308004.7500 - mae: 1036.1924 - val_loss: 3143795.2500 - val_mae: 1175.3097\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2272629.7500 - mae: 1027.4335 - val_loss: 3087555.5000 - val_mae: 1166.9159\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2231539.5000 - mae: 1017.2486 - val_loss: 3023930.7500 - val_mae: 1156.4355\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2182352.7500 - mae: 1005.7186 - val_loss: 2956044.2500 - val_mae: 1143.8881\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2125690.7500 - mae: 992.3686 - val_loss: 2885030.5000 - val_mae: 1129.0844\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2060473.7500 - mae: 976.7236 - val_loss: 2813623.7500 - val_mae: 1111.6282\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1986844.5000 - mae: 958.5839 - val_loss: 2745086.7500 - val_mae: 1091.2764\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1904422.5000 - mae: 937.5773 - val_loss: 2682030.5000 - val_mae: 1067.2643\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1811864.7500 - mae: 913.1066 - val_loss: 2626991.0000 - val_mae: 1039.6222\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1707761.3750 - mae: 884.4492 - val_loss: 2590285.0000 - val_mae: 1007.4302\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1593211.8750 - mae: 851.1949 - val_loss: 2584947.2500 - val_mae: 969.8230\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1468284.2500 - mae: 812.5959 - val_loss: 2629795.7500 - val_mae: 930.5099\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1334653.2500 - mae: 767.9621 - val_loss: 2745814.0000 - val_mae: 886.2514\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1195264.8750 - mae: 716.6208 - val_loss: 2952613.0000 - val_mae: 836.3256\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1054146.1250 - mae: 659.1192 - val_loss: 3267982.5000 - val_mae: 781.9882\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 916936.2500 - mae: 600.3199 - val_loss: 3704522.2500 - val_mae: 723.8277\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 791563.3125 - mae: 538.6613 - val_loss: 4252549.0000 - val_mae: 670.7188\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 688534.6250 - mae: 480.8680 - val_loss: 4898283.5000 - val_mae: 635.2995\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 620242.3125 - mae: 433.1678 - val_loss: 5605656.5000 - val_mae: 647.3952\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 597880.1875 - mae: 413.2180 - val_loss: 6272744.0000 - val_mae: 676.8338\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 624383.9375 - mae: 418.5098 - val_loss: 6718082.0000 - val_mae: 724.1773\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 682462.4375 - mae: 436.0053 - val_loss: 6779734.0000 - val_mae: 757.6423\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 736244.3750 - mae: 452.6183 - val_loss: 6419051.0000 - val_mae: 763.0047\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 755408.3750 - mae: 459.3653 - val_loss: 5744406.5000 - val_mae: 741.5773\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 733887.6250 - mae: 453.5647 - val_loss: 4904714.5000 - val_mae: 700.4324\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 684201.1250 - mae: 438.8756 - val_loss: 4033338.7500 - val_mae: 647.6578\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 624628.6875 - mae: 420.4748 - val_loss: 3239889.5000 - val_mae: 591.8892\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 570251.9375 - mae: 401.8136 - val_loss: 2567715.7500 - val_mae: 546.8666\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 529845.3750 - mae: 387.5524 - val_loss: 2033741.8750 - val_mae: 513.8785\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 505743.4375 - mae: 378.7541 - val_loss: 1633210.0000 - val_mae: 487.7301\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 495860.8125 - mae: 373.4789 - val_loss: 1357844.0000 - val_mae: 466.5460\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 495810.3438 - mae: 374.7569 - val_loss: 1163939.7500 - val_mae: 453.1814\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 500542.0625 - mae: 377.3918 - val_loss: 1023286.5000 - val_mae: 444.2968\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 505859.2188 - mae: 380.5664 - val_loss: 914640.2500 - val_mae: 438.3873\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 508751.2812 - mae: 381.9180 - val_loss: 828123.1875 - val_mae: 432.4912\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 507685.5312 - mae: 380.5224 - val_loss: 757948.0625 - val_mae: 424.6572\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 502239.0625 - mae: 376.5250 - val_loss: 698459.9375 - val_mae: 414.9502\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 492886.4375 - mae: 370.3485 - val_loss: 645944.9375 - val_mae: 404.7083\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 480605.1562 - mae: 362.3719 - val_loss: 599835.3125 - val_mae: 395.8352\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 466914.7812 - mae: 353.3022 - val_loss: 559909.1250 - val_mae: 388.0749\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 453408.7500 - mae: 345.2770 - val_loss: 526279.4375 - val_mae: 383.4973\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 441720.0000 - mae: 338.4428 - val_loss: 499758.3750 - val_mae: 382.2319\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 433218.4375 - mae: 334.0553 - val_loss: 480386.1875 - val_mae: 382.6627\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 428484.7812 - mae: 332.1186 - val_loss: 466781.6250 - val_mae: 384.2602\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 427116.7812 - mae: 332.9601 - val_loss: 456444.9688 - val_mae: 387.6225\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 427829.8750 - mae: 334.5686 - val_loss: 446775.1250 - val_mae: 391.5428\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 428726.1562 - mae: 335.7867 - val_loss: 435493.2188 - val_mae: 392.9432\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 428191.7500 - mae: 336.0390 - val_loss: 422020.0312 - val_mae: 391.2963\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 425375.2500 - mae: 334.8819 - val_loss: 407341.0625 - val_mae: 386.9416\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 420409.0625 - mae: 332.2629 - val_loss: 392933.9375 - val_mae: 380.3063\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 414114.5625 - mae: 328.3200 - val_loss: 380790.0312 - val_mae: 372.1093\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 407594.8750 - mae: 323.5782 - val_loss: 373095.6562 - val_mae: 363.8125\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 401844.3438 - mae: 318.7899 - val_loss: 369798.7188 - val_mae: 356.0911\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 397497.2812 - mae: 314.8203 - val_loss: 369797.0938 - val_mae: 349.1537\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 394624.5625 - mae: 312.6411 - val_loss: 371703.5625 - val_mae: 343.3846\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 392828.8125 - mae: 311.0246 - val_loss: 374383.0625 - val_mae: 339.1934\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 391657.5000 - mae: 309.7472 - val_loss: 376597.0938 - val_mae: 336.7021\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 390600.5625 - mae: 308.7281 - val_loss: 377820.4375 - val_mae: 335.8615\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 389255.2500 - mae: 307.9228 - val_loss: 377701.5000 - val_mae: 336.2103\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 387456.1875 - mae: 307.3351 - val_loss: 376462.5938 - val_mae: 337.6514\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 385232.6562 - mae: 306.9843 - val_loss: 374668.7188 - val_mae: 340.2120\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 382777.3750 - mae: 307.0592 - val_loss: 373265.6562 - val_mae: 343.8939\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 380361.6250 - mae: 307.7003 - val_loss: 372803.4375 - val_mae: 348.5663\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 378229.6875 - mae: 308.9907 - val_loss: 373435.9688 - val_mae: 353.3708\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 376586.6562 - mae: 311.0552 - val_loss: 375900.8438 - val_mae: 358.2046\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 375479.6875 - mae: 313.2223 - val_loss: 379805.4375 - val_mae: 363.1179\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 374748.3438 - mae: 315.3380 - val_loss: 384376.5625 - val_mae: 367.3332\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 374242.9062 - mae: 317.1702 - val_loss: 388814.1875 - val_mae: 369.9836\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 373730.6875 - mae: 318.5065 - val_loss: 392293.2812 - val_mae: 370.8766\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 372988.3750 - mae: 319.1210 - val_loss: 394497.3125 - val_mae: 370.1743\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 372032.1250 - mae: 318.9947 - val_loss: 395480.1875 - val_mae: 368.1140\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 371005.9688 - mae: 318.2528 - val_loss: 395485.8750 - val_mae: 365.0524\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 370087.2812 - mae: 317.1310 - val_loss: 394893.2188 - val_mae: 361.5066\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 369412.4688 - mae: 315.8874 - val_loss: 394149.4375 - val_mae: 358.4808\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 369013.3438 - mae: 314.6640 - val_loss: 393474.7188 - val_mae: 355.6965\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 368809.9375 - mae: 313.7862 - val_loss: 392779.2500 - val_mae: 353.5224\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 368815.3438 - mae: 313.0933 - val_loss: 391463.9062 - val_mae: 352.5033\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 368693.5625 - mae: 313.0986 - val_loss: 389872.0312 - val_mae: 352.3692\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 368407.8750 - mae: 313.6368 - val_loss: 388220.5312 - val_mae: 353.0356\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 368057.5625 - mae: 314.4607 - val_loss: 386784.9375 - val_mae: 354.1251\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 367747.8750 - mae: 315.3935 - val_loss: 385076.6562 - val_mae: 355.5792\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 367426.8125 - mae: 316.5786 - val_loss: 383331.5312 - val_mae: 357.8305\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 367231.1250 - mae: 317.8141 - val_loss: 381653.0938 - val_mae: 359.9097\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 367137.1562 - mae: 318.9918 - val_loss: 379945.4375 - val_mae: 361.3568\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 367097.4688 - mae: 319.9534 - val_loss: 378286.1562 - val_mae: 362.0661\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 367053.2500 - mae: 320.6604 - val_loss: 376725.4375 - val_mae: 361.8931\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 366956.5625 - mae: 320.9258 - val_loss: 375172.0312 - val_mae: 360.8515\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 366797.6562 - mae: 320.7713 - val_loss: 373807.0000 - val_mae: 359.1295\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 366596.6250 - mae: 320.2731 - val_loss: 372787.5938 - val_mae: 357.0006\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 366388.0938 - mae: 319.5434 - val_loss: 372121.7500 - val_mae: 354.6644\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 366204.0312 - mae: 318.7023 - val_loss: 371742.9062 - val_mae: 352.4149\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 366051.5312 - mae: 317.9022 - val_loss: 371646.3438 - val_mae: 350.7050\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 365917.9375 - mae: 317.2110 - val_loss: 371256.7812 - val_mae: 349.4189\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 365800.4062 - mae: 316.6848 - val_loss: 370892.1875 - val_mae: 348.6425\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 365660.6250 - mae: 316.3644 - val_loss: 370281.4062 - val_mae: 348.3756\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 365488.7188 - mae: 316.2670 - val_loss: 369472.0312 - val_mae: 348.5567\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 365294.3750 - mae: 316.3856 - val_loss: 368609.2188 - val_mae: 349.0509\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 365104.3438 - mae: 316.6650 - val_loss: 367785.0625 - val_mae: 349.6262\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 364919.0625 - mae: 317.0065 - val_loss: 366996.7500 - val_mae: 350.2351\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 364739.0625 - mae: 317.3191 - val_loss: 366254.1875 - val_mae: 350.5897\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 364571.7500 - mae: 317.5335 - val_loss: 365659.9688 - val_mae: 350.5356\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 364414.3438 - mae: 317.6212 - val_loss: 364297.7188 - val_mae: 350.4606\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 364254.8125 - mae: 317.7995 - val_loss: 362847.0625 - val_mae: 349.8404\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 364100.9375 - mae: 317.7365 - val_loss: 361793.9062 - val_mae: 348.7176\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 363930.3750 - mae: 317.4594 - val_loss: 360926.4688 - val_mae: 347.2471\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 363747.6250 - mae: 317.0219 - val_loss: 360375.2500 - val_mae: 345.5650\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 363557.0938 - mae: 316.4634 - val_loss: 359843.4375 - val_mae: 343.7632\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 363324.3125 - mae: 315.8669 - val_loss: 359224.5938 - val_mae: 341.7541\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 363153.6562 - mae: 315.2146 - val_loss: 358640.0312 - val_mae: 340.7878\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 362965.9375 - mae: 314.9863 - val_loss: 358300.0938 - val_mae: 340.2849\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 362772.2188 - mae: 314.8292 - val_loss: 357856.3750 - val_mae: 339.9662\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 362602.3438 - mae: 314.7356 - val_loss: 357291.1562 - val_mae: 339.9297\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 362405.4688 - mae: 314.7403 - val_loss: 356648.3438 - val_mae: 340.0609\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 362192.1250 - mae: 314.8108 - val_loss: 355860.9062 - val_mae: 340.1255\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 361939.2188 - mae: 314.8789 - val_loss: 354971.5938 - val_mae: 340.0364\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 361733.3125 - mae: 314.92 - 0s 82ms/step - loss: 361733.3125 - mae: 314.9288 - val_loss: 354276.4688 - val_mae: 340.7423\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 361532.7188 - mae: 315.3024 - val_loss: 353572.2500 - val_mae: 340.9127\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 361368.0312 - mae: 315.5235 - val_loss: 353029.2500 - val_mae: 340.2802\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 361160.0312 - mae: 315.4320 - val_loss: 352536.5938 - val_mae: 339.1795\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 360990.2500 - mae: 315.1941 - val_loss: 352226.1250 - val_mae: 338.4522\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 360783.7188 - mae: 315.1369 - val_loss: 352015.6562 - val_mae: 339.1975\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 360574.4062 - mae: 315.1115 - val_loss: 351758.7500 - val_mae: 339.7626\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 360376.5312 - mae: 315.1032 - val_loss: 351521.0938 - val_mae: 339.8143\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 360200.2188 - mae: 314.9509 - val_loss: 351493.4062 - val_mae: 339.5096\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 359975.7500 - mae: 314.7877 - val_loss: 351692.9375 - val_mae: 339.0277\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 359761.3125 - mae: 314.5607 - val_loss: 351688.3750 - val_mae: 338.5044\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 359583.5625 - mae: 314.4726 - val_loss: 351421.3125 - val_mae: 338.2995\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 359350.1875 - mae: 314.5095 - val_loss: 350920.9375 - val_mae: 338.3468\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 359107.1875 - mae: 314.6504 - val_loss: 350202.4375 - val_mae: 338.4803\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 358878.4375 - mae: 314.7735 - val_loss: 350043.6562 - val_mae: 338.9809\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 358629.7500 - mae: 314.9129 - val_loss: 350036.5000 - val_mae: 339.6646\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 358392.3750 - mae: 315.0002 - val_loss: 350183.9375 - val_mae: 340.5217\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 358160.7188 - mae: 314.9906 - val_loss: 350358.1562 - val_mae: 341.2673\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 357914.5938 - mae: 314.9331 - val_loss: 350445.5625 - val_mae: 341.9156\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 357654.3125 - mae: 314.9666 - val_loss: 350835.2500 - val_mae: 342.3796\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 357389.8438 - mae: 314.9351 - val_loss: 350644.7188 - val_mae: 342.0376\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 357168.4062 - mae: 314.7921 - val_loss: 350046.6875 - val_mae: 341.4444\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 356938.8125 - mae: 314.7594 - val_loss: 349520.6562 - val_mae: 340.8338\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 356707.7812 - mae: 314.6749 - val_loss: 349222.0625 - val_mae: 340.4844\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 356462.3125 - mae: 314.5762 - val_loss: 348966.4688 - val_mae: 340.5698\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 356206.8750 - mae: 314.7262 - val_loss: 348926.2188 - val_mae: 340.9898\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 355989.1250 - mae: 314.8901 - val_loss: 349212.8438 - val_mae: 341.8486\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 355758.1562 - mae: 314.9561 - val_loss: 349868.3125 - val_mae: 342.8549\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 355481.0000 - mae: 314.9760 - val_loss: 350654.9062 - val_mae: 343.5279\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 355243.2188 - mae: 314.8642 - val_loss: 350615.2188 - val_mae: 343.3852\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 355041.7812 - mae: 314.7237 - val_loss: 348963.2188 - val_mae: 342.7287\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 354774.6875 - mae: 315.0112 - val_loss: 347320.1250 - val_mae: 341.9844\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 354496.5625 - mae: 315.4915 - val_loss: 346675.9688 - val_mae: 341.7862\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 354259.5938 - mae: 315.7079 - val_loss: 346789.6250 - val_mae: 341.9904\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 353960.5312 - mae: 315.5337 - val_loss: 347281.5000 - val_mae: 342.4214\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 353693.2812 - mae: 315.3087 - val_loss: 347964.3125 - val_mae: 342.9222\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 353463.6562 - mae: 315.0653 - val_loss: 348145.0312 - val_mae: 343.2970\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 353155.6562 - mae: 315.1371 - val_loss: 347482.0312 - val_mae: 343.2288\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 352873.0938 - mae: 315.3354 - val_loss: 346570.7188 - val_mae: 342.8613\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 352650.7188 - mae: 315.4420 - val_loss: 346149.5938 - val_mae: 342.8148\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 352348.7188 - mae: 315.5045 - val_loss: 346948.6875 - val_mae: 343.2710\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 351982.9062 - mae: 315.3177 - val_loss: 347762.2500 - val_mae: 343.3492\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 351658.8125 - mae: 315.0219 - val_loss: 347277.0625 - val_mae: 343.0574\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 351319.8750 - mae: 315.1733 - val_loss: 345696.0938 - val_mae: 342.4838\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 351001.1875 - mae: 315.8074 - val_loss: 345293.1562 - val_mae: 342.5691\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 350748.5312 - mae: 316.2517 - val_loss: 346510.8750 - val_mae: 343.7495\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 350468.0000 - mae: 316.0923 - val_loss: 347679.5312 - val_mae: 345.1047\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 350161.3125 - mae: 315.9582 - val_loss: 346156.1250 - val_mae: 344.8165\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 349896.2188 - mae: 316.0863 - val_loss: 343548.8125 - val_mae: 343.6215\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 349575.6562 - mae: 316.4439 - val_loss: 341693.7500 - val_mae: 342.5229\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 349143.1250 - mae: 316.8141 - val_loss: 341144.7188 - val_mae: 342.1667\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 348739.8750 - mae: 316.7359 - val_loss: 342011.5625 - val_mae: 342.7340\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 348446.3750 - mae: 316.1786 - val_loss: 343938.8438 - val_mae: 343.6195\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 348157.1250 - mae: 315.5130 - val_loss: 343893.9688 - val_mae: 343.7190\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 347736.6250 - mae: 315.4195 - val_loss: 342213.8438 - val_mae: 343.1574\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 347282.9375 - mae: 315.7878 - val_loss: 341750.9375 - val_mae: 342.0208\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 346844.3750 - mae: 315.7144 - val_loss: 341875.7188 - val_mae: 341.2858\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 346517.6875 - mae: 315.2737 - val_loss: 340603.9688 - val_mae: 341.4540\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 346110.0312 - mae: 315.6400 - val_loss: 339108.3125 - val_mae: 342.9285\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 345730.6562 - mae: 316.7147 - val_loss: 339761.2188 - val_mae: 344.9727\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 345447.4062 - mae: 317.2122 - val_loss: 343665.9062 - val_mae: 346.6049\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 345114.7500 - mae: 316.3351 - val_loss: 343230.4688 - val_mae: 345.9686\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 344727.1562 - mae: 316.0793 - val_loss: 339859.1250 - val_mae: 343.7211\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 344348.5312 - mae: 316.4645 - val_loss: 337125.7812 - val_mae: 341.4122\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 343952.5312 - mae: 317.4400 - val_loss: 336912.1562 - val_mae: 342.1154\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 343548.4062 - mae: 317.9159 - val_loss: 339490.6875 - val_mae: 345.3221\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 343103.7812 - mae: 317.4055 - val_loss: 343770.1875 - val_mae: 348.5840\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 342843.9062 - mae: 317.1705 - val_loss: 343768.9375 - val_mae: 350.2374\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 342394.3125 - mae: 318.1891 - val_loss: 339398.0625 - val_mae: 349.6848\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 342028.9375 - mae: 320.0642 - val_loss: 338522.3750 - val_mae: 348.7938\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 341696.9375 - mae: 320.4110 - val_loss: 341177.0625 - val_mae: 348.6978\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 341202.1562 - mae: 318.7713 - val_loss: 342116.0000 - val_mae: 348.4665\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 340830.3125 - mae: 317.4117 - val_loss: 340360.7188 - val_mae: 347.8920\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 340438.2812 - mae: 317.4159 - val_loss: 338322.2500 - val_mae: 347.4989\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 339980.3750 - mae: 318.3976 - val_loss: 337495.1562 - val_mae: 347.7682\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 339740.8438 - mae: 319.4794 - val_loss: 339864.9062 - val_mae: 349.5690\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 339363.6562 - mae: 319.0189 - val_loss: 343541.5312 - val_mae: 351.7769\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 339023.9688 - mae: 318.3209 - val_loss: 344262.8125 - val_mae: 352.9625\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 338605.1562 - mae: 318.3704 - val_loss: 340936.7812 - val_mae: 352.5975\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 338184.1562 - mae: 318.8701 - val_loss: 337271.5312 - val_mae: 351.1839\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 337790.0625 - mae: 319.7150 - val_loss: 336909.7500 - val_mae: 350.3384\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 337358.9375 - mae: 319.9564 - val_loss: 339781.5938 - val_mae: 351.5635\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 336952.4062 - mae: 319.1607 - val_loss: 342256.6250 - val_mae: 353.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 336660.0312 - mae: 318.7775 - val_loss: 343921.6250 - val_mae: 354.2745\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 336363.1562 - mae: 318.7832 - val_loss: 344962.9375 - val_mae: 355.2059\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 335944.2500 - mae: 318.6806 - val_loss: 343321.6562 - val_mae: 355.3431\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 335563.5000 - mae: 319.0814 - val_loss: 341099.8125 - val_mae: 355.1403\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 335055.2500 - mae: 319.4913 - val_loss: 341742.3438 - val_mae: 355.4547\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 334617.9062 - mae: 319.2907 - val_loss: 341603.9375 - val_mae: 355.3499\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 334158.9688 - mae: 319.8928 - val_loss: 339642.0000 - val_mae: 355.9060\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 333863.2500 - mae: 322.0373 - val_loss: 341575.3125 - val_mae: 358.0493\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 333623.0938 - mae: 322.7281 - val_loss: 347983.0000 - val_mae: 360.8001\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 333171.0938 - mae: 321.3633 - val_loss: 348285.7812 - val_mae: 361.4653\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 332764.3750 - mae: 321.1168 - val_loss: 344176.7812 - val_mae: 360.2660\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 332363.8750 - mae: 320.6584 - val_loss: 341549.9062 - val_mae: 358.0480\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 332155.2812 - mae: 319.2352 - val_loss: 337131.3750 - val_mae: 355.2971\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 331738.3750 - mae: 319.3103 - val_loss: 336826.6250 - val_mae: 355.0525\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 331222.3750 - mae: 320.7760 - val_loss: 339155.4688 - val_mae: 358.2165\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 330859.3750 - mae: 322.9622 - val_loss: 349810.2812 - val_mae: 365.2003\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 330445.8438 - mae: 322.6705 - val_loss: 362929.4688 - val_mae: 370.8968\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 330197.5938 - mae: 322.1012 - val_loss: 351189.0312 - val_mae: 369.5543\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 329840.2500 - mae: 323.9972 - val_loss: 341358.7188 - val_mae: 364.0063\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 329442.4062 - mae: 323.7720 - val_loss: 344363.0000 - val_mae: 359.7540\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 329128.4062 - mae: 320.4307 - val_loss: 341528.4062 - val_mae: 358.0865\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 328742.5312 - mae: 320.7154 - val_loss: 336901.6250 - val_mae: 360.4742\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 328562.3750 - mae: 323.8778 - val_loss: 350650.1875 - val_mae: 367.9002\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 328226.3750 - mae: 322.3664 - val_loss: 369978.5000 - val_mae: 374.0983\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 327914.5938 - mae: 321.4536 - val_loss: 359678.3750 - val_mae: 372.4572\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 327527.8750 - mae: 322.9542 - val_loss: 343314.0938 - val_mae: 366.9849\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 327349.0312 - mae: 324.6412 - val_loss: 346402.2500 - val_mae: 364.4718\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 326956.5625 - mae: 322.3548 - val_loss: 345226.8438 - val_mae: 365.1200\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 326628.1875 - mae: 322.9549 - val_loss: 346040.0312 - val_mae: 368.7046\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 326269.5625 - mae: 324.5433 - val_loss: 354991.5938 - val_mae: 373.2506\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 325896.0000 - mae: 324.6778 - val_loss: 368774.4688 - val_mae: 376.4830\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 325682.3125 - mae: 323.3313 - val_loss: 364239.2812 - val_mae: 375.0780\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 325359.3125 - mae: 323.0169 - val_loss: 349053.0938 - val_mae: 370.4911\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 324994.6875 - mae: 323.4926 - val_loss: 343353.5312 - val_mae: 367.1807\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 324689.9375 - mae: 322.9622 - val_loss: 348847.9375 - val_mae: 367.4031\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 324477.4062 - mae: 320.7184 - val_loss: 350559.5938 - val_mae: 369.4524\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 324137.2500 - mae: 321.6082 - val_loss: 346512.1875 - val_mae: 372.2148\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 324113.0938 - mae: 325.5714 - val_loss: 366921.3750 - val_mae: 378.8659\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 323548.6875 - mae: 323.7758 - val_loss: 379063.3438 - val_mae: 381.4283\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 323376.0938 - mae: 322.5959 - val_loss: 354273.8125 - val_mae: 377.2797\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 323092.9375 - mae: 326.3276 - val_loss: 347193.8750 - val_mae: 374.0273\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 322759.3750 - mae: 326.2175 - val_loss: 362486.7188 - val_mae: 374.8313\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 322482.9688 - mae: 321.0755 - val_loss: 359860.3438 - val_mae: 374.3253\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 322103.0625 - mae: 321.0963 - val_loss: 350879.0312 - val_mae: 373.4850\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 321964.9688 - mae: 322.9653 - val_loss: 357858.7500 - val_mae: 375.4028\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 321665.0000 - mae: 321.8295 - val_loss: 367017.0625 - val_mae: 377.0180\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 321368.0625 - mae: 320.5412 - val_loss: 358709.8750 - val_mae: 376.2208\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 320981.6875 - mae: 322.4706 - val_loss: 352138.4688 - val_mae: 376.1736\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 320668.7188 - mae: 324.6315 - val_loss: 360746.5625 - val_mae: 379.2265\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 320339.9062 - mae: 323.6748 - val_loss: 369198.6250 - val_mae: 380.9480\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 320103.8125 - mae: 322.3708 - val_loss: 355221.9375 - val_mae: 378.4991\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 319834.0000 - mae: 324.3583 - val_loss: 357707.3438 - val_mae: 377.6630\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 319464.5000 - mae: 322.5575 - val_loss: 359693.7500 - val_mae: 376.6505\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 319247.8125 - mae: 321.0167 - val_loss: 351056.4062 - val_mae: 375.2155\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 319050.3125 - mae: 322.7937 - val_loss: 360736.2188 - val_mae: 377.6383\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 318767.7500 - mae: 320.5657 - val_loss: 362579.1875 - val_mae: 377.5923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 318736.5312 - mae: 319.6370 - val_loss: 346345.7812 - val_mae: 373.6725\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 318305.2812 - mae: 321.8932 - val_loss: 345407.8125 - val_mae: 372.3406\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 317827.5938 - mae: 321.8857 - val_loss: 353587.8750 - val_mae: 374.3573\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 317618.1250 - mae: 320.2245 - val_loss: 351275.3750 - val_mae: 376.8336\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 317288.4062 - mae: 322.9165 - val_loss: 356421.3125 - val_mae: 380.1982\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 317067.0625 - mae: 323.6718 - val_loss: 373644.5625 - val_mae: 383.0827\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 316782.0625 - mae: 320.3143 - val_loss: 358739.8750 - val_mae: 380.3991\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 316480.6562 - mae: 321.8075 - val_loss: 345008.9688 - val_mae: 374.7890\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 316179.2812 - mae: 321.9272 - val_loss: 347316.5625 - val_mae: 371.9276\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 316002.8438 - mae: 318.9746 - val_loss: 339896.9375 - val_mae: 371.1377\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 315546.6875 - mae: 321.7020 - val_loss: 342064.8438 - val_mae: 375.0229\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 315297.3438 - mae: 324.2128 - val_loss: 363131.3125 - val_mae: 382.6838\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 315000.4375 - mae: 322.6172 - val_loss: 374415.4688 - val_mae: 385.9356\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 314723.2188 - mae: 322.1814 - val_loss: 364767.3750 - val_mae: 383.9008\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 314333.5312 - mae: 322.7812 - val_loss: 353783.2812 - val_mae: 379.3423\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 313903.0625 - mae: 321.4967 - val_loss: 345445.8125 - val_mae: 374.3347\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 313609.1562 - mae: 320.2147 - val_loss: 338415.8125 - val_mae: 371.7575\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 313398.1875 - mae: 320.9245 - val_loss: 338539.2188 - val_mae: 373.5335\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 313048.0938 - mae: 321.8732 - val_loss: 356226.2188 - val_mae: 379.7993\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 312571.2812 - mae: 320.4466 - val_loss: 364490.6562 - val_mae: 382.5110\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 312274.7500 - mae: 320.4922 - val_loss: 359640.2500 - val_mae: 382.3032\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 312002.8438 - mae: 321.7734 - val_loss: 357085.0312 - val_mae: 380.2423\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 311708.1875 - mae: 320.5986 - val_loss: 351949.8750 - val_mae: 377.5289\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 311253.4688 - mae: 319.0676 - val_loss: 337631.1562 - val_mae: 373.1353\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 311085.0312 - mae: 320.0970 - val_loss: 339553.7188 - val_mae: 372.3092\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 310850.0000 - mae: 318.8104 - val_loss: 338405.1562 - val_mae: 372.5934\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 310487.3438 - mae: 319.4185 - val_loss: 341565.0625 - val_mae: 374.3077\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 309968.1875 - mae: 319.1672 - val_loss: 344922.0625 - val_mae: 376.6581\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 309645.1562 - mae: 319.7858 - val_loss: 343716.6250 - val_mae: 377.7975\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 309348.5000 - mae: 321.3739 - val_loss: 354153.2500 - val_mae: 378.2161\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 308894.5625 - mae: 318.3636 - val_loss: 343748.0938 - val_mae: 375.4345\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 308639.4062 - mae: 318.8413 - val_loss: 339953.9062 - val_mae: 373.8282\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 308298.8438 - mae: 318.0936 - val_loss: 340057.8750 - val_mae: 372.2677\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 307930.5312 - mae: 316.7941 - val_loss: 329729.3750 - val_mae: 369.6040\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 307559.3125 - mae: 318.2233 - val_loss: 330869.4062 - val_mae: 369.7968\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 307133.8750 - mae: 318.0865 - val_loss: 331607.4688 - val_mae: 370.3243\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 306608.7812 - mae: 318.1671 - val_loss: 343839.0312 - val_mae: 372.9241\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 306438.4062 - mae: 315.9200 - val_loss: 329450.2500 - val_mae: 372.1626\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 306117.1562 - mae: 319.7125 - val_loss: 350414.5625 - val_mae: 373.4915\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 305800.0312 - mae: 314.2296 - val_loss: 313804.0312 - val_mae: 367.9924\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 305564.0312 - mae: 322.6235 - val_loss: 340620.4375 - val_mae: 370.4616\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 304739.7188 - mae: 314.0312 - val_loss: 324554.9375 - val_mae: 368.1590\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 304054.3125 - mae: 317.4332 - val_loss: 326771.0000 - val_mae: 369.3454\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 303644.2500 - mae: 317.2887 - val_loss: 344755.7500 - val_mae: 372.1816\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 303617.7500 - mae: 314.1077 - val_loss: 323053.7188 - val_mae: 369.3158\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 303054.3750 - mae: 318.4100 - val_loss: 326808.9062 - val_mae: 367.1517\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 302478.6875 - mae: 314.9186 - val_loss: 326498.5625 - val_mae: 365.1949\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 301987.2812 - mae: 313.0396 - val_loss: 311603.3750 - val_mae: 361.9214\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 301722.3438 - mae: 316.2841 - val_loss: 331565.3125 - val_mae: 366.6458\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 301311.1875 - mae: 312.4849 - val_loss: 317488.3750 - val_mae: 366.4639\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 300926.6875 - mae: 317.3581 - val_loss: 340581.5938 - val_mae: 369.6812\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 300573.5000 - mae: 312.4518 - val_loss: 309241.9688 - val_mae: 365.3219\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 300920.2812 - mae: 320.1020 - val_loss: 350103.2812 - val_mae: 370.5183\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 301294.1875 - mae: 311.3421 - val_loss: 304540.0625 - val_mae: 363.4883\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 300377.4375 - mae: 320.0023 - val_loss: 332329.2812 - val_mae: 367.3948\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 299456.8438 - mae: 312.8725 - val_loss: 321963.7188 - val_mae: 364.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 299392.6562 - mae: 314.1353 - val_loss: 318927.7812 - val_mae: 364.6802\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 299205.4062 - mae: 314.7858 - val_loss: 332394.6250 - val_mae: 367.6397\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 298842.0312 - mae: 313.0645 - val_loss: 324439.3750 - val_mae: 367.5006\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 298314.3125 - mae: 315.0451 - val_loss: 333472.1250 - val_mae: 368.7654\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 298177.1562 - mae: 313.6056 - val_loss: 324114.1875 - val_mae: 367.3471\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 297561.4062 - mae: 315.2072 - val_loss: 330956.3125 - val_mae: 367.9693\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 297650.1875 - mae: 314.0323 - val_loss: 305538.9375 - val_mae: 362.9138\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 297979.2812 - mae: 320.0458 - val_loss: 354010.1250 - val_mae: 370.9707\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 298754.7500 - mae: 310.9460 - val_loss: 293067.7188 - val_mae: 359.7680\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 299505.9375 - mae: 324.7247 - val_loss: 346588.5625 - val_mae: 368.8669\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 297953.0000 - mae: 311.6343 - val_loss: 327080.2812 - val_mae: 366.5278\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 296427.7188 - mae: 314.4745 - val_loss: 293297.1562 - val_mae: 362.1404\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 298470.3125 - mae: 324.7163 - val_loss: 358351.8125 - val_mae: 371.5674\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 298061.4062 - mae: 311.4777 - val_loss: 316520.5000 - val_mae: 365.9966\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 295678.1250 - mae: 317.2174 - val_loss: 294320.3438 - val_mae: 360.6932\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 296787.4688 - mae: 322.3365 - val_loss: 335904.8438 - val_mae: 366.4971\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 296533.9375 - mae: 311.7371 - val_loss: 314579.7500 - val_mae: 363.3359\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 295255.1875 - mae: 314.6967 - val_loss: 290989.3750 - val_mae: 358.8522\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 296187.1562 - mae: 320.5844 - val_loss: 323107.3438 - val_mae: 364.9814\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 295189.0938 - mae: 313.0637 - val_loss: 322165.8750 - val_mae: 365.6379\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 294786.5938 - mae: 313.7242 - val_loss: 296089.3750 - val_mae: 361.5773\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 295509.2500 - mae: 320.7138 - val_loss: 321768.4062 - val_mae: 366.5107\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 294474.5312 - mae: 314.4637 - val_loss: 329120.3125 - val_mae: 367.7669\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 294508.4688 - mae: 313.2406 - val_loss: 295909.2812 - val_mae: 361.4607\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 294801.9062 - mae: 320.0523 - val_loss: 314932.5625 - val_mae: 364.5372\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 293774.0000 - mae: 314.4982 - val_loss: 325918.1875 - val_mae: 365.2131\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 294206.9062 - mae: 312.0925 - val_loss: 290731.5312 - val_mae: 357.6148\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 294050.7812 - mae: 319.8155 - val_loss: 307861.8438 - val_mae: 362.8964\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 293089.2812 - mae: 315.5868 - val_loss: 332362.4688 - val_mae: 368.0719\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 293671.9688 - mae: 312.7569 - val_loss: 304202.7812 - val_mae: 364.5265\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 293318.3750 - mae: 318.9496 - val_loss: 322657.1562 - val_mae: 367.5399\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 292734.2500 - mae: 314.8188 - val_loss: 328855.8125 - val_mae: 367.4626\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 292797.4062 - mae: 313.2610 - val_loss: 300047.7812 - val_mae: 360.8128\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 292707.4375 - mae: 317.5913 - val_loss: 306925.1562 - val_mae: 361.1420\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 292230.5625 - mae: 314.8316 - val_loss: 316274.4375 - val_mae: 362.9274\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 292198.9375 - mae: 313.1197 - val_loss: 301171.9688 - val_mae: 361.0195\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 292141.0000 - mae: 316.9285 - val_loss: 320378.0312 - val_mae: 366.1576\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 291780.3438 - mae: 314.3613 - val_loss: 326946.0625 - val_mae: 368.1210\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 291556.4062 - mae: 314.3706 - val_loss: 316865.4375 - val_mae: 366.8472\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 291475.3438 - mae: 316.2742 - val_loss: 320703.5938 - val_mae: 365.9354\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 291178.4375 - mae: 314.2890 - val_loss: 317781.0938 - val_mae: 363.6941\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 291097.8125 - mae: 313.4112 - val_loss: 316698.7812 - val_mae: 362.4496\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 291087.5312 - mae: 313.1205 - val_loss: 308490.4375 - val_mae: 360.8012\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 290962.4688 - mae: 314.8964 - val_loss: 320403.7188 - val_mae: 363.6049\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 290544.0000 - mae: 312.6632 - val_loss: 318303.1875 - val_mae: 364.3335\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 290406.1562 - mae: 313.5437 - val_loss: 308829.2812 - val_mae: 363.7294\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 290369.2812 - mae: 315.9775 - val_loss: 323553.5938 - val_mae: 366.2830\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 290171.5312 - mae: 313.1943 - val_loss: 315054.4375 - val_mae: 365.3360\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 290154.2188 - mae: 314.5975 - val_loss: 321133.6562 - val_mae: 365.5726\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 289801.3438 - mae: 313.5531 - val_loss: 321088.9062 - val_mae: 364.3973\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 289679.4062 - mae: 312.9336 - val_loss: 316550.3438 - val_mae: 362.4485\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 289466.6562 - mae: 312.9467 - val_loss: 308903.6875 - val_mae: 361.0704\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 289341.0312 - mae: 314.7757 - val_loss: 318499.7500 - val_mae: 363.0146\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 289218.5625 - mae: 312.6738 - val_loss: 311831.0000 - val_mae: 363.6698\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 288912.4062 - mae: 314.7477 - val_loss: 320091.8750 - val_mae: 366.3077\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 288899.2812 - mae: 313.8562 - val_loss: 330510.4688 - val_mae: 367.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 288748.5938 - mae: 312.8651 - val_loss: 318793.8750 - val_mae: 364.4898\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 288634.1250 - mae: 313.5733 - val_loss: 316639.0000 - val_mae: 361.6132\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 288463.9375 - mae: 312.2112 - val_loss: 305776.6250 - val_mae: 358.3613\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 288340.8438 - mae: 313.7711 - val_loss: 306637.8125 - val_mae: 358.8024\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 288105.8125 - mae: 313.3319 - val_loss: 313876.2188 - val_mae: 361.6552\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 288043.1875 - mae: 312.2410 - val_loss: 324867.5938 - val_mae: 364.8998\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 288071.7188 - mae: 312.1809 - val_loss: 323831.5312 - val_mae: 365.4834\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 287965.4688 - mae: 312.8502 - val_loss: 318021.0000 - val_mae: 364.2562\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 287650.3125 - mae: 312.8117 - val_loss: 314078.7188 - val_mae: 363.2653\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 287447.1250 - mae: 313.4532 - val_loss: 315922.5000 - val_mae: 363.6954\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 287433.7500 - mae: 313.6261 - val_loss: 326399.2812 - val_mae: 365.4802\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 287522.2812 - mae: 312.2800 - val_loss: 313143.9062 - val_mae: 365.4496\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 287524.1875 - mae: 315.3268 - val_loss: 334894.9375 - val_mae: 367.0756\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 287492.4062 - mae: 311.3310 - val_loss: 306830.8750 - val_mae: 363.8284\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 287176.3438 - mae: 315.5670 - val_loss: 327663.3438 - val_mae: 365.0282\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 286739.4062 - mae: 311.2542 - val_loss: 313070.1875 - val_mae: 362.7313\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 286526.1875 - mae: 313.0680 - val_loss: 317030.5938 - val_mae: 362.2559\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 286393.5938 - mae: 311.5334 - val_loss: 325247.4375 - val_mae: 362.3620\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 286410.5938 - mae: 309.9329 - val_loss: 300326.3125 - val_mae: 360.1045\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 286804.1562 - mae: 315.9054 - val_loss: 339618.8125 - val_mae: 364.7392\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 287207.9062 - mae: 309.0061 - val_loss: 303405.6562 - val_mae: 363.0088\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 286740.0000 - mae: 316.4234 - val_loss: 324214.4688 - val_mae: 365.9396\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 285754.4688 - mae: 312.0777 - val_loss: 340384.0000 - val_mae: 368.1434\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 286108.6562 - mae: 310.4013 - val_loss: 298844.5000 - val_mae: 365.6471\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 287841.6875 - mae: 319.4916 - val_loss: 362199.3125 - val_mae: 368.2555\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 288305.4062 - mae: 307.5827 - val_loss: 301645.7188 - val_mae: 361.4386\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 286173.3438 - mae: 315.7917 - val_loss: 306372.7812 - val_mae: 360.8491\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 285313.4688 - mae: 313.3163 - val_loss: 350323.6562 - val_mae: 365.8296\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 287521.0938 - mae: 307.6965 - val_loss: 294752.7188 - val_mae: 363.5827\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 287080.7188 - mae: 319.7864 - val_loss: 335936.8750 - val_mae: 367.8443\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 285088.7188 - mae: 310.7803 - val_loss: 346067.8750 - val_mae: 368.9449\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 285525.8438 - mae: 309.7923 - val_loss: 299800.3438 - val_mae: 364.8007\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 286136.2812 - mae: 318.1465 - val_loss: 323654.6562 - val_mae: 363.5471\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 284449.5938 - mae: 309.7820 - val_loss: 323806.6250 - val_mae: 362.6119\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 284752.1875 - mae: 308.9098 - val_loss: 299842.5625 - val_mae: 361.9074\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 285135.7500 - mae: 315.2857 - val_loss: 327572.0625 - val_mae: 364.4238\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 284128.5312 - mae: 309.4858 - val_loss: 327993.5625 - val_mae: 365.7727\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 283907.6250 - mae: 310.1799 - val_loss: 302531.0000 - val_mae: 364.6052\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 284697.5625 - mae: 315.8476 - val_loss: 334456.3750 - val_mae: 366.6493\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 284303.9062 - mae: 309.6981 - val_loss: 323220.4688 - val_mae: 364.6435\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 283581.6875 - mae: 310.5153 - val_loss: 307966.0000 - val_mae: 363.7121\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 283965.3438 - mae: 313.9550 - val_loss: 327911.0000 - val_mae: 364.4529\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 283569.6875 - mae: 309.1277 - val_loss: 315728.2812 - val_mae: 363.5199\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 283506.7500 - mae: 311.0276 - val_loss: 311670.5312 - val_mae: 364.7246\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 283332.5000 - mae: 312.2121 - val_loss: 339797.8438 - val_mae: 367.1137\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 283463.7812 - mae: 308.5866 - val_loss: 318174.6250 - val_mae: 366.7049\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 283389.5000 - mae: 312.4597 - val_loss: 326390.9375 - val_mae: 365.7859\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 282789.4375 - mae: 310.3069 - val_loss: 325111.9688 - val_mae: 365.0634\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 282666.0312 - mae: 310.2847 - val_loss: 300815.4375 - val_mae: 362.9292\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 283365.6875 - mae: 315.2303 - val_loss: 330405.9688 - val_mae: 366.4760\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 282600.2812 - mae: 309.6079 - val_loss: 331818.5625 - val_mae: 367.3494\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 282506.7500 - mae: 309.7420 - val_loss: 319562.6250 - val_mae: 367.2403\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 283157.4062 - mae: 312.2560 - val_loss: 336050.5000 - val_mae: 364.7235\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 282689.6562 - mae: 307.5776 - val_loss: 309696.6562 - val_mae: 362.2491\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 281817.6875 - mae: 311.4892 - val_loss: 305581.0000 - val_mae: 362.0339\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 282436.9375 - mae: 312.6051 - val_loss: 326263.8750 - val_mae: 366.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 282276.7812 - mae: 309.8040 - val_loss: 326831.0938 - val_mae: 369.7416\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 281567.3438 - mae: 311.1191 - val_loss: 331095.6562 - val_mae: 369.1226\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 281720.9375 - mae: 310.1496 - val_loss: 332340.9375 - val_mae: 365.7776\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 281559.1875 - mae: 308.3786 - val_loss: 304024.1562 - val_mae: 359.7516\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 281396.0625 - mae: 312.0978 - val_loss: 308974.3438 - val_mae: 360.0549\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 281377.2500 - mae: 310.8495 - val_loss: 326793.3125 - val_mae: 366.0538\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 281005.2500 - mae: 309.3582 - val_loss: 320191.7812 - val_mae: 370.5379\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 281262.2188 - mae: 312.7153 - val_loss: 341821.7500 - val_mae: 368.8271\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 281063.9688 - mae: 308.3400 - val_loss: 323219.0625 - val_mae: 367.9619\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 280636.3438 - mae: 310.1526 - val_loss: 320002.8750 - val_mae: 363.9918\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 280388.0312 - mae: 309.0294 - val_loss: 312459.6562 - val_mae: 359.4587\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 280273.1875 - mae: 308.9362 - val_loss: 302850.6250 - val_mae: 359.4376\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 280229.7812 - mae: 310.8762 - val_loss: 332487.1250 - val_mae: 364.9074\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 280569.4688 - mae: 307.4284 - val_loss: 322527.1250 - val_mae: 369.0653\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 280682.3750 - mae: 311.3728 - val_loss: 333207.9062 - val_mae: 368.0633\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 280255.2500 - mae: 308.7808 - val_loss: 327628.1875 - val_mae: 366.6651\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 279858.9062 - mae: 308.9313 - val_loss: 305161.4688 - val_mae: 363.1339\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 280060.5625 - mae: 312.7422 - val_loss: 332208.1562 - val_mae: 364.7453\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 280231.0625 - mae: 307.0177 - val_loss: 310270.0625 - val_mae: 367.1169\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 279837.2500 - mae: 312.4688 - val_loss: 329610.3438 - val_mae: 368.0933\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 279209.6562 - mae: 308.7977 - val_loss: 330629.8438 - val_mae: 368.4308\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 279169.3125 - mae: 308.9879 - val_loss: 320311.9062 - val_mae: 367.5343\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 279069.9375 - mae: 310.0327 - val_loss: 320942.4688 - val_mae: 362.7708\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 278822.7188 - mae: 307.4721 - val_loss: 308280.9688 - val_mae: 359.3967\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 278856.7188 - mae: 308.4360 - val_loss: 315182.9062 - val_mae: 360.3831\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 278558.7500 - mae: 307.2463 - val_loss: 314554.0625 - val_mae: 364.1347\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 278501.0938 - mae: 309.1165 - val_loss: 327414.0312 - val_mae: 364.5024\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 278445.1875 - mae: 307.0270 - val_loss: 316961.9688 - val_mae: 366.6544\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 278473.0312 - mae: 309.6550 - val_loss: 326626.3438 - val_mae: 363.4019\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 278291.7812 - mae: 306.5582 - val_loss: 312996.9375 - val_mae: 363.0051\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 278028.6875 - mae: 308.9232 - val_loss: 315831.0000 - val_mae: 362.9644\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 278000.6562 - mae: 307.9687 - val_loss: 328337.9688 - val_mae: 364.2185\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 277933.6875 - mae: 306.4290 - val_loss: 313964.6250 - val_mae: 369.9072\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 278541.5938 - mae: 312.2768 - val_loss: 346491.0625 - val_mae: 366.8314\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 278892.3438 - mae: 305.6553 - val_loss: 314186.0625 - val_mae: 367.4293\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 278107.9688 - mae: 311.0615 - val_loss: 316847.0625 - val_mae: 362.6625\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 277277.0312 - mae: 307.3957 - val_loss: 323852.4062 - val_mae: 360.7354\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 277751.1875 - mae: 305.2184 - val_loss: 305245.5938 - val_mae: 361.6691\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 277280.3750 - mae: 309.5838 - val_loss: 327877.8750 - val_mae: 363.1736\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 277320.4688 - mae: 305.2101 - val_loss: 324640.3750 - val_mae: 365.3699\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 277224.9688 - mae: 306.8881 - val_loss: 323131.3438 - val_mae: 365.2753\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 276581.9375 - mae: 306.7747 - val_loss: 319768.9375 - val_mae: 364.4919\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 277085.4688 - mae: 307.2888 - val_loss: 314701.3125 - val_mae: 363.5442\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 276907.1562 - mae: 307.3527 - val_loss: 319304.3438 - val_mae: 364.9083\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 276360.1562 - mae: 306.9686 - val_loss: 328561.3750 - val_mae: 364.1852\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 276468.5625 - mae: 305.2317 - val_loss: 320741.5312 - val_mae: 363.1454\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 276144.0625 - mae: 305.9120 - val_loss: 314349.5000 - val_mae: 360.2321\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 275974.4375 - mae: 306.1488 - val_loss: 308029.0625 - val_mae: 358.8729\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 275978.6562 - mae: 307.4918 - val_loss: 312545.2812 - val_mae: 359.3177\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 275885.7500 - mae: 306.1033 - val_loss: 317307.6875 - val_mae: 362.2045\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 275552.7188 - mae: 305.7727 - val_loss: 322253.4688 - val_mae: 365.3305\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 275665.0000 - mae: 306.3434 - val_loss: 329436.0625 - val_mae: 365.0019\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 275511.5000 - mae: 305.0002 - val_loss: 310151.9062 - val_mae: 364.5858\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 275491.4375 - mae: 308.6118 - val_loss: 321770.6250 - val_mae: 361.6975\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 275365.7500 - mae: 304.7473 - val_loss: 313431.5625 - val_mae: 360.7620\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 274882.4688 - mae: 305.7108 - val_loss: 309325.9688 - val_mae: 360.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 275073.7812 - mae: 306.6299 - val_loss: 330871.0625 - val_mae: 359.5847\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 275681.9375 - mae: 303.2051 - val_loss: 294399.5625 - val_mae: 360.9613\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 277108.0312 - mae: 313.7473 - val_loss: 349577.9688 - val_mae: 361.9706\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 277924.8750 - mae: 303.1581 - val_loss: 307045.0000 - val_mae: 363.5257\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 275028.0625 - mae: 309.0311 - val_loss: 310141.3125 - val_mae: 361.3202\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 274493.3438 - mae: 306.3361 - val_loss: 340462.8438 - val_mae: 357.1093\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 276510.1562 - mae: 301.4012 - val_loss: 291301.2188 - val_mae: 359.0816\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 277387.5938 - mae: 314.1370 - val_loss: 341432.0312 - val_mae: 360.2505\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 275809.1562 - mae: 302.4182 - val_loss: 320421.3750 - val_mae: 363.4157\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 273816.5312 - mae: 305.8852 - val_loss: 308438.5625 - val_mae: 367.3459\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 275558.5625 - mae: 312.2223 - val_loss: 354338.1250 - val_mae: 364.5962\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 276086.1562 - mae: 303.5240 - val_loss: 317201.6875 - val_mae: 361.9195\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 273718.6250 - mae: 305.6655 - val_loss: 297935.5000 - val_mae: 360.6230\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 275238.1250 - mae: 311.5780 - val_loss: 349541.2188 - val_mae: 358.2670\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 276282.7188 - mae: 301.2346 - val_loss: 301783.3750 - val_mae: 356.9247\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 273774.0625 - mae: 306.4072 - val_loss: 305333.2188 - val_mae: 357.7542\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 273570.1562 - mae: 305.8430 - val_loss: 351818.2812 - val_mae: 357.0707\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 276193.0312 - mae: 300.1412 - val_loss: 310851.2812 - val_mae: 359.0263\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 273716.5625 - mae: 306.4460 - val_loss: 307777.3750 - val_mae: 359.6258\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 273502.5312 - mae: 307.8237 - val_loss: 346986.4062 - val_mae: 360.9217\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 274882.9062 - mae: 301.8199 - val_loss: 315629.0625 - val_mae: 361.7314\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 272930.3750 - mae: 306.4757 - val_loss: 312449.0312 - val_mae: 363.4367\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 273098.9688 - mae: 308.6841 - val_loss: 350626.6875 - val_mae: 362.0109\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 273859.9062 - mae: 301.9620 - val_loss: 327087.2812 - val_mae: 362.7813\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 272561.5312 - mae: 304.6826 - val_loss: 309234.8438 - val_mae: 362.0080\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 273670.7812 - mae: 308.6658 - val_loss: 349531.4062 - val_mae: 356.6719\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 275221.4688 - mae: 300.6707 - val_loss: 311323.6875 - val_mae: 357.2269\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 271841.2188 - mae: 305.8140 - val_loss: 300225.7812 - val_mae: 360.3871\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 274008.3438 - mae: 311.6102 - val_loss: 360095.0625 - val_mae: 358.4822\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 276330.3438 - mae: 300.1696 - val_loss: 317147.4375 - val_mae: 359.7370\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 271361.8438 - mae: 303.4125 - val_loss: 295672.9375 - val_mae: 363.4913\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 277472.8750 - mae: 315.1389 - val_loss: 382742.3750 - val_mae: 356.4405\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 280190.6562 - mae: 298.4673 - val_loss: 330942.9688 - val_mae: 354.5818\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 271964.7812 - mae: 300.0000 - val_loss: 304243.6562 - val_mae: 377.0310\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 282777.7812 - mae: 324.0864 - val_loss: 368772.7188 - val_mae: 359.2260\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 277170.5312 - mae: 299.8376 - val_loss: 362252.7188 - val_mae: 361.4966\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 275606.0000 - mae: 300.5129 - val_loss: 302273.5312 - val_mae: 373.8837\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 279407.6250 - mae: 321.6308 - val_loss: 320892.2188 - val_mae: 362.4257\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 270943.3750 - mae: 304.3221 - val_loss: 376026.3750 - val_mae: 359.1389\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 277122.8438 - mae: 298.8433 - val_loss: 315706.2500 - val_mae: 357.2610\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 270902.3438 - mae: 302.9706 - val_loss: 298899.0938 - val_mae: 360.2584\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 276001.6875 - mae: 314.2505 - val_loss: 329925.7500 - val_mae: 347.6029\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 272064.9375 - mae: 297.5974 - val_loss: 334931.7188 - val_mae: 346.3674\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 273168.7188 - mae: 296.9422 - val_loss: 301814.8438 - val_mae: 359.3591\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 272346.2188 - mae: 309.2868 - val_loss: 304932.9375 - val_mae: 354.1641\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 271285.1562 - mae: 307.2293 - val_loss: 344365.8438 - val_mae: 355.6010\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 271922.7188 - mae: 298.4281 - val_loss: 337940.5312 - val_mae: 359.0989\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 270159.1875 - mae: 299.8735 - val_loss: 307584.9688 - val_mae: 365.1356\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 272175.6875 - mae: 308.8676 - val_loss: 324127.2500 - val_mae: 359.7101\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 269315.2812 - mae: 301.4846 - val_loss: 340300.9688 - val_mae: 354.8632\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 271303.1875 - mae: 298.3255 - val_loss: 306160.2812 - val_mae: 353.3459\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 269536.4375 - mae: 303.5645 - val_loss: 300019.2188 - val_mae: 354.8010\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 270814.8438 - mae: 307.7122 - val_loss: 324275.9062 - val_mae: 351.3133\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 269756.7812 - mae: 299.0518 - val_loss: 328380.1562 - val_mae: 353.4078\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 269375.3125 - mae: 298.9574 - val_loss: 307324.9375 - val_mae: 358.7938\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 270063.6250 - mae: 305.6163 - val_loss: 317913.5000 - val_mae: 358.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 268853.4062 - mae: 302.1802 - val_loss: 342525.9375 - val_mae: 356.2522\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 270008.3438 - mae: 298.6157 - val_loss: 319484.4062 - val_mae: 357.6504\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 268148.6875 - mae: 302.0899 - val_loss: 308499.1875 - val_mae: 358.1437\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 269236.2500 - mae: 306.8266 - val_loss: 321506.7188 - val_mae: 354.3163\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 268564.5312 - mae: 300.7219 - val_loss: 328605.5938 - val_mae: 354.3427\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 268538.4062 - mae: 299.2542 - val_loss: 309166.4688 - val_mae: 357.2531\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 268163.2812 - mae: 303.7779 - val_loss: 317064.7812 - val_mae: 356.8601\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 267980.7500 - mae: 301.6251 - val_loss: 337655.8438 - val_mae: 355.2385\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 268540.5938 - mae: 298.1026 - val_loss: 320829.0312 - val_mae: 357.5494\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 267523.5938 - mae: 301.2092 - val_loss: 315090.5938 - val_mae: 358.6478\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 267544.7812 - mae: 303.7191 - val_loss: 324068.7500 - val_mae: 355.8946\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 267273.3750 - mae: 300.7129 - val_loss: 321085.6562 - val_mae: 355.2280\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 267371.3438 - mae: 301.1685 - val_loss: 315495.7188 - val_mae: 356.7557\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 267003.1875 - mae: 302.8857 - val_loss: 321104.9688 - val_mae: 356.4939\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 266609.9375 - mae: 300.7728 - val_loss: 332740.1250 - val_mae: 355.8186\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 266863.1250 - mae: 298.4834 - val_loss: 323943.6875 - val_mae: 357.2899\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 266520.0312 - mae: 300.4591 - val_loss: 321922.4375 - val_mae: 358.1126\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 266299.5938 - mae: 301.2845 - val_loss: 329954.2500 - val_mae: 356.4557\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 266261.1875 - mae: 299.2999 - val_loss: 328253.8750 - val_mae: 356.4167\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 265986.3750 - mae: 299.8692 - val_loss: 320185.1875 - val_mae: 357.1150\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 265984.4375 - mae: 302.3742 - val_loss: 324670.0938 - val_mae: 355.9045\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 265700.4375 - mae: 300.6382 - val_loss: 328081.8750 - val_mae: 353.3418\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 265720.1250 - mae: 298.7980 - val_loss: 322605.5312 - val_mae: 352.4779\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 265501.9062 - mae: 300.0036 - val_loss: 321325.9375 - val_mae: 352.1333\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 265356.7188 - mae: 300.3311 - val_loss: 328480.1875 - val_mae: 353.3073\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 265177.7812 - mae: 298.8623 - val_loss: 328042.1250 - val_mae: 359.1424\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 265062.7500 - mae: 301.5135 - val_loss: 336738.6250 - val_mae: 362.0320\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 264921.8438 - mae: 300.7863 - val_loss: 339894.1250 - val_mae: 362.4464\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 264852.6562 - mae: 300.3726 - val_loss: 332195.2188 - val_mae: 362.5757\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 264880.6875 - mae: 302.0392 - val_loss: 339373.2812 - val_mae: 359.0464\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 264564.2188 - mae: 299.0902 - val_loss: 334338.1562 - val_mae: 359.5963\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 264293.9688 - mae: 300.3260 - val_loss: 337332.3750 - val_mae: 358.3462\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 264258.2188 - mae: 299.2380 - val_loss: 329898.1250 - val_mae: 358.2478\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 264330.5625 - mae: 301.0690 - val_loss: 337860.3438 - val_mae: 354.6208\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 264161.4688 - mae: 298.0271 - val_loss: 331131.3438 - val_mae: 355.0612\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 263645.1562 - mae: 300.2160 - val_loss: 331383.4375 - val_mae: 356.1633\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 263712.6562 - mae: 300.9880 - val_loss: 335990.0312 - val_mae: 358.8216\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 263434.1562 - mae: 300.1672 - val_loss: 339910.6250 - val_mae: 362.7164\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 263293.5625 - mae: 300.6357 - val_loss: 344541.5938 - val_mae: 363.1611\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 263267.8125 - mae: 299.7519 - val_loss: 345335.5312 - val_mae: 361.0748\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 263170.4375 - mae: 298.7515 - val_loss: 330206.3438 - val_mae: 361.7027\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 263916.8750 - mae: 302.8970 - val_loss: 343005.0000 - val_mae: 356.1189\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 263371.6875 - mae: 297.3470 - val_loss: 341487.9688 - val_mae: 357.1035\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 263020.3125 - mae: 297.7088 - val_loss: 331607.4375 - val_mae: 361.0099\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 263221.8125 - mae: 301.9733 - val_loss: 346052.4688 - val_mae: 358.1718\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 262700.6562 - mae: 297.8770 - val_loss: 339556.4688 - val_mae: 357.8807\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 262068.8906 - mae: 299.2735 - val_loss: 333752.0312 - val_mae: 355.9444\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 261979.0938 - mae: 300.2691 - val_loss: 341785.2812 - val_mae: 354.3765\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 262144.6875 - mae: 297.5791 - val_loss: 334334.1875 - val_mae: 357.5862\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 261492.8438 - mae: 300.3922 - val_loss: 340511.3750 - val_mae: 358.7746\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 261288.0000 - mae: 299.1562 - val_loss: 341518.1875 - val_mae: 360.8838\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 261250.0938 - mae: 299.6428 - val_loss: 343414.6250 - val_mae: 362.6513\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 260998.1719 - mae: 299.5372 - val_loss: 347661.0000 - val_mae: 362.8423\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 260869.2969 - mae: 298.5159 - val_loss: 342659.2500 - val_mae: 361.4404\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 260729.0625 - mae: 298.6622 - val_loss: 349515.6250 - val_mae: 359.5669\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 261033.1094 - mae: 297.1000 - val_loss: 333743.5625 - val_mae: 361.3441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 261656.9219 - mae: 301.4624 - val_loss: 350714.0625 - val_mae: 359.0928\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 260685.6562 - mae: 296.8423 - val_loss: 342072.2500 - val_mae: 360.0441\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 260053.1562 - mae: 298.8544 - val_loss: 343145.3750 - val_mae: 358.3941\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 260219.6094 - mae: 298.5366 - val_loss: 349823.2188 - val_mae: 355.9109\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 260189.7500 - mae: 296.9774 - val_loss: 336838.5938 - val_mae: 359.7577\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 261085.1562 - mae: 302.3476 - val_loss: 358696.0000 - val_mae: 356.9563\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 260817.0312 - mae: 295.7466 - val_loss: 343501.3750 - val_mae: 362.3744\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 259756.8125 - mae: 299.9565 - val_loss: 353140.6562 - val_mae: 362.3311\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 259349.4375 - mae: 297.7210 - val_loss: 350295.7812 - val_mae: 362.0848\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 259159.8281 - mae: 298.1228 - val_loss: 346468.4375 - val_mae: 360.9041\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 258996.3750 - mae: 298.2609 - val_loss: 352735.4375 - val_mae: 359.0211\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 258935.7812 - mae: 296.1608 - val_loss: 339476.4688 - val_mae: 361.7453\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 259214.7344 - mae: 300.0183 - val_loss: 356068.7188 - val_mae: 356.6886\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 259760.5469 - mae: 295.1566 - val_loss: 337889.6875 - val_mae: 358.9619\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 259279.7188 - mae: 300.4226 - val_loss: 351091.4688 - val_mae: 357.3145\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 258111.7812 - mae: 296.3421 - val_loss: 350608.1250 - val_mae: 360.1729\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 258010.5469 - mae: 297.4093 - val_loss: 355519.0625 - val_mae: 362.1989\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 257870.4531 - mae: 297.1160 - val_loss: 357028.8750 - val_mae: 363.4591\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 257739.4062 - mae: 297.1825 - val_loss: 353682.6250 - val_mae: 360.2351\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 257400.3125 - mae: 296.4568 - val_loss: 341180.1250 - val_mae: 358.5411\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 257631.7812 - mae: 299.1922 - val_loss: 352759.0000 - val_mae: 353.2974\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 257845.2188 - mae: 294.8228 - val_loss: 341533.6250 - val_mae: 355.6223\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 257342.6094 - mae: 298.5175 - val_loss: 352285.5938 - val_mae: 358.6188\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 256776.2656 - mae: 296.2220 - val_loss: 359302.8750 - val_mae: 363.3167\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 256687.3594 - mae: 296.3637 - val_loss: 358708.4688 - val_mae: 368.4379\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 257012.0938 - mae: 298.4168 - val_loss: 374688.0312 - val_mae: 364.6664\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 256982.7656 - mae: 295.0070 - val_loss: 353395.7812 - val_mae: 362.7902\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 256282.9844 - mae: 297.6259 - val_loss: 355456.0312 - val_mae: 355.5606\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 256668.1094 - mae: 295.5286 - val_loss: 349378.9062 - val_mae: 356.1177\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 256212.0625 - mae: 298.0955 - val_loss: 351913.2500 - val_mae: 358.3168\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 255949.2969 - mae: 296.9278 - val_loss: 374786.9062 - val_mae: 360.9717\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 256989.9688 - mae: 293.7421 - val_loss: 347326.8438 - val_mae: 369.4297\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 258677.4844 - mae: 302.6357 - val_loss: 394769.9688 - val_mae: 362.8727\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 259462.0938 - mae: 293.0400 - val_loss: 349315.4062 - val_mae: 362.9469\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 255905.7969 - mae: 297.8190 - val_loss: 352399.3750 - val_mae: 361.0361\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 255321.7188 - mae: 296.7951 - val_loss: 363998.3125 - val_mae: 358.4534\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 255771.6875 - mae: 293.6549 - val_loss: 349493.8750 - val_mae: 362.9144\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 256101.2969 - mae: 298.7945 - val_loss: 372177.0000 - val_mae: 362.3783\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 255213.7656 - mae: 293.7055 - val_loss: 366755.7500 - val_mae: 363.5667\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 254581.3281 - mae: 295.1067 - val_loss: 356484.4688 - val_mae: 364.9590\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 255870.3438 - mae: 299.1244 - val_loss: 379333.3750 - val_mae: 357.2552\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 256537.0000 - mae: 291.9460 - val_loss: 356616.3438 - val_mae: 361.1785\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 254761.8594 - mae: 298.4440 - val_loss: 371332.2188 - val_mae: 360.6583\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 254285.8594 - mae: 294.0889 - val_loss: 368770.2812 - val_mae: 363.3019\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 253799.6875 - mae: 295.1133 - val_loss: 361626.1875 - val_mae: 366.1999\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 254337.3438 - mae: 297.6279 - val_loss: 384121.1562 - val_mae: 360.2407\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 254943.0000 - mae: 291.6843 - val_loss: 353253.2812 - val_mae: 359.0553\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 254557.1250 - mae: 296.7688 - val_loss: 362212.4062 - val_mae: 354.5739\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 253311.1094 - mae: 292.9226 - val_loss: 360165.1875 - val_mae: 357.7361\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 252902.2031 - mae: 294.9991 - val_loss: 366407.9688 - val_mae: 357.3239\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 253226.0938 - mae: 292.9571 - val_loss: 355378.2500 - val_mae: 363.8857\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 253419.4219 - mae: 297.9470 - val_loss: 376450.9062 - val_mae: 360.3969\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 253638.9375 - mae: 291.9675 - val_loss: 355716.8438 - val_mae: 362.0543\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 252685.8281 - mae: 295.6452 - val_loss: 359740.1250 - val_mae: 359.9846\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 251935.3125 - mae: 294.0579 - val_loss: 365739.1562 - val_mae: 357.8035\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 252321.2344 - mae: 292.5670 - val_loss: 356540.6250 - val_mae: 363.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 252788.3906 - mae: 297.2434 - val_loss: 380928.0000 - val_mae: 359.9123\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 252981.9219 - mae: 291.2688 - val_loss: 359739.3125 - val_mae: 363.0983\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 253116.9688 - mae: 296.3503 - val_loss: 370685.9688 - val_mae: 359.4733\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 251487.9375 - mae: 292.3830 - val_loss: 375250.8438 - val_mae: 356.2335\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 252099.4531 - mae: 291.3406 - val_loss: 361753.1562 - val_mae: 362.7524\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 254165.1875 - mae: 300.6251 - val_loss: 388577.3125 - val_mae: 354.3087\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 255441.4844 - mae: 290.4787 - val_loss: 358617.3750 - val_mae: 358.8905\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 252263.3750 - mae: 297.2278 - val_loss: 359398.8750 - val_mae: 359.5046\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 251378.6250 - mae: 295.9979 - val_loss: 389551.0312 - val_mae: 356.9898\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 253722.6250 - mae: 290.5017 - val_loss: 360673.8125 - val_mae: 365.5227\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 253301.1719 - mae: 299.6351 - val_loss: 380979.7812 - val_mae: 356.1884\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 251685.0312 - mae: 290.2921 - val_loss: 368041.3750 - val_mae: 358.1791\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 250073.5000 - mae: 292.6066 - val_loss: 362473.6250 - val_mae: 359.6151\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 250986.1406 - mae: 295.7061 - val_loss: 389339.8750 - val_mae: 358.7992\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 252136.7500 - mae: 290.3823 - val_loss: 366086.4062 - val_mae: 365.1523\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 250483.6875 - mae: 296.9185 - val_loss: 376656.1875 - val_mae: 362.2441\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 250016.3125 - mae: 292.7273 - val_loss: 378915.2188 - val_mae: 362.5601\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 249723.0312 - mae: 292.3835 - val_loss: 365808.5625 - val_mae: 364.9218\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 250171.5781 - mae: 296.0907 - val_loss: 394127.1250 - val_mae: 358.2086\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 251644.8125 - mae: 289.9666 - val_loss: 367594.6250 - val_mae: 359.3807\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 249915.7344 - mae: 296.4098 - val_loss: 373042.9062 - val_mae: 353.6518\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 248595.6094 - mae: 292.4904 - val_loss: 380073.4375 - val_mae: 352.7483\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 248900.3281 - mae: 290.3865 - val_loss: 367027.3125 - val_mae: 360.1649\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 250357.0156 - mae: 297.2300 - val_loss: 400458.1250 - val_mae: 360.7040\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 250516.0156 - mae: 290.1085 - val_loss: 379422.7812 - val_mae: 368.8250\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 248518.8906 - mae: 294.7950 - val_loss: 386916.1250 - val_mae: 367.8170\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 247919.6719 - mae: 293.0872 - val_loss: 398262.5000 - val_mae: 362.6816\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 249045.9062 - mae: 290.1210 - val_loss: 373024.7500 - val_mae: 367.1890\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 249881.2969 - mae: 298.2042 - val_loss: 396890.8438 - val_mae: 357.8912\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 249782.1406 - mae: 289.3864 - val_loss: 378044.7812 - val_mae: 358.3436\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 247358.8125 - mae: 292.7687 - val_loss: 370509.2188 - val_mae: 362.6561\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 250079.4844 - mae: 297.3569 - val_loss: 420259.4375 - val_mae: 358.3631\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 253927.1406 - mae: 289.6046 - val_loss: 374461.5000 - val_mae: 367.0011\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 248721.5000 - mae: 295.5365 - val_loss: 382501.4375 - val_mae: 364.2467\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 246893.7500 - mae: 292.3431 - val_loss: 399902.2500 - val_mae: 357.5842\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 249911.8750 - mae: 288.5350 - val_loss: 377882.8125 - val_mae: 367.0941\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 248784.0938 - mae: 298.1890 - val_loss: 387126.2500 - val_mae: 361.1223\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 246503.9062 - mae: 290.6292 - val_loss: 396518.8438 - val_mae: 364.2480\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 246696.9219 - mae: 289.7633 - val_loss: 383028.2500 - val_mae: 368.8774\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 247361.5469 - mae: 294.0971 - val_loss: 405282.0625 - val_mae: 362.6749\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 246879.7500 - mae: 289.0430 - val_loss: 384615.2500 - val_mae: 364.5423\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 245757.8594 - mae: 292.6599 - val_loss: 387667.6875 - val_mae: 359.8241\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 245424.7969 - mae: 290.6922 - val_loss: 385839.7500 - val_mae: 356.8800\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 245252.2500 - mae: 290.2803 - val_loss: 379707.1562 - val_mae: 358.9753\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 245617.5625 - mae: 292.8022 - val_loss: 400992.6562 - val_mae: 358.9262\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 246028.1094 - mae: 287.9307 - val_loss: 387031.7812 - val_mae: 366.9627\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 245352.4844 - mae: 293.5683 - val_loss: 399733.9688 - val_mae: 361.8047\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 244831.3750 - mae: 289.2869 - val_loss: 388725.2812 - val_mae: 361.8185\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 244115.3750 - mae: 291.1782 - val_loss: 388044.4688 - val_mae: 358.9166\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 244187.5312 - mae: 290.4738 - val_loss: 396943.6562 - val_mae: 356.5885\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 244772.7500 - mae: 288.4434 - val_loss: 384884.1250 - val_mae: 364.9110\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 245474.2344 - mae: 294.9726 - val_loss: 416729.9375 - val_mae: 360.8321\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 246113.5312 - mae: 287.7941 - val_loss: 386784.7812 - val_mae: 367.6277\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 245141.4219 - mae: 293.3733 - val_loss: 403148.1875 - val_mae: 365.2250\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 244270.0938 - mae: 289.0989 - val_loss: 406988.4375 - val_mae: 364.0732\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 244048.8594 - mae: 288.5874 - val_loss: 385909.7500 - val_mae: 367.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 245476.6250 - mae: 295.1738 - val_loss: 416585.8125 - val_mae: 356.9931\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 247908.3594 - mae: 287.1415 - val_loss: 387197.8750 - val_mae: 362.1099\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 244020.0625 - mae: 294.0364 - val_loss: 389691.0000 - val_mae: 360.0627\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 243000.0469 - mae: 291.8260 - val_loss: 413947.1250 - val_mae: 359.3683\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 245053.5469 - mae: 287.7429 - val_loss: 393262.7812 - val_mae: 365.2228\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 243479.4531 - mae: 293.2963 - val_loss: 405496.1250 - val_mae: 364.1346\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 242303.7969 - mae: 290.0004 - val_loss: 415966.0312 - val_mae: 361.1909\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 243126.8750 - mae: 287.9289 - val_loss: 395025.1875 - val_mae: 366.5683\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 243051.8750 - mae: 293.2051 - val_loss: 422266.3750 - val_mae: 359.4997\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 244665.9062 - mae: 286.7834 - val_loss: 387596.2188 - val_mae: 364.6984\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 243531.3750 - mae: 293.2177 - val_loss: 398464.4688 - val_mae: 362.5533\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 241888.1562 - mae: 288.6388 - val_loss: 421848.9688 - val_mae: 362.3636\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 243237.9844 - mae: 286.4365 - val_loss: 396501.3750 - val_mae: 372.5841\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 244981.6094 - mae: 296.2358 - val_loss: 428030.1562 - val_mae: 359.2929\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 244852.3906 - mae: 285.9589 - val_loss: 390875.8125 - val_mae: 358.7473\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 241952.5312 - mae: 290.6841 - val_loss: 392745.4062 - val_mae: 357.6533\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 241815.1562 - mae: 290.6896 - val_loss: 417319.9688 - val_mae: 357.5260\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 242713.2812 - mae: 286.0063 - val_loss: 401503.3750 - val_mae: 366.8379\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 241739.0469 - mae: 292.9087 - val_loss: 413781.0938 - val_mae: 362.2138\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 240212.7031 - mae: 287.6751 - val_loss: 412343.4688 - val_mae: 362.0531\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 239913.0312 - mae: 287.2961 - val_loss: 396168.4688 - val_mae: 364.5040\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 241415.0938 - mae: 291.1962 - val_loss: 416848.4375 - val_mae: 358.9178\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 241158.5000 - mae: 285.6974 - val_loss: 401788.3438 - val_mae: 360.6930\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 239483.9375 - mae: 288.7501 - val_loss: 401637.1562 - val_mae: 363.0277\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 240324.9688 - mae: 290.2631 - val_loss: 422237.0938 - val_mae: 359.1028\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 240751.7969 - mae: 285.5644 - val_loss: 404519.3438 - val_mae: 367.3266\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 239486.2500 - mae: 290.2855 - val_loss: 429687.8750 - val_mae: 364.3003\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 239652.3594 - mae: 285.8369 - val_loss: 407674.6250 - val_mae: 366.5165\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 238766.3438 - mae: 289.5577 - val_loss: 408723.3750 - val_mae: 360.0512\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 238284.6250 - mae: 287.5132 - val_loss: 405055.4688 - val_mae: 357.0387\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 237996.2500 - mae: 287.4017 - val_loss: 401922.0312 - val_mae: 359.9395\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 238198.3281 - mae: 288.6727 - val_loss: 432446.4688 - val_mae: 359.1818\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 240268.7500 - mae: 284.6422 - val_loss: 405529.6250 - val_mae: 368.7664\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 240475.2656 - mae: 292.9691 - val_loss: 431677.8438 - val_mae: 361.1961\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 239104.5156 - mae: 284.6361 - val_loss: 404906.4062 - val_mae: 362.7219\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 238010.9688 - mae: 288.0428 - val_loss: 407222.3438 - val_mae: 360.6615\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 237723.7344 - mae: 286.5208 - val_loss: 417779.8750 - val_mae: 359.9685\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 237242.3594 - mae: 284.6707 - val_loss: 405606.1562 - val_mae: 366.8729\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 237876.3906 - mae: 290.0599 - val_loss: 426078.6250 - val_mae: 362.0317\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 237331.4219 - mae: 284.4370 - val_loss: 412468.7812 - val_mae: 364.3605\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 236175.9531 - mae: 286.6624 - val_loss: 409110.6250 - val_mae: 360.1885\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 236218.5156 - mae: 285.9788 - val_loss: 418193.9688 - val_mae: 355.4238\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 236135.2500 - mae: 283.7737 - val_loss: 407362.4062 - val_mae: 360.0761\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 236401.3750 - mae: 289.7312 - val_loss: 435968.4375 - val_mae: 359.6434\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 237205.6719 - mae: 283.7253 - val_loss: 418397.5312 - val_mae: 370.7172\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 236207.9062 - mae: 289.6426 - val_loss: 440667.6875 - val_mae: 366.6477\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 235616.9531 - mae: 284.9019 - val_loss: 423733.2188 - val_mae: 365.2730\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 234829.1875 - mae: 285.8750 - val_loss: 413134.2500 - val_mae: 363.0835\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 234973.7969 - mae: 287.8360 - val_loss: 434405.8125 - val_mae: 355.3470\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 237252.1719 - mae: 282.2552 - val_loss: 411565.6250 - val_mae: 363.3853\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 236809.7031 - mae: 291.4270 - val_loss: 434123.5312 - val_mae: 360.0858\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 235106.4688 - mae: 283.0893 - val_loss: 427883.5312 - val_mae: 367.8628\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 234193.9844 - mae: 285.6011 - val_loss: 431679.6562 - val_mae: 373.1872\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 234009.7500 - mae: 287.4189 - val_loss: 461725.3750 - val_mae: 366.2077\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 236135.0312 - mae: 283.0354 - val_loss: 425049.2812 - val_mae: 372.3363\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 236683.1406 - mae: 292.3373 - val_loss: 442885.5000 - val_mae: 355.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 236582.0156 - mae: 281.8657 - val_loss: 417854.1250 - val_mae: 360.8989\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 234040.9688 - mae: 289.0299 - val_loss: 426152.7812 - val_mae: 358.5006\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 232675.6875 - mae: 284.3594 - val_loss: 447085.4375 - val_mae: 363.6429\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 233048.8438 - mae: 282.8928 - val_loss: 430341.5312 - val_mae: 377.0219\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 235186.1875 - mae: 291.6050 - val_loss: 465092.3438 - val_mae: 363.3184\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 235722.8750 - mae: 281.5418 - val_loss: 417277.4375 - val_mae: 365.3233\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 232767.2656 - mae: 288.4358 - val_loss: 428141.4062 - val_mae: 356.3663\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 231887.5781 - mae: 282.3443 - val_loss: 421631.2188 - val_mae: 357.4143\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 230699.9375 - mae: 284.2766 - val_loss: 421701.5000 - val_mae: 364.8257\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 231537.6406 - mae: 287.1595 - val_loss: 459576.6562 - val_mae: 364.6288\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 232619.1875 - mae: 281.6148 - val_loss: 433716.0000 - val_mae: 372.3972\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 231350.5156 - mae: 286.8511 - val_loss: 450627.5625 - val_mae: 366.2630\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 230727.5781 - mae: 282.6658 - val_loss: 437930.2500 - val_mae: 363.4680\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 230555.8438 - mae: 283.3909 - val_loss: 424918.0625 - val_mae: 362.9005\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 230414.2969 - mae: 286.2021 - val_loss: 449561.8750 - val_mae: 355.9533\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 232695.5781 - mae: 280.0646 - val_loss: 421499.1250 - val_mae: 364.3068\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 232110.7656 - mae: 288.9125 - val_loss: 448150.8125 - val_mae: 361.3532\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 230625.8594 - mae: 280.9462 - val_loss: 440135.0000 - val_mae: 367.8486\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 229457.4219 - mae: 284.0827 - val_loss: 443145.0625 - val_mae: 368.3200\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 228971.8906 - mae: 283.7995 - val_loss: 452459.7812 - val_mae: 363.0356\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 228834.3438 - mae: 280.9139 - val_loss: 427357.3750 - val_mae: 365.6044\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 230581.4531 - mae: 287.3336 - val_loss: 456585.7500 - val_mae: 359.4032\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 230880.5312 - mae: 279.9586 - val_loss: 432863.2188 - val_mae: 366.5604\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 228876.4688 - mae: 285.2827 - val_loss: 452490.3438 - val_mae: 363.8552\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 227472.1250 - mae: 280.6357 - val_loss: 445545.5938 - val_mae: 369.2233\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 227192.7969 - mae: 283.2628 - val_loss: 457384.8750 - val_mae: 364.6943\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 227869.3750 - mae: 280.4508 - val_loss: 436636.6562 - val_mae: 368.1554\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 228645.7031 - mae: 286.1751 - val_loss: 464322.1875 - val_mae: 359.4105\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 230370.6250 - mae: 279.1614 - val_loss: 438183.4375 - val_mae: 369.6879\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 230055.2969 - mae: 289.1976 - val_loss: 468545.0000 - val_mae: 359.2388\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 230388.8906 - mae: 278.9592 - val_loss: 439461.3125 - val_mae: 367.3157\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 227010.6719 - mae: 285.7996 - val_loss: 450178.2500 - val_mae: 360.8598\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 225936.7500 - mae: 280.1205 - val_loss: 452781.3125 - val_mae: 364.0713\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 225470.3594 - mae: 280.2737 - val_loss: 457216.2500 - val_mae: 367.0046\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 225026.7031 - mae: 280.9430 - val_loss: 451604.0938 - val_mae: 373.2293\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 225600.3906 - mae: 284.5627 - val_loss: 475614.1875 - val_mae: 364.4715\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 227094.4375 - mae: 278.5306 - val_loss: 439648.6250 - val_mae: 368.1065\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 227199.7500 - mae: 286.3864 - val_loss: 458181.8750 - val_mae: 361.1459\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 225694.6562 - mae: 278.8620 - val_loss: 454841.8750 - val_mae: 362.0949\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 223583.7344 - mae: 279.4244 - val_loss: 446470.3438 - val_mae: 372.2066\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 227778.9375 - mae: 288.5771 - val_loss: 499352.7812 - val_mae: 363.8488\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 233413.0312 - mae: 278.3624 - val_loss: 435161.5938 - val_mae: 373.0006\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 230221.6094 - mae: 290.3243 - val_loss: 473771.6875 - val_mae: 367.4467\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 224889.7188 - mae: 279.0586 - val_loss: 485358.8125 - val_mae: 370.2064\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 224030.2969 - mae: 278.6631 - val_loss: 452527.0625 - val_mae: 382.9599\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 230531.2500 - mae: 292.9775 - val_loss: 506693.7188 - val_mae: 365.6421\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 235183.3125 - mae: 277.9507 - val_loss: 445617.9375 - val_mae: 363.3486\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 223371.1875 - mae: 284.2094 - val_loss: 444985.2812 - val_mae: 370.0113\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 225413.3750 - mae: 287.2928 - val_loss: 501804.8438 - val_mae: 364.7567\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 235816.2188 - mae: 278.1650 - val_loss: 445401.0000 - val_mae: 371.4349\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 225523.6719 - mae: 287.4119 - val_loss: 450506.5625 - val_mae: 369.8752\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 222476.3281 - mae: 282.7551 - val_loss: 506018.7188 - val_mae: 365.9295\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 231327.1406 - mae: 276.5771 - val_loss: 453996.8438 - val_mae: 374.9599\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 225953.9688 - mae: 288.5051 - val_loss: 453192.0312 - val_mae: 361.5977\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 220926.4688 - mae: 278.8875 - val_loss: 464411.6875 - val_mae: 358.3656\n",
      "Epoch 830/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 222456.4219 - mae: 276.1144 - val_loss: 450321.8438 - val_mae: 368.6998\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 223385.7500 - mae: 285.5125 - val_loss: 469513.2812 - val_mae: 367.1030\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 221237.2656 - mae: 277.8495 - val_loss: 484557.7188 - val_mae: 367.1541\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 221380.1094 - mae: 276.4209 - val_loss: 461730.6250 - val_mae: 376.3491\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 223621.5625 - mae: 285.7467 - val_loss: 477665.8750 - val_mae: 358.3263\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 222260.4219 - mae: 275.1479 - val_loss: 457895.1562 - val_mae: 360.2812\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 219129.6719 - mae: 278.3118 - val_loss: 455777.2188 - val_mae: 366.0494\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 220222.6562 - mae: 282.9201 - val_loss: 494402.2812 - val_mae: 363.9738\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 224800.4688 - mae: 275.3741 - val_loss: 471182.5000 - val_mae: 377.0323\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 221086.8906 - mae: 285.0706 - val_loss: 482023.4375 - val_mae: 371.1140\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 218212.7031 - mae: 278.5092 - val_loss: 493222.4062 - val_mae: 364.2157\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 219640.5469 - mae: 275.6891 - val_loss: 461436.5625 - val_mae: 369.6021\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 221680.1562 - mae: 284.2907 - val_loss: 478485.1562 - val_mae: 358.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 219440.5469 - mae: 274.5565 - val_loss: 468813.9375 - val_mae: 358.5008\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 217684.6406 - mae: 274.9054 - val_loss: 464074.8438 - val_mae: 370.8410\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 221234.5000 - mae: 285.2402 - val_loss: 485713.4062 - val_mae: 360.2543\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 220847.2188 - mae: 273.3891 - val_loss: 469093.2188 - val_mae: 366.3748\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 216220.0938 - mae: 276.7728 - val_loss: 458602.5625 - val_mae: 373.9582\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 220237.6719 - mae: 284.4070 - val_loss: 516394.8438 - val_mae: 368.6671\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 224298.2031 - mae: 274.4055 - val_loss: 470514.4688 - val_mae: 373.2846\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 217076.9062 - mae: 280.6821 - val_loss: 473252.3125 - val_mae: 370.1795\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 216155.3750 - mae: 279.2084 - val_loss: 500566.5938 - val_mae: 362.1701\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 221308.5938 - mae: 273.9282 - val_loss: 473814.7812 - val_mae: 369.8130\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 218766.6562 - mae: 283.5339 - val_loss: 475945.3750 - val_mae: 359.0962\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 215659.2031 - mae: 274.4413 - val_loss: 476151.2812 - val_mae: 359.6729\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 214804.5312 - mae: 274.0815 - val_loss: 471128.6562 - val_mae: 369.1007\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 217142.7188 - mae: 281.9695 - val_loss: 491845.8750 - val_mae: 360.6469\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 217060.1719 - mae: 272.5961 - val_loss: 473084.1875 - val_mae: 366.0505\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 213705.3438 - mae: 276.0941 - val_loss: 474221.5312 - val_mae: 368.1597\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 213745.2969 - mae: 277.4567 - val_loss: 485482.3750 - val_mae: 361.6886\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 214877.6406 - mae: 272.4178 - val_loss: 477114.2812 - val_mae: 368.7430\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 213662.1250 - mae: 277.8458 - val_loss: 484897.0625 - val_mae: 366.5112\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 212933.1875 - mae: 273.9745 - val_loss: 481197.6562 - val_mae: 370.3610\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 213430.7344 - mae: 277.0609 - val_loss: 499138.3438 - val_mae: 369.5590\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 212771.3438 - mae: 273.5832 - val_loss: 495356.6562 - val_mae: 374.6584\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 212030.0312 - mae: 276.7400 - val_loss: 499277.6562 - val_mae: 365.3508\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 212360.3125 - mae: 272.8243 - val_loss: 484594.9062 - val_mae: 365.6382\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 211816.9531 - mae: 276.3641 - val_loss: 483635.9062 - val_mae: 359.7497\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 211262.0156 - mae: 272.4682 - val_loss: 478842.1250 - val_mae: 364.2289\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 211720.4375 - mae: 276.6805 - val_loss: 495765.8438 - val_mae: 364.9818\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 212196.0469 - mae: 271.3986 - val_loss: 491355.2188 - val_mae: 375.4840\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 211371.5625 - mae: 277.2865 - val_loss: 507568.4688 - val_mae: 368.0711\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 210196.0625 - mae: 271.6824 - val_loss: 494066.2812 - val_mae: 367.9043\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 209326.0625 - mae: 274.2040 - val_loss: 489902.9375 - val_mae: 362.8104\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 209026.8906 - mae: 273.2068 - val_loss: 487540.3438 - val_mae: 360.9070\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 208677.0156 - mae: 272.4660 - val_loss: 493824.9375 - val_mae: 362.3025\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 208230.2031 - mae: 271.4044 - val_loss: 493869.5312 - val_mae: 374.2777\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 209924.9688 - mae: 278.0394 - val_loss: 521608.4375 - val_mae: 366.1359\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 211193.0000 - mae: 269.9499 - val_loss: 496035.5625 - val_mae: 374.1104\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 208870.6719 - mae: 277.3044 - val_loss: 502425.4375 - val_mae: 362.8486\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 208356.0625 - mae: 270.0819 - val_loss: 494324.6562 - val_mae: 367.4354\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 207619.1875 - mae: 275.9189 - val_loss: 498209.5312 - val_mae: 363.1664\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 206509.4375 - mae: 270.8602 - val_loss: 503934.0625 - val_mae: 364.6394\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 206200.2656 - mae: 270.4904 - val_loss: 506349.0625 - val_mae: 368.1559\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 206359.2656 - mae: 272.4958 - val_loss: 506342.0625 - val_mae: 366.8302\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 206517.0156 - mae: 271.3844 - val_loss: 500501.6562 - val_mae: 366.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 205829.1562 - mae: 272.5011 - val_loss: 506401.8750 - val_mae: 363.7486\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 205592.0469 - mae: 269.3716 - val_loss: 494644.9688 - val_mae: 371.6512\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 208109.6562 - mae: 276.2624 - val_loss: 533568.1875 - val_mae: 368.7394\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 208117.5938 - mae: 268.7667 - val_loss: 510719.6875 - val_mae: 373.0658\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 205286.6719 - mae: 272.5849 - val_loss: 504709.6250 - val_mae: 367.8231\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 205635.0000 - mae: 272.1511 - val_loss: 506415.2812 - val_mae: 360.1451\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 206741.5625 - mae: 268.2444 - val_loss: 507868.3438 - val_mae: 375.8947\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 207512.2500 - mae: 279.5785 - val_loss: 547407.3750 - val_mae: 372.8500\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 209373.5469 - mae: 268.6438 - val_loss: 514072.3438 - val_mae: 385.3256\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 208824.7344 - mae: 278.1078 - val_loss: 527687.9375 - val_mae: 378.9989\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 206706.9375 - mae: 272.4969 - val_loss: 527556.5625 - val_mae: 367.9737\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 205838.8125 - mae: 268.3203 - val_loss: 506697.9375 - val_mae: 365.9367\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 204916.5781 - mae: 272.8748 - val_loss: 504225.4375 - val_mae: 353.3868\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 205886.8125 - mae: 268.1038 - val_loss: 518446.7188 - val_mae: 371.3742\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 206539.7344 - mae: 277.1078 - val_loss: 531212.2500 - val_mae: 365.2846\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 210695.3438 - mae: 268.0326 - val_loss: 528935.1875 - val_mae: 390.7704\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 213533.2969 - mae: 285.6343 - val_loss: 631624.3750 - val_mae: 388.6629\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 219169.4375 - mae: 272.0212 - val_loss: 524299.5000 - val_mae: 399.7115\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 213762.5469 - mae: 285.0680 - val_loss: 537705.5625 - val_mae: 370.6376\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 203959.4062 - mae: 267.2850 - val_loss: 511496.2188 - val_mae: 362.1068\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 202663.3750 - mae: 266.2358 - val_loss: 525992.8750 - val_mae: 388.1777\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 209679.3594 - mae: 282.1624 - val_loss: 539476.1250 - val_mae: 363.4791\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 217941.1875 - mae: 267.6542 - val_loss: 529916.1875 - val_mae: 384.3624\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 205451.8906 - mae: 279.3737 - val_loss: 523922.5938 - val_mae: 376.1296\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 200078.0781 - mae: 270.8634 - val_loss: 570152.6875 - val_mae: 384.1796\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 205052.9219 - mae: 267.5314 - val_loss: 531896.8125 - val_mae: 397.1152\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 208126.5469 - mae: 282.1235 - val_loss: 556711.3750 - val_mae: 380.3559\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 201134.5469 - mae: 267.2695 - val_loss: 554523.3125 - val_mae: 369.6656\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 201236.0625 - mae: 264.5942 - val_loss: 538871.4375 - val_mae: 392.4813\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 212288.8438 - mae: 284.3954 - val_loss: 557327.1875 - val_mae: 365.1407\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 216246.7344 - mae: 267.4398 - val_loss: 516949.8438 - val_mae: 362.9254\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 199087.5156 - mae: 271.9024 - val_loss: 526976.9375 - val_mae: 374.7188\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 201187.4844 - mae: 276.0071 - val_loss: 594225.4375 - val_mae: 380.2180\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 215990.5156 - mae: 270.9202 - val_loss: 550179.1250 - val_mae: 397.5764\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 203815.6719 - mae: 279.3682 - val_loss: 554619.8125 - val_mae: 383.1950\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 197177.9219 - mae: 268.9173 - val_loss: 550312.8125 - val_mae: 371.6994\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 198010.5156 - mae: 264.9108 - val_loss: 523881.0625 - val_mae: 373.1996\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 200229.6094 - mae: 274.3261 - val_loss: 528572.4375 - val_mae: 357.6771\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 198907.1562 - mae: 263.1768 - val_loss: 520147.2188 - val_mae: 362.5576\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 195882.4531 - mae: 266.8378 - val_loss: 530961.1250 - val_mae: 373.7931\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 195570.6719 - mae: 269.1745 - val_loss: 564412.3750 - val_mae: 377.8086\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 196173.1719 - mae: 264.2531 - val_loss: 559322.5000 - val_mae: 393.4007\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 195987.1094 - mae: 272.3244 - val_loss: 572980.6875 - val_mae: 386.1376\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 194518.2500 - mae: 266.2892 - val_loss: 563193.1250 - val_mae: 378.6999\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 194157.6719 - mae: 264.4979 - val_loss: 542321.8750 - val_mae: 375.3698\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 194947.6250 - mae: 270.6386 - val_loss: 544538.0000 - val_mae: 362.7671\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 194535.6250 - mae: 262.7483 - val_loss: 538789.4375 - val_mae: 366.7751\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 193019.1875 - mae: 266.7239 - val_loss: 545899.1250 - val_mae: 370.8656\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 191969.0156 - mae: 264.8257 - val_loss: 563319.6250 - val_mae: 372.5077\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 194676.3906 - mae: 262.9355 - val_loss: 561278.1250 - val_mae: 397.4604\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 198842.4375 - mae: 277.8207 - val_loss: 583278.7500 - val_mae: 376.5122\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 200236.4219 - mae: 263.0944 - val_loss: 556926.6875 - val_mae: 384.0193\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 192543.8906 - mae: 269.3060 - val_loss: 551466.8750 - val_mae: 381.9889\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 192984.2031 - mae: 270.2482 - val_loss: 585074.3125 - val_mae: 372.7249\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 201309.0312 - mae: 263.6262 - val_loss: 559951.9375 - val_mae: 390.4479\n",
      "Epoch 941/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step - loss: 199371.0938 - mae: 276.7540 - val_loss: 565787.7500 - val_mae: 371.6660\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 191364.9219 - mae: 261.8255 - val_loss: 567271.7500 - val_mae: 373.0111\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 190387.3125 - mae: 261.9308 - val_loss: 567039.0625 - val_mae: 389.8712\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 195624.5469 - mae: 273.9641 - val_loss: 590058.1250 - val_mae: 373.8546\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 200095.6250 - mae: 263.3904 - val_loss: 562159.9375 - val_mae: 385.7646\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 192614.6094 - mae: 271.8661 - val_loss: 561047.3750 - val_mae: 373.3307\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 188848.5156 - mae: 262.4014 - val_loss: 569199.3125 - val_mae: 374.1790\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 190115.7812 - mae: 261.3904 - val_loss: 573580.5000 - val_mae: 398.6438\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 194320.0625 - mae: 275.0090 - val_loss: 589869.1250 - val_mae: 374.9808\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 194310.3594 - mae: 261.1497 - val_loss: 567190.1250 - val_mae: 384.4564\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 190843.9062 - mae: 268.8296 - val_loss: 571659.0000 - val_mae: 376.2192\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 187551.4219 - mae: 262.6179 - val_loss: 581199.5625 - val_mae: 371.3398\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 190381.9062 - mae: 260.1430 - val_loss: 579313.5625 - val_mae: 393.0768\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 195445.2188 - mae: 275.8028 - val_loss: 586039.5000 - val_mae: 371.6062\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 195889.1094 - mae: 260.9079 - val_loss: 569045.6875 - val_mae: 379.0157\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 186579.0781 - mae: 265.6638 - val_loss: 565814.5000 - val_mae: 382.1651\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 187653.5469 - mae: 268.1641 - val_loss: 593190.6250 - val_mae: 376.2618\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 195193.5000 - mae: 261.7657 - val_loss: 566396.3125 - val_mae: 390.8388\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 190221.7188 - mae: 271.6711 - val_loss: 572409.1875 - val_mae: 378.7291\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 184638.8281 - mae: 260.8080 - val_loss: 574628.5000 - val_mae: 372.7698\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 187394.5781 - mae: 259.1051 - val_loss: 571022.5625 - val_mae: 391.9958\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 189626.2500 - mae: 271.2441 - val_loss: 579405.3750 - val_mae: 372.0940\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 187870.5469 - mae: 258.7571 - val_loss: 567220.5625 - val_mae: 377.1611\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 183832.9688 - mae: 262.5432 - val_loss: 570967.0625 - val_mae: 380.3365\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 184452.7344 - mae: 264.7624 - val_loss: 588160.2500 - val_mae: 373.9930\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 188899.4062 - mae: 259.3502 - val_loss: 580919.6875 - val_mae: 389.6530\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 187000.6406 - mae: 269.0359 - val_loss: 576708.9375 - val_mae: 372.9987\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 183746.4531 - mae: 258.7178 - val_loss: 568995.5625 - val_mae: 374.0993\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 182056.9219 - mae: 259.8459 - val_loss: 568579.1875 - val_mae: 378.6465\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 183751.1094 - mae: 263.9125 - val_loss: 584323.0625 - val_mae: 371.1104\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 185285.2188 - mae: 258.2565 - val_loss: 585772.3750 - val_mae: 391.6411\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 184692.6406 - mae: 266.8311 - val_loss: 588052.6875 - val_mae: 373.5163\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 183357.9375 - mae: 257.7766 - val_loss: 578119.5000 - val_mae: 380.0939\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 180973.0312 - mae: 262.9564 - val_loss: 578071.5000 - val_mae: 374.4311\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 179923.3750 - mae: 258.7106 - val_loss: 581007.1875 - val_mae: 377.0948\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 179522.3906 - mae: 259.7876 - val_loss: 591180.8125 - val_mae: 378.6927\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 179608.5156 - mae: 258.4726 - val_loss: 592937.5625 - val_mae: 387.0176\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 180380.6562 - mae: 262.0128 - val_loss: 595218.3125 - val_mae: 375.2974\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 180640.5000 - mae: 257.0576 - val_loss: 578073.5000 - val_mae: 385.5468\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 181223.1875 - mae: 264.4953 - val_loss: 577160.3125 - val_mae: 371.4017\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 181262.6094 - mae: 256.1584 - val_loss: 566917.1250 - val_mae: 375.7934\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 179271.2656 - mae: 262.6408 - val_loss: 571716.3125 - val_mae: 371.2548\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 178091.9844 - mae: 257.6865 - val_loss: 581736.3750 - val_mae: 375.1655\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 177328.5156 - mae: 258.1837 - val_loss: 588319.4375 - val_mae: 381.1221\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 177647.8906 - mae: 260.5265 - val_loss: 590791.1875 - val_mae: 374.1947\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 183855.8594 - mae: 257.3889 - val_loss: 584704.5000 - val_mae: 398.1485\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 187128.4375 - mae: 272.2402 - val_loss: 577298.3750 - val_mae: 372.6413\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 187335.8438 - mae: 256.6271 - val_loss: 566743.0000 - val_mae: 386.6450\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 178660.2969 - mae: 264.1009 - val_loss: 573588.8125 - val_mae: 386.3104\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 176925.2500 - mae: 260.5983 - val_loss: 593111.6875 - val_mae: 376.6784\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 179449.3438 - mae: 254.9314 - val_loss: 593445.8750 - val_mae: 396.8947\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 179674.4375 - mae: 264.2860 - val_loss: 597575.8750 - val_mae: 377.2017\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 179113.0000 - mae: 255.5037 - val_loss: 582670.0625 - val_mae: 379.4109\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 176174.4844 - mae: 260.0373 - val_loss: 580341.4375 - val_mae: 374.9291\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 174607.6094 - mae: 257.5355 - val_loss: 587495.6875 - val_mae: 376.4864\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step - loss: 175199.9219 - mae: 254.4457 - val_loss: 596179.4375 - val_mae: 394.5801\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 177479.7500 - mae: 264.8280 - val_loss: 604271.6875 - val_mae: 377.5241\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 181139.0781 - mae: 254.4929 - val_loss: 595287.0625 - val_mae: 397.1574\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 177579.4219 - mae: 264.1266 - val_loss: 583658.5625 - val_mae: 374.1408\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 173451.6406 - mae: 254.4370 - val_loss: 580704.6250 - val_mae: 370.1498\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(250, input_dim=features.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "history = model.fit(features, target, epochs=1000, batch_size=500, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8273417286203273"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original=[]\n",
    "predicted = []\n",
    "for x in target['Supplier Quote(including GST)']:\n",
    "    original.append(x)\n",
    "\n",
    "for x in predictions:\n",
    "    predicted.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for x in range(len(original)):\n",
    "    diff.append(predicted[x] - original[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Preds'] = predicted\n",
    "df['Margin Of Error'] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "      <th>Number of MiniBus</th>\n",
       "      <th>Number of Large MiniBus</th>\n",
       "      <th>Number of Small Coach</th>\n",
       "      <th>Number of Medium Coach</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "      <th>Extra Large Coach</th>\n",
       "      <th>Preds</th>\n",
       "      <th>Margin Of Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>431.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416.309235</td>\n",
       "      <td>-14.940765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>517.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>426.844238</td>\n",
       "      <td>-90.655762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>889.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>495.183502</td>\n",
       "      <td>-393.856498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>1518.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>978.855164</td>\n",
       "      <td>-539.144836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>490.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>710.501648</td>\n",
       "      <td>220.501648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>530.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>544.956116</td>\n",
       "      <td>14.956116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>224.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313.021576</td>\n",
       "      <td>88.271576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313.021576</td>\n",
       "      <td>-186.978424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>985.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1194.435059</td>\n",
       "      <td>209.435059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1380.860840</td>\n",
       "      <td>480.860840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  \\\n",
       "0                     21                       0.35   \n",
       "1                     36                       5.37   \n",
       "2                     84                       7.45   \n",
       "3                     25                       7.72   \n",
       "4                     26                       3.18   \n",
       "..                   ...                        ...   \n",
       "448                   23                       7.43   \n",
       "449                   28                       2.98   \n",
       "450                   28                       2.98   \n",
       "451                  103                       9.85   \n",
       "452                  143                      12.18   \n",
       "\n",
       "     Supplier Quote(including GST)  Number of MiniBus  \\\n",
       "0                           431.25                  0   \n",
       "1                           517.50                  0   \n",
       "2                           889.04                  0   \n",
       "3                          1518.00                  0   \n",
       "4                           490.00                  0   \n",
       "..                             ...                ...   \n",
       "448                         530.00                  0   \n",
       "449                         224.75                  0   \n",
       "450                         500.00                  0   \n",
       "451                         985.00                  0   \n",
       "452                         900.00                  0   \n",
       "\n",
       "     Number of Large MiniBus  Number of Small Coach  Number of Medium Coach  \\\n",
       "0                          0                      1                       0   \n",
       "1                          0                      1                       0   \n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          0                      0                       0   \n",
       "..                       ...                    ...                     ...   \n",
       "448                        0                      1                       0   \n",
       "449                        0                      1                       0   \n",
       "450                        0                      1                       0   \n",
       "451                        0                      0                       0   \n",
       "452                        0                      0                       0   \n",
       "\n",
       "     Number of Large Coach  Extra Large Coach        Preds  Margin Of Error  \n",
       "0                        0                  0   416.309235       -14.940765  \n",
       "1                        0                  0   426.844238       -90.655762  \n",
       "2                        0                  0   495.183502      -393.856498  \n",
       "3                        0                  1   978.855164      -539.144836  \n",
       "4                        0                  1   710.501648       220.501648  \n",
       "..                     ...                ...          ...              ...  \n",
       "448                      0                  0   544.956116        14.956116  \n",
       "449                      0                  0   313.021576        88.271576  \n",
       "450                      0                  0   313.021576      -186.978424  \n",
       "451                      1                  0  1194.435059       209.435059  \n",
       "452                      0                  1  1380.860840       480.860840  \n",
       "\n",
       "[453 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.89157697867086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for x in df['Margin Of Error']:\n",
    "    sum = sum + np.abs(x)\n",
    "\n",
    "sum/len(df['Margin Of Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"NN_predictor_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NN_predictor_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('NN_predictor_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"NN_predictor_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[544.98145]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params = [[Vehicle class,Trip type,Passengers,Distance in kms,Travel time minutes,Total time elapsed(hours),Number of Large Coach]]\n",
    "loaded_model.predict([[0,1,30,20.85,23,7.43,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"NN_DataFile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
