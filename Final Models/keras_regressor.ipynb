{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import backend as k\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "      <th>Number of MiniBus</th>\n",
       "      <th>Number of Large MiniBus</th>\n",
       "      <th>Number of Small Coach</th>\n",
       "      <th>Number of Medium Coach</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "      <th>Extra Large Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>431.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>517.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>889.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>1518.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>490.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>530.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>224.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>985.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  \\\n",
       "0                     21                       0.35   \n",
       "1                     36                       5.37   \n",
       "2                     84                       7.45   \n",
       "3                     25                       7.72   \n",
       "4                     26                       3.18   \n",
       "..                   ...                        ...   \n",
       "448                   23                       7.43   \n",
       "449                   28                       2.98   \n",
       "450                   28                       2.98   \n",
       "451                  103                       9.85   \n",
       "452                  143                      12.18   \n",
       "\n",
       "     Supplier Quote(including GST)  Number of MiniBus  \\\n",
       "0                           431.25                  0   \n",
       "1                           517.50                  0   \n",
       "2                           889.04                  0   \n",
       "3                          1518.00                  0   \n",
       "4                           490.00                  0   \n",
       "..                             ...                ...   \n",
       "448                         530.00                  0   \n",
       "449                         224.75                  0   \n",
       "450                         500.00                  0   \n",
       "451                         985.00                  0   \n",
       "452                         900.00                  0   \n",
       "\n",
       "     Number of Large MiniBus  Number of Small Coach  Number of Medium Coach  \\\n",
       "0                          0                      1                       0   \n",
       "1                          0                      1                       0   \n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          0                      0                       0   \n",
       "..                       ...                    ...                     ...   \n",
       "448                        0                      1                       0   \n",
       "449                        0                      1                       0   \n",
       "450                        0                      1                       0   \n",
       "451                        0                      0                       0   \n",
       "452                        0                      0                       0   \n",
       "\n",
       "     Number of Large Coach  Extra Large Coach  \n",
       "0                        0                  0  \n",
       "1                        0                  0  \n",
       "2                        0                  0  \n",
       "3                        0                  1  \n",
       "4                        0                  1  \n",
       "..                     ...                ...  \n",
       "448                      0                  0  \n",
       "449                      0                  0  \n",
       "450                      0                  0  \n",
       "451                      1                  0  \n",
       "452                      0                  1  \n",
       "\n",
       "[453 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv(\"./final_dataset.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(labels=['Supplier Quote(including GST)','Number of MiniBus','Number of Medium Coach','Number of Large MiniBus','Number of Small Coach','Extra Large Coach'],axis=1)\n",
    "target = df[['Supplier Quote(including GST)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  Number of Large Coach  \n",
       "0                     21                       0.35                      0  \n",
       "1                     36                       5.37                      0  \n",
       "2                     84                       7.45                      0  \n",
       "3                     25                       7.72                      0  \n",
       "4                     26                       3.18                      0  \n",
       "..                   ...                        ...                    ...  \n",
       "448                   23                       7.43                      0  \n",
       "449                   28                       2.98                      0  \n",
       "450                   28                       2.98                      0  \n",
       "451                  103                       9.85                      1  \n",
       "452                  143                      12.18                      0  \n",
       "\n",
       "[453 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>889.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1518.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>530.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>224.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>985.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>900.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Supplier Quote(including GST)\n",
       "0                           431.25\n",
       "1                           517.50\n",
       "2                           889.04\n",
       "3                          1518.00\n",
       "4                           490.00\n",
       "..                             ...\n",
       "448                         530.00\n",
       "449                         224.75\n",
       "450                         500.00\n",
       "451                         985.00\n",
       "452                         900.00\n",
       "\n",
       "[453 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.reshape(target, (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               2000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 40,271\n",
      "Trainable params: 40,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2515166.7500 - mae: 1085.7118 - val_loss: 3506207.2500 - val_mae: 1252.8185\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2472657.7500 - mae: 1076.5487 - val_loss: 3444670.0000 - val_mae: 1241.4363\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2436791.2500 - mae: 1068.6576 - val_loss: 3386677.7500 - val_mae: 1230.1735\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2404163.0000 - mae: 1061.2183 - val_loss: 3323167.0000 - val_mae: 1217.6600\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2369452.5000 - mae: 1053.3422 - val_loss: 3253215.0000 - val_mae: 1203.2537\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2330768.7500 - mae: 1044.3713 - val_loss: 3172840.0000 - val_mae: 1185.7053\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2286349.5000 - mae: 1033.8938 - val_loss: 3085629.2500 - val_mae: 1165.5701\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2236094.0000 - mae: 1021.8638 - val_loss: 2991636.7500 - val_mae: 1142.1925\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2179242.0000 - mae: 1007.9996 - val_loss: 2893807.5000 - val_mae: 1128.0172\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2115502.5000 - mae: 992.0898 - val_loss: 2793874.0000 - val_mae: 1112.1914\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2043998.7500 - mae: 973.9683 - val_loss: 2693986.7500 - val_mae: 1093.7594\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1963521.3750 - mae: 954.2637 - val_loss: 2595306.7500 - val_mae: 1071.6211\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1872849.5000 - mae: 931.2921 - val_loss: 2497825.7500 - val_mae: 1045.2505\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1770283.0000 - mae: 904.3127 - val_loss: 2406234.5000 - val_mae: 1014.6181\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1657115.6250 - mae: 873.0083 - val_loss: 2326800.5000 - val_mae: 978.5598\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1533888.5000 - mae: 836.8267 - val_loss: 2269915.2500 - val_mae: 936.4136\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1401259.6250 - mae: 794.9733 - val_loss: 2251565.5000 - val_mae: 887.6463\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1261814.7500 - mae: 746.9144 - val_loss: 2289956.0000 - val_mae: 835.8444\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1118584.0000 - mae: 691.8257 - val_loss: 2400644.2500 - val_mae: 781.4999\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 976475.9375 - mae: 635.1799 - val_loss: 2617093.7500 - val_mae: 725.4639\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 845310.4375 - mae: 575.8977 - val_loss: 2952077.7500 - val_mae: 670.4719\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 731899.3750 - mae: 518.8913 - val_loss: 3395042.0000 - val_mae: 624.7073\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 647001.6250 - mae: 465.3490 - val_loss: 3923100.2500 - val_mae: 614.8275\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 602399.7500 - mae: 432.7907 - val_loss: 4475507.5000 - val_mae: 633.7796\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 606168.6875 - mae: 426.2108 - val_loss: 4919249.0000 - val_mae: 669.1070\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 651170.9375 - mae: 436.4150 - val_loss: 5093244.0000 - val_mae: 708.3778\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 708601.1250 - mae: 452.3875 - val_loss: 4896971.5000 - val_mae: 721.8382\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 742739.4375 - mae: 462.0674 - val_loss: 4396850.5000 - val_mae: 709.0675\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 737170.9375 - mae: 460.2383 - val_loss: 3727614.2500 - val_mae: 674.7843\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 698282.8125 - mae: 447.9494 - val_loss: 3012164.2500 - val_mae: 626.9124\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 642575.3750 - mae: 430.5506 - val_loss: 2360818.7500 - val_mae: 573.6277\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 586379.1250 - mae: 411.7075 - val_loss: 1829618.1250 - val_mae: 525.0208\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 541157.4375 - mae: 395.0005 - val_loss: 1416317.1250 - val_mae: 488.9821\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 511283.3125 - mae: 383.9308 - val_loss: 1119865.1250 - val_mae: 462.4802\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 496400.2500 - mae: 376.8331 - val_loss: 917761.6875 - val_mae: 440.5055\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 492866.2500 - mae: 374.8954 - val_loss: 786720.6250 - val_mae: 429.2341\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 495617.8125 - mae: 376.3393 - val_loss: 701026.4375 - val_mae: 423.2600\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 499815.3438 - mae: 378.0733 - val_loss: 641335.2500 - val_mae: 417.4958\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 501781.3438 - mae: 378.0512 - val_loss: 596658.3750 - val_mae: 410.7518\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 499358.5312 - mae: 375.0254 - val_loss: 559233.4375 - val_mae: 401.9186\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 491607.5938 - mae: 368.9005 - val_loss: 524512.5000 - val_mae: 391.3624\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 479434.0000 - mae: 360.4419 - val_loss: 493069.7188 - val_mae: 381.8625\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 464510.4062 - mae: 350.0384 - val_loss: 464393.5312 - val_mae: 373.9321\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 448916.6875 - mae: 339.9372 - val_loss: 440087.8750 - val_mae: 367.9047\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 435038.3750 - mae: 332.1684 - val_loss: 422443.5312 - val_mae: 368.0227\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 424927.0312 - mae: 327.5237 - val_loss: 412832.2188 - val_mae: 370.3111\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 419708.3438 - mae: 326.0161 - val_loss: 410719.6875 - val_mae: 378.0473\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 418959.4688 - mae: 327.4683 - val_loss: 412284.4062 - val_mae: 385.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 420355.1250 - mae: 330.4352 - val_loss: 412934.6250 - val_mae: 391.5893\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 420891.5312 - mae: 333.1174 - val_loss: 409565.7500 - val_mae: 393.2916\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 418551.8125 - mae: 333.9810 - val_loss: 402112.8438 - val_mae: 390.7557\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 412736.7812 - mae: 332.0379 - val_loss: 392116.5312 - val_mae: 384.3658\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 404702.0625 - mae: 327.6282 - val_loss: 383028.0312 - val_mae: 375.4443\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 396493.9688 - mae: 321.6582 - val_loss: 377383.6875 - val_mae: 366.2246\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 389956.9062 - mae: 315.6219 - val_loss: 376345.7188 - val_mae: 357.6905\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 385833.9062 - mae: 311.9548 - val_loss: 378495.8125 - val_mae: 350.2883\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 383813.8750 - mae: 309.3540 - val_loss: 382616.7500 - val_mae: 345.3123\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 382956.7188 - mae: 307.5911 - val_loss: 387023.1562 - val_mae: 342.7715\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 382424.3125 - mae: 306.5587 - val_loss: 390259.9688 - val_mae: 342.5737\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 381430.2188 - mae: 306.1963 - val_loss: 391722.1562 - val_mae: 343.6955\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 379636.1562 - mae: 306.4159 - val_loss: 390905.7188 - val_mae: 345.8674\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 377105.8438 - mae: 307.1499 - val_loss: 389815.4688 - val_mae: 349.3593\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 374433.1562 - mae: 308.7372 - val_loss: 389753.5312 - val_mae: 354.6759\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 372248.1250 - mae: 311.5420 - val_loss: 392071.0000 - val_mae: 361.1970\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 371060.9375 - mae: 315.3375 - val_loss: 396932.0000 - val_mae: 368.7116\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 370859.5000 - mae: 319.2321 - val_loss: 403274.6250 - val_mae: 375.7934\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 371242.3438 - mae: 322.7051 - val_loss: 410162.5625 - val_mae: 381.2137\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 371541.4688 - mae: 325.1917 - val_loss: 415318.7812 - val_mae: 383.4050\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 371302.6250 - mae: 326.1882 - val_loss: 417345.6562 - val_mae: 382.1474\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 370467.9062 - mae: 325.6251 - val_loss: 416563.2188 - val_mae: 378.0772\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 369402.4062 - mae: 323.8057 - val_loss: 414472.1875 - val_mae: 372.3649\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 368567.8125 - mae: 321.3707 - val_loss: 411876.5312 - val_mae: 366.4869\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 368247.4688 - mae: 319.1264 - val_loss: 409783.6875 - val_mae: 362.5427\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 368395.7500 - mae: 317.2523 - val_loss: 407796.0938 - val_mae: 359.6226\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 368661.0312 - mae: 316.0375 - val_loss: 405273.5000 - val_mae: 357.9687\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 368701.1250 - mae: 315.5568 - val_loss: 402040.7188 - val_mae: 357.6437\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 368368.0000 - mae: 315.8057 - val_loss: 398357.5938 - val_mae: 358.5246\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 367768.8750 - mae: 316.7126 - val_loss: 394312.9375 - val_mae: 360.0588\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 367177.2812 - mae: 318.0686 - val_loss: 390576.5312 - val_mae: 362.1096\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 366787.9062 - mae: 319.5347 - val_loss: 387045.4375 - val_mae: 364.1645\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 366593.5938 - mae: 321.0468 - val_loss: 383657.3750 - val_mae: 365.6651\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 366519.7812 - mae: 322.2256 - val_loss: 380568.2500 - val_mae: 365.9996\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 366432.7188 - mae: 322.8370 - val_loss: 377706.1250 - val_mae: 365.0314\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 366233.5625 - mae: 322.6877 - val_loss: 375140.3125 - val_mae: 362.6978\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 365900.5625 - mae: 321.8204 - val_loss: 373188.5625 - val_mae: 359.5602\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 365499.1875 - mae: 320.4267 - val_loss: 372108.2500 - val_mae: 356.1410\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 365136.7812 - mae: 318.7724 - val_loss: 371451.9062 - val_mae: 352.7638\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 364877.8125 - mae: 317.2089 - val_loss: 370991.8750 - val_mae: 350.1213\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 364713.6875 - mae: 315.9153 - val_loss: 370609.6562 - val_mae: 348.1783\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 364588.5312 - mae: 315.0453 - val_loss: 370032.7812 - val_mae: 347.0273\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 364417.8125 - mae: 314.5625 - val_loss: 369208.0312 - val_mae: 346.6518\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 364196.7188 - mae: 314.4572 - val_loss: 368350.2500 - val_mae: 347.0323\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 363936.5000 - mae: 314.6897 - val_loss: 367575.4375 - val_mae: 347.9262\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 363682.6562 - mae: 315.1891 - val_loss: 367010.8125 - val_mae: 349.3267\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 363469.3125 - mae: 315.8193 - val_loss: 366376.1875 - val_mae: 350.5645\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 363304.7500 - mae: 316.4259 - val_loss: 365508.3750 - val_mae: 351.2887\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 363161.9375 - mae: 316.8412 - val_loss: 364353.5625 - val_mae: 351.4256\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 363006.6875 - mae: 316.9629 - val_loss: 363004.1875 - val_mae: 350.7613\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 362818.3750 - mae: 316.7589 - val_loss: 361669.5312 - val_mae: 349.4035\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 362605.7500 - mae: 316.2784 - val_loss: 360558.2500 - val_mae: 347.6142\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 362401.5000 - mae: 315.6379 - val_loss: 359421.2812 - val_mae: 345.7293\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 362196.0312 - mae: 314.9480 - val_loss: 358435.3750 - val_mae: 344.0051\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 362020.1875 - mae: 314.3414 - val_loss: 357871.5625 - val_mae: 342.7128\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 361863.8750 - mae: 313.8897 - val_loss: 357338.0000 - val_mae: 341.9253\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 361694.0312 - mae: 313.6452 - val_loss: 356719.3438 - val_mae: 341.6750\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 361500.6562 - mae: 313.6278 - val_loss: 356059.8750 - val_mae: 341.8996\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 361288.3438 - mae: 313.8102 - val_loss: 355540.2500 - val_mae: 342.4883\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 361089.3125 - mae: 314.1372 - val_loss: 355070.2812 - val_mae: 343.2242\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 360887.1250 - mae: 314.5229 - val_loss: 354747.6875 - val_mae: 343.9520\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 360680.9375 - mae: 314.8800 - val_loss: 354498.5938 - val_mae: 344.4753\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 360492.4062 - mae: 315.1533 - val_loss: 354460.0938 - val_mae: 344.6972\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 360288.6562 - mae: 315.2993 - val_loss: 354252.2812 - val_mae: 344.4820\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 360068.5625 - mae: 315.3056 - val_loss: 353916.4688 - val_mae: 343.9270\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 359840.5312 - mae: 315.1673 - val_loss: 353374.4688 - val_mae: 343.1448\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 359630.3438 - mae: 314.9472 - val_loss: 352759.0625 - val_mae: 342.3120\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 359419.0625 - mae: 314.7061 - val_loss: 352272.1250 - val_mae: 341.6216\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 359196.0312 - mae: 314.4891 - val_loss: 351798.2500 - val_mae: 341.1239\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 358986.5938 - mae: 314.3719 - val_loss: 350959.7500 - val_mae: 340.7596\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 358760.1250 - mae: 314.3787 - val_loss: 350031.6562 - val_mae: 340.5222\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 358513.3125 - mae: 314.4653 - val_loss: 349062.1562 - val_mae: 340.3444\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 358272.0625 - mae: 314.6003 - val_loss: 348320.1875 - val_mae: 340.2079\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 358026.7188 - mae: 314.7363 - val_loss: 347593.1562 - val_mae: 340.0463\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 357763.7500 - mae: 314.8462 - val_loss: 346984.1562 - val_mae: 339.8632\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 357507.4062 - mae: 314.9075 - val_loss: 346494.7500 - val_mae: 339.6071\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 357244.2812 - mae: 314.9030 - val_loss: 346109.0312 - val_mae: 339.2688\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 357011.2500 - mae: 314.8438 - val_loss: 345567.3125 - val_mae: 338.8496\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 356753.9375 - mae: 314.7623 - val_loss: 344958.8125 - val_mae: 338.4063\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 356493.5625 - mae: 314.6821 - val_loss: 344378.3125 - val_mae: 337.9553\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 356242.9062 - mae: 314.5869 - val_loss: 343860.5938 - val_mae: 337.6064\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 355978.0625 - mae: 314.4918 - val_loss: 343459.5312 - val_mae: 337.4135\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 355713.3125 - mae: 314.4417 - val_loss: 343125.1562 - val_mae: 337.4229\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 355466.5938 - mae: 314.4641 - val_loss: 342902.2188 - val_mae: 337.5533\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 355189.9688 - mae: 314.5240 - val_loss: 342654.2812 - val_mae: 337.7344\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 354914.4375 - mae: 314.6030 - val_loss: 342425.7500 - val_mae: 337.8266\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 354613.0312 - mae: 314.6208 - val_loss: 342413.7188 - val_mae: 337.8959\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 354294.6562 - mae: 314.6091 - val_loss: 342695.1875 - val_mae: 337.8480\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 354018.3750 - mae: 314.5457 - val_loss: 342548.7188 - val_mae: 337.6590\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 353704.5938 - mae: 314.4937 - val_loss: 342347.1250 - val_mae: 337.5516\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 353409.2812 - mae: 314.4739 - val_loss: 342044.5625 - val_mae: 337.4715\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 353080.6875 - mae: 314.5006 - val_loss: 341689.6250 - val_mae: 337.3737\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 352759.3438 - mae: 314.5490 - val_loss: 341601.0000 - val_mae: 337.2160\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 352389.8438 - mae: 314.5706 - val_loss: 341498.0000 - val_mae: 337.0753\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 352072.1250 - mae: 314.6128 - val_loss: 340936.9375 - val_mae: 337.0135\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 351745.3438 - mae: 314.7774 - val_loss: 340217.5625 - val_mae: 336.9564\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 351389.3125 - mae: 314.9513 - val_loss: 339725.9688 - val_mae: 336.7805\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 351028.4062 - mae: 315.0362 - val_loss: 339321.7500 - val_mae: 336.5958\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 350684.6875 - mae: 315.0712 - val_loss: 338770.3750 - val_mae: 336.1300\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 350197.9688 - mae: 314.8944 - val_loss: 338843.6562 - val_mae: 334.8633\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 349868.9688 - mae: 314.2334 - val_loss: 338971.0625 - val_mae: 333.6971\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 349430.5000 - mae: 313.5602 - val_loss: 338488.5000 - val_mae: 333.4717\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 349075.6875 - mae: 313.5187 - val_loss: 337889.9375 - val_mae: 334.2834\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 348643.3750 - mae: 314.0207 - val_loss: 337251.2812 - val_mae: 335.4912\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 348192.5312 - mae: 314.8075 - val_loss: 336402.9688 - val_mae: 336.6025\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 347806.9062 - mae: 315.5782 - val_loss: 335607.8125 - val_mae: 337.3308\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 347465.0312 - mae: 316.2170 - val_loss: 335113.5625 - val_mae: 337.3668\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 347086.1250 - mae: 316.4165 - val_loss: 334893.7500 - val_mae: 336.5927\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 346688.5625 - mae: 316.1039 - val_loss: 334982.8438 - val_mae: 335.5341\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 346286.0625 - mae: 315.5713 - val_loss: 335054.2812 - val_mae: 334.9070\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 345893.2500 - mae: 315.2142 - val_loss: 334881.5000 - val_mae: 335.2268\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 345480.1875 - mae: 315.3306 - val_loss: 334805.0000 - val_mae: 336.1307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 345042.3750 - mae: 315.8086 - val_loss: 335345.5312 - val_mae: 335.9901\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 344594.2812 - mae: 315.6270 - val_loss: 335118.2188 - val_mae: 336.1058\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 344172.7812 - mae: 315.7852 - val_loss: 334237.6562 - val_mae: 336.4721\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 343617.0938 - mae: 316.2971 - val_loss: 334704.0312 - val_mae: 337.4829\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 343107.1250 - mae: 316.8157 - val_loss: 335727.0938 - val_mae: 337.5769\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 342386.5312 - mae: 316.2180 - val_loss: 336053.8750 - val_mae: 337.1438\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 341888.7188 - mae: 315.7499 - val_loss: 334650.1562 - val_mae: 337.4979\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 341400.5000 - mae: 316.4670 - val_loss: 333155.5938 - val_mae: 339.6454\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 340923.0938 - mae: 317.9386 - val_loss: 333282.2500 - val_mae: 339.8024\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 340426.4062 - mae: 317.9195 - val_loss: 333792.0000 - val_mae: 338.8945\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 339950.6875 - mae: 317.3797 - val_loss: 334322.6875 - val_mae: 339.8056\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 339457.9375 - mae: 317.0973 - val_loss: 333578.3438 - val_mae: 340.6233\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 338977.0312 - mae: 317.5356 - val_loss: 333458.0312 - val_mae: 340.5507\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 338402.6250 - mae: 317.3006 - val_loss: 332773.6250 - val_mae: 340.0981\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 337825.5625 - mae: 317.2528 - val_loss: 331761.1562 - val_mae: 339.9327\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 337197.5625 - mae: 317.8183 - val_loss: 332737.6250 - val_mae: 341.3436\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 336559.8750 - mae: 318.4785 - val_loss: 336693.7188 - val_mae: 342.7995\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 335849.3125 - mae: 318.3674 - val_loss: 341691.8125 - val_mae: 344.9100\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 335393.5312 - mae: 317.6227 - val_loss: 341776.5312 - val_mae: 346.5008\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 334855.2188 - mae: 318.8428 - val_loss: 339244.2500 - val_mae: 347.3484\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 334352.5000 - mae: 320.8420 - val_loss: 338508.7188 - val_mae: 347.5992\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 333858.0625 - mae: 320.8715 - val_loss: 339636.5625 - val_mae: 347.9477\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 333270.5938 - mae: 319.7542 - val_loss: 341170.6562 - val_mae: 348.5497\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 332645.5938 - mae: 318.9829 - val_loss: 341218.0312 - val_mae: 349.5230\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 332105.9375 - mae: 319.7558 - val_loss: 338696.8750 - val_mae: 350.6103\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 331615.9062 - mae: 321.7968 - val_loss: 338158.4688 - val_mae: 351.6487\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 331070.9062 - mae: 322.1870 - val_loss: 339520.6875 - val_mae: 352.4476\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 330471.3438 - mae: 321.0916 - val_loss: 340298.3438 - val_mae: 352.7506\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 329963.5000 - mae: 320.3812 - val_loss: 338828.7812 - val_mae: 352.6652\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 329434.3125 - mae: 320.6482 - val_loss: 336364.8438 - val_mae: 352.7872\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 328975.3438 - mae: 322.0296 - val_loss: 338099.3750 - val_mae: 351.7665\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 328401.1250 - mae: 320.2401 - val_loss: 339482.0312 - val_mae: 351.9347\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 327930.9688 - mae: 318.9414 - val_loss: 337044.8438 - val_mae: 353.3043\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 327409.8438 - mae: 320.3744 - val_loss: 336083.5938 - val_mae: 354.8112\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 326956.2188 - mae: 321.3527 - val_loss: 337871.1562 - val_mae: 355.9633\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 326420.8750 - mae: 320.8946 - val_loss: 340507.3438 - val_mae: 356.7003\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 325989.1562 - mae: 320.1137 - val_loss: 340488.1875 - val_mae: 356.5610\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 325467.2188 - mae: 319.7236 - val_loss: 338455.5625 - val_mae: 356.1768\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 324913.0000 - mae: 319.9940 - val_loss: 335919.9062 - val_mae: 357.0240\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 324452.0312 - mae: 321.0502 - val_loss: 336083.1562 - val_mae: 357.8643\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 323969.5625 - mae: 321.0403 - val_loss: 339792.2812 - val_mae: 359.4468\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 323476.0312 - mae: 320.1547 - val_loss: 340074.5938 - val_mae: 361.0803\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 323058.3438 - mae: 321.1694 - val_loss: 337022.8750 - val_mae: 361.9890\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 322686.6875 - mae: 323.0164 - val_loss: 340304.9375 - val_mae: 361.4049\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 322145.9688 - mae: 320.7278 - val_loss: 339611.4375 - val_mae: 361.4089\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 321688.7812 - mae: 320.4867 - val_loss: 337399.3750 - val_mae: 362.5999\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 321214.5625 - mae: 321.8817 - val_loss: 340003.9375 - val_mae: 363.6981\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 320763.7500 - mae: 321.3486 - val_loss: 340747.9062 - val_mae: 365.2701\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 320323.2500 - mae: 321.8831 - val_loss: 342824.7500 - val_mae: 366.2061\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 319829.5625 - mae: 321.3306 - val_loss: 343584.9375 - val_mae: 366.0009\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 319388.6875 - mae: 320.4031 - val_loss: 340037.8750 - val_mae: 366.9817\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 319072.5000 - mae: 321.9157 - val_loss: 343228.2500 - val_mae: 367.6349\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 318593.7188 - mae: 320.9496 - val_loss: 348072.3125 - val_mae: 368.7368\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 318113.4688 - mae: 319.8665 - val_loss: 344611.5000 - val_mae: 369.9383\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 317554.5938 - mae: 321.3836 - val_loss: 341780.4688 - val_mae: 370.5266\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 317192.8438 - mae: 322.3273 - val_loss: 347337.5938 - val_mae: 369.7029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 316856.6250 - mae: 319.7116 - val_loss: 341093.0312 - val_mae: 370.3068\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 316327.9375 - mae: 321.6245 - val_loss: 340083.3750 - val_mae: 371.2178\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 315848.2500 - mae: 322.2725 - val_loss: 352702.4062 - val_mae: 371.7191\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 315411.4375 - mae: 318.7897 - val_loss: 344337.4688 - val_mae: 371.9406\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 314945.2188 - mae: 320.9254 - val_loss: 342938.5000 - val_mae: 372.5853\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 314518.7500 - mae: 321.4130 - val_loss: 352929.8750 - val_mae: 372.7976\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 314071.6562 - mae: 318.4720 - val_loss: 346352.6250 - val_mae: 374.0247\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 313574.2188 - mae: 320.5108 - val_loss: 343410.8438 - val_mae: 374.3669\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 313245.4688 - mae: 321.2274 - val_loss: 351312.2188 - val_mae: 373.6864\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 312766.3750 - mae: 318.1332 - val_loss: 344369.2812 - val_mae: 373.4951\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 312253.0625 - mae: 319.4352 - val_loss: 341072.6250 - val_mae: 374.2455\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 311848.0312 - mae: 320.9807 - val_loss: 354882.5625 - val_mae: 374.9386\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 311400.6562 - mae: 317.8478 - val_loss: 343877.2812 - val_mae: 374.8396\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 310947.9688 - mae: 320.3610 - val_loss: 346042.2500 - val_mae: 374.5445\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 310415.7500 - mae: 319.0381 - val_loss: 349217.6562 - val_mae: 374.6593\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 309961.1562 - mae: 317.8633 - val_loss: 341380.1875 - val_mae: 374.6245\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 309539.9062 - mae: 319.4561 - val_loss: 346344.3438 - val_mae: 374.9510\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 308981.0938 - mae: 318.0457 - val_loss: 346427.8750 - val_mae: 375.1489\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 308470.5000 - mae: 318.0466 - val_loss: 340825.1562 - val_mae: 374.4518\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 308021.2188 - mae: 318.8595 - val_loss: 346509.1562 - val_mae: 374.2084\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 307538.7812 - mae: 316.8247 - val_loss: 342335.7812 - val_mae: 373.8653\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 307034.8438 - mae: 317.2273 - val_loss: 340762.8438 - val_mae: 374.4084\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 306506.2188 - mae: 317.8038 - val_loss: 344491.8125 - val_mae: 373.8212\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 306035.6562 - mae: 316.2457 - val_loss: 334059.0625 - val_mae: 373.5773\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 305510.3750 - mae: 318.7593 - val_loss: 354466.4688 - val_mae: 374.3628\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 305144.6562 - mae: 314.3578 - val_loss: 331102.0312 - val_mae: 372.3950\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 304488.7812 - mae: 318.1559 - val_loss: 345432.9375 - val_mae: 373.1080\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 303765.4062 - mae: 314.6443 - val_loss: 339680.5938 - val_mae: 372.0901\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 303080.0312 - mae: 314.8237 - val_loss: 327696.1875 - val_mae: 369.9994\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 302552.5625 - mae: 316.2571 - val_loss: 346337.0000 - val_mae: 372.1431\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 301981.0625 - mae: 312.9574 - val_loss: 325914.4375 - val_mae: 370.6072\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 301428.8750 - mae: 316.5945 - val_loss: 346971.7500 - val_mae: 372.2090\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 300830.5938 - mae: 312.6502 - val_loss: 329962.9375 - val_mae: 370.0725\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 300212.2188 - mae: 314.5877 - val_loss: 335039.3750 - val_mae: 369.7498\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 299689.3438 - mae: 312.8253 - val_loss: 331089.9062 - val_mae: 368.4806\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 299116.5000 - mae: 312.8653 - val_loss: 325476.4688 - val_mae: 367.9071\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 298553.9375 - mae: 314.0442 - val_loss: 345702.2812 - val_mae: 369.9288\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 298296.0312 - mae: 311.2096 - val_loss: 315748.5625 - val_mae: 366.6125\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 298110.5938 - mae: 316.4579 - val_loss: 360850.9375 - val_mae: 370.8878\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 297842.0000 - mae: 309.5655 - val_loss: 310268.7812 - val_mae: 365.2693\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 297555.6562 - mae: 317.4972 - val_loss: 352672.9375 - val_mae: 370.7323\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 296680.6250 - mae: 310.3951 - val_loss: 332558.1250 - val_mae: 368.5994\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 295924.1875 - mae: 312.6653 - val_loss: 319170.6562 - val_mae: 366.7231\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 295655.5938 - mae: 314.8452 - val_loss: 356689.6562 - val_mae: 371.1038\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 295451.2812 - mae: 310.0409 - val_loss: 314799.8750 - val_mae: 367.3233\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 295237.2500 - mae: 316.9722 - val_loss: 364585.5625 - val_mae: 372.5174\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 294939.5938 - mae: 310.0327 - val_loss: 318402.2812 - val_mae: 367.9974\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 294305.2500 - mae: 316.0374 - val_loss: 343731.0938 - val_mae: 370.9838\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 293674.9062 - mae: 312.2107 - val_loss: 340646.9375 - val_mae: 370.9120\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 293203.5938 - mae: 312.5302 - val_loss: 325694.0625 - val_mae: 369.5125\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 292980.8438 - mae: 314.4629 - val_loss: 350559.5938 - val_mae: 371.8826\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 292667.8750 - mae: 310.7491 - val_loss: 319148.4062 - val_mae: 368.5842\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 292353.2500 - mae: 315.4412 - val_loss: 352748.0000 - val_mae: 373.0874\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 291894.9062 - mae: 311.5828 - val_loss: 337654.0938 - val_mae: 372.2017\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 291382.4375 - mae: 313.8989 - val_loss: 339846.2812 - val_mae: 371.3732\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 290987.7188 - mae: 312.5199 - val_loss: 338862.9688 - val_mae: 369.8369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 290684.3125 - mae: 311.0704 - val_loss: 318141.7188 - val_mae: 367.7607\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 290554.2188 - mae: 314.4763 - val_loss: 373965.0000 - val_mae: 374.1098\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 290566.4375 - mae: 308.9068 - val_loss: 306086.6250 - val_mae: 366.6396\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 290804.7812 - mae: 317.2624 - val_loss: 391411.5625 - val_mae: 374.7885\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 290707.9688 - mae: 307.8753 - val_loss: 306954.6250 - val_mae: 367.0458\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 290112.6562 - mae: 316.9788 - val_loss: 364046.1250 - val_mae: 372.6831\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 289313.9688 - mae: 309.2045 - val_loss: 335015.4688 - val_mae: 370.4425\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 288669.6875 - mae: 311.9013 - val_loss: 321250.5938 - val_mae: 369.5758\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 288527.5000 - mae: 314.3434 - val_loss: 382936.8750 - val_mae: 374.6080\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 288626.1562 - mae: 308.6193 - val_loss: 315641.9375 - val_mae: 368.3306\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 288182.2188 - mae: 314.4563 - val_loss: 343676.7188 - val_mae: 371.2171\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 287537.4375 - mae: 310.3472 - val_loss: 358023.6875 - val_mae: 373.3014\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 287378.9062 - mae: 309.6205 - val_loss: 315250.0625 - val_mae: 370.1002\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 287665.0625 - mae: 315.2397 - val_loss: 393082.1875 - val_mae: 376.6722\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 287740.9375 - mae: 308.2262 - val_loss: 314207.6562 - val_mae: 369.6242\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 286993.6875 - mae: 314.5948 - val_loss: 350423.0312 - val_mae: 373.2109\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 286262.8125 - mae: 309.7574 - val_loss: 361420.7188 - val_mae: 374.5256\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 286224.6562 - mae: 309.1859 - val_loss: 318295.4375 - val_mae: 370.6515\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 286297.5312 - mae: 313.9650 - val_loss: 369857.7188 - val_mae: 375.0232\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 285850.5938 - mae: 308.4538 - val_loss: 332733.8125 - val_mae: 372.3369\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 285348.7188 - mae: 311.7495 - val_loss: 340241.3438 - val_mae: 373.6837\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 285098.9062 - mae: 311.3486 - val_loss: 371006.7188 - val_mae: 376.2733\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 285137.7500 - mae: 309.1067 - val_loss: 320330.3125 - val_mae: 370.9193\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 285062.8438 - mae: 313.2242 - val_loss: 366519.4375 - val_mae: 373.9421\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 284623.8750 - mae: 307.8896 - val_loss: 331855.5312 - val_mae: 371.1182\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 284234.2188 - mae: 310.6450 - val_loss: 339523.6875 - val_mae: 371.9108\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 283984.5625 - mae: 309.7322 - val_loss: 355657.0625 - val_mae: 373.2191\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 283831.6250 - mae: 308.2348 - val_loss: 320631.8125 - val_mae: 370.4140\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 283749.9062 - mae: 312.2671 - val_loss: 378302.1562 - val_mae: 376.4492\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 283591.1250 - mae: 308.2616 - val_loss: 328862.3438 - val_mae: 372.7286\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 283352.5625 - mae: 312.1655 - val_loss: 358536.1250 - val_mae: 374.4102\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 283012.5000 - mae: 308.8840 - val_loss: 339975.8750 - val_mae: 372.1267\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 282696.4688 - mae: 309.5242 - val_loss: 332655.4375 - val_mae: 371.2178\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 282513.3125 - mae: 309.9875 - val_loss: 366594.5625 - val_mae: 373.9360\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 282573.4062 - mae: 307.4644 - val_loss: 320370.0312 - val_mae: 370.0331\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 282516.5312 - mae: 311.4580 - val_loss: 374447.1562 - val_mae: 374.3676\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 282401.7500 - mae: 306.8357 - val_loss: 316413.4375 - val_mae: 370.0399\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 282144.4375 - mae: 311.9979 - val_loss: 375114.7812 - val_mae: 375.8219\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 281868.7188 - mae: 307.5791 - val_loss: 333724.9688 - val_mae: 373.3098\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 281447.9688 - mae: 310.5519 - val_loss: 351144.2188 - val_mae: 374.3981\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 281134.0000 - mae: 308.5391 - val_loss: 345700.4062 - val_mae: 373.3026\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 280912.2500 - mae: 308.4807 - val_loss: 335768.4062 - val_mae: 372.4186\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 280743.3750 - mae: 309.2413 - val_loss: 359251.3125 - val_mae: 374.7871\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 280618.0625 - mae: 307.9641 - val_loss: 338283.3438 - val_mae: 373.2883\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 280459.0938 - mae: 309.4112 - val_loss: 360405.0938 - val_mae: 374.6702\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 280316.7188 - mae: 307.3851 - val_loss: 323314.1250 - val_mae: 371.4508\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 280215.8750 - mae: 310.2980 - val_loss: 375165.8438 - val_mae: 375.8972\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 280257.0312 - mae: 306.6996 - val_loss: 322052.8438 - val_mae: 372.4973\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 280290.8438 - mae: 311.3396 - val_loss: 400210.8125 - val_mae: 378.0179\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 280314.8125 - mae: 305.7914 - val_loss: 307141.1875 - val_mae: 370.3175\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 280433.5312 - mae: 312.7352 - val_loss: 393552.5625 - val_mae: 376.7947\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 280258.3125 - mae: 305.3322 - val_loss: 314970.5000 - val_mae: 372.0673\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 279765.9375 - mae: 311.9720 - val_loss: 386321.2188 - val_mae: 377.3311\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 279100.1250 - mae: 306.3139 - val_loss: 337312.5312 - val_mae: 372.7914\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 278611.2812 - mae: 308.1156 - val_loss: 328533.1562 - val_mae: 371.8975\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 278453.2500 - mae: 308.6943 - val_loss: 381860.1875 - val_mae: 377.2943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 278647.5000 - mae: 305.7963 - val_loss: 319391.9062 - val_mae: 374.2294\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 278991.4062 - mae: 311.9112 - val_loss: 409489.7500 - val_mae: 379.6913\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 279019.1250 - mae: 305.1742 - val_loss: 313009.1875 - val_mae: 371.9388\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 278487.2812 - mae: 311.2847 - val_loss: 371765.4375 - val_mae: 376.7661\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 277842.7188 - mae: 305.8762 - val_loss: 350276.0000 - val_mae: 376.3550\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 277388.6875 - mae: 307.7235 - val_loss: 347007.4375 - val_mae: 375.9141\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 277229.1875 - mae: 307.6925 - val_loss: 370367.5312 - val_mae: 376.3249\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 277272.5625 - mae: 305.3132 - val_loss: 315202.6562 - val_mae: 371.9520\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 277528.3125 - mae: 310.3342 - val_loss: 411951.0000 - val_mae: 379.7752\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 277650.4062 - mae: 304.4908 - val_loss: 323608.5000 - val_mae: 374.5054\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 277290.4375 - mae: 310.2760 - val_loss: 375481.4375 - val_mae: 376.2890\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 276590.4375 - mae: 304.5214 - val_loss: 329560.7188 - val_mae: 372.0878\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 276168.3438 - mae: 306.7466 - val_loss: 335513.4375 - val_mae: 373.7152\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 275958.1562 - mae: 306.6329 - val_loss: 382708.3125 - val_mae: 379.2952\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 275857.0000 - mae: 304.9680 - val_loss: 328767.3750 - val_mae: 376.9551\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 276223.8438 - mae: 310.0209 - val_loss: 403982.9375 - val_mae: 380.5634\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 276253.6875 - mae: 303.8538 - val_loss: 319261.1562 - val_mae: 373.3990\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 275731.7812 - mae: 309.0770 - val_loss: 365305.8125 - val_mae: 377.8484\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 275178.4375 - mae: 304.8430 - val_loss: 366139.2812 - val_mae: 379.1710\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 274912.9375 - mae: 305.9236 - val_loss: 346662.1875 - val_mae: 377.2225\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 274828.8750 - mae: 307.0302 - val_loss: 378873.2188 - val_mae: 377.5472\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 274936.3750 - mae: 303.9072 - val_loss: 312033.9688 - val_mae: 372.4796\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 275277.5938 - mae: 309.9075 - val_loss: 421106.3750 - val_mae: 380.5329\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 275241.3125 - mae: 303.1686 - val_loss: 330560.2500 - val_mae: 375.8107\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 274707.3438 - mae: 308.7324 - val_loss: 372782.3438 - val_mae: 376.8885\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 274170.0625 - mae: 303.8706 - val_loss: 340459.4062 - val_mae: 374.1684\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 273831.6562 - mae: 305.5994 - val_loss: 347964.8125 - val_mae: 376.4320\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 273663.9688 - mae: 305.8054 - val_loss: 387698.1562 - val_mae: 380.2906\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 273641.4688 - mae: 304.2245 - val_loss: 328483.3125 - val_mae: 375.5049\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 273718.6250 - mae: 307.8841 - val_loss: 385332.3125 - val_mae: 378.2879\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 273695.8750 - mae: 302.7201 - val_loss: 320446.2812 - val_mae: 375.0403\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 273623.1250 - mae: 308.7765 - val_loss: 411381.4062 - val_mae: 382.3869\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 273427.2812 - mae: 303.1720 - val_loss: 337406.6562 - val_mae: 378.0252\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 273082.5938 - mae: 307.3907 - val_loss: 369652.4062 - val_mae: 377.8201\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 272661.9688 - mae: 303.0782 - val_loss: 333138.1250 - val_mae: 374.5528\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 272380.7188 - mae: 305.5424 - val_loss: 370574.8438 - val_mae: 378.6734\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 272222.5938 - mae: 303.7795 - val_loss: 368301.2500 - val_mae: 378.8087\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 272077.6562 - mae: 304.0013 - val_loss: 349793.2188 - val_mae: 376.4742\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 271786.0312 - mae: 304.1941 - val_loss: 359954.0000 - val_mae: 376.2735\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 271719.2188 - mae: 302.8722 - val_loss: 336961.7500 - val_mae: 375.7822\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 271713.2500 - mae: 305.3339 - val_loss: 401250.5000 - val_mae: 380.9465\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 271749.5000 - mae: 302.5796 - val_loss: 331902.6562 - val_mae: 376.6516\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 271641.8125 - mae: 306.7128 - val_loss: 397425.4062 - val_mae: 379.4731\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 271700.3438 - mae: 301.5442 - val_loss: 323428.0938 - val_mae: 376.2640\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 271732.3750 - mae: 308.0005 - val_loss: 454734.2812 - val_mae: 385.2217\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 272177.9688 - mae: 301.3414 - val_loss: 318006.2812 - val_mae: 377.9630\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 272226.5938 - mae: 309.9482 - val_loss: 426107.1250 - val_mae: 382.4666\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 271805.8438 - mae: 300.7112 - val_loss: 321506.4375 - val_mae: 375.0995\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 270818.2812 - mae: 306.5866 - val_loss: 378784.6562 - val_mae: 380.1516\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 270150.0000 - mae: 302.1893 - val_loss: 391418.1250 - val_mae: 383.3858\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 269990.2188 - mae: 303.3995 - val_loss: 358155.6562 - val_mae: 381.7211\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 270115.7500 - mae: 305.2968 - val_loss: 407991.4688 - val_mae: 381.7442\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 270259.4375 - mae: 301.0533 - val_loss: 315083.9688 - val_mae: 374.1140\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 270310.6875 - mae: 307.2413 - val_loss: 438651.3750 - val_mae: 382.6382\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 270577.8125 - mae: 300.1109 - val_loss: 331843.5000 - val_mae: 378.4086\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 270250.9062 - mae: 307.2382 - val_loss: 410748.3125 - val_mae: 379.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 269803.7188 - mae: 300.0173 - val_loss: 327566.0938 - val_mae: 374.4397\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 269139.1875 - mae: 304.8241 - val_loss: 375023.0312 - val_mae: 379.2827\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 268741.0312 - mae: 301.9670 - val_loss: 410180.9375 - val_mae: 383.5164\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 268704.8125 - mae: 302.1308 - val_loss: 351914.1875 - val_mae: 380.2505\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 268766.5938 - mae: 304.8677 - val_loss: 405491.1562 - val_mae: 379.9627\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 269077.0625 - mae: 299.7715 - val_loss: 318223.0000 - val_mae: 375.2610\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 269005.4062 - mae: 306.5982 - val_loss: 439698.1875 - val_mae: 384.3296\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 268767.0312 - mae: 300.2398 - val_loss: 356250.2812 - val_mae: 380.9857\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 268232.9688 - mae: 304.4993 - val_loss: 382985.3125 - val_mae: 378.4009\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 267795.0625 - mae: 300.1730 - val_loss: 346346.0625 - val_mae: 375.2587\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 267385.4688 - mae: 302.1120 - val_loss: 375237.9688 - val_mae: 379.7979\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 267232.5312 - mae: 301.6928 - val_loss: 413014.6875 - val_mae: 382.2848\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 267241.9688 - mae: 300.3537 - val_loss: 341398.6562 - val_mae: 376.8518\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 267296.7812 - mae: 303.5932 - val_loss: 408814.7188 - val_mae: 378.3950\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 267803.8438 - mae: 298.4702 - val_loss: 319885.5312 - val_mae: 376.3814\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 268088.6562 - mae: 306.7972 - val_loss: 493934.1562 - val_mae: 387.5637\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 268282.9688 - mae: 299.2258 - val_loss: 330737.5312 - val_mae: 378.6816\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 267696.0000 - mae: 306.1320 - val_loss: 395959.6875 - val_mae: 378.5533\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 266770.8438 - mae: 298.6387 - val_loss: 355469.6562 - val_mae: 376.3010\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 266092.3438 - mae: 300.8393 - val_loss: 360050.7188 - val_mae: 380.2502\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 266363.8125 - mae: 302.8127 - val_loss: 471274.7188 - val_mae: 386.4030\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 266880.5938 - mae: 299.1487 - val_loss: 322652.6250 - val_mae: 376.8213\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 266858.2188 - mae: 305.4141 - val_loss: 397811.4688 - val_mae: 377.6204\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 266577.5000 - mae: 297.4550 - val_loss: 338677.4688 - val_mae: 376.3913\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 265607.9375 - mae: 302.3448 - val_loss: 394967.1562 - val_mae: 381.6467\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 265184.5312 - mae: 300.0126 - val_loss: 411820.0938 - val_mae: 381.3809\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 265149.5312 - mae: 298.6587 - val_loss: 329341.6562 - val_mae: 375.2326\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 265487.4375 - mae: 303.0772 - val_loss: 432299.8125 - val_mae: 381.5852\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 265710.5000 - mae: 297.6672 - val_loss: 339701.2188 - val_mae: 379.5092\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 265673.4688 - mae: 304.2509 - val_loss: 444760.8750 - val_mae: 382.0684\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 265529.2812 - mae: 297.2643 - val_loss: 323900.5000 - val_mae: 374.6320\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 264924.7812 - mae: 302.9847 - val_loss: 386001.4062 - val_mae: 379.0504\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 264231.5000 - mae: 298.0028 - val_loss: 391524.0938 - val_mae: 381.8401\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 263848.1875 - mae: 299.1338 - val_loss: 367059.6562 - val_mae: 381.9268\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 263979.6562 - mae: 301.5181 - val_loss: 429595.8750 - val_mae: 382.4710\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 264220.4062 - mae: 297.3508 - val_loss: 332202.7500 - val_mae: 375.7661\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 263897.8125 - mae: 302.3963 - val_loss: 424408.5625 - val_mae: 380.3547\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 263713.0312 - mae: 296.8459 - val_loss: 368555.8750 - val_mae: 378.8224\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 263326.5625 - mae: 299.8765 - val_loss: 389965.0000 - val_mae: 377.6427\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 263013.5625 - mae: 297.3382 - val_loss: 372712.2188 - val_mae: 374.9104\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 262793.1562 - mae: 297.0499 - val_loss: 349175.7188 - val_mae: 374.7467\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 262785.6250 - mae: 299.5267 - val_loss: 430022.8125 - val_mae: 381.1702\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 262684.8750 - mae: 296.7489 - val_loss: 365204.5000 - val_mae: 380.1533\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 262706.3438 - mae: 300.8188 - val_loss: 431296.7812 - val_mae: 381.3294\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 262874.4062 - mae: 296.1488 - val_loss: 334101.0625 - val_mae: 376.5412\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 262720.5312 - mae: 302.0786 - val_loss: 451556.7500 - val_mae: 383.5236\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 262478.9688 - mae: 296.1181 - val_loss: 364833.7500 - val_mae: 381.2166\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 262184.0312 - mae: 301.1303 - val_loss: 433792.2188 - val_mae: 380.5640\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 261997.2812 - mae: 295.7817 - val_loss: 332967.8438 - val_mae: 372.8387\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 261805.2969 - mae: 300.2917 - val_loss: 418557.1562 - val_mae: 379.4100\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 261464.2500 - mae: 295.9300 - val_loss: 389178.4688 - val_mae: 381.1777\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 261092.9219 - mae: 298.7350 - val_loss: 404451.9688 - val_mae: 380.2857\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 260800.5938 - mae: 296.7514 - val_loss: 379105.3125 - val_mae: 377.3594\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 260693.7969 - mae: 296.7246 - val_loss: 365218.9375 - val_mae: 378.5164\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 260607.5625 - mae: 298.6790 - val_loss: 444198.6250 - val_mae: 383.2425\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 260646.2344 - mae: 295.8645 - val_loss: 355287.4062 - val_mae: 379.1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 260900.3906 - mae: 300.4193 - val_loss: 452661.0938 - val_mae: 379.6548\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 261597.1250 - mae: 294.2428 - val_loss: 308722.5938 - val_mae: 373.2267\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 262253.7812 - mae: 304.4889 - val_loss: 536033.0000 - val_mae: 385.7644\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 263102.0312 - mae: 294.4798 - val_loss: 323183.0625 - val_mae: 377.9360\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 262138.2969 - mae: 304.8703 - val_loss: 462972.8438 - val_mae: 381.6254\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 260728.6250 - mae: 294.4556 - val_loss: 355237.4688 - val_mae: 377.0569\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 259295.2969 - mae: 298.7039 - val_loss: 382209.0000 - val_mae: 378.2497\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 258854.0156 - mae: 296.5654 - val_loss: 444738.6250 - val_mae: 380.5094\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 259575.4531 - mae: 294.0077 - val_loss: 322207.8125 - val_mae: 375.9590\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 260384.6250 - mae: 302.7802 - val_loss: 493911.0625 - val_mae: 383.0774\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 260789.4219 - mae: 293.6267 - val_loss: 332899.4062 - val_mae: 377.0427\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 259367.2656 - mae: 301.4530 - val_loss: 423844.7812 - val_mae: 379.5490\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 258290.7656 - mae: 294.3348 - val_loss: 395387.1250 - val_mae: 377.9882\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 257913.8281 - mae: 295.3306 - val_loss: 354520.8438 - val_mae: 378.1977\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 258219.8281 - mae: 299.1817 - val_loss: 482461.4062 - val_mae: 382.5231\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 258971.8438 - mae: 293.3008 - val_loss: 323424.1875 - val_mae: 374.7809\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 258842.3281 - mae: 301.2244 - val_loss: 444042.6250 - val_mae: 378.6219\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 258808.7031 - mae: 292.6691 - val_loss: 349814.8438 - val_mae: 378.1404\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 257740.9062 - mae: 299.0702 - val_loss: 429366.1250 - val_mae: 382.8581\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 256942.0938 - mae: 294.6109 - val_loss: 408477.4062 - val_mae: 381.1284\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 256607.0000 - mae: 294.6360 - val_loss: 347282.4688 - val_mae: 376.5602\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 256760.0000 - mae: 298.2151 - val_loss: 442211.7812 - val_mae: 380.2367\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 257297.8125 - mae: 292.8091 - val_loss: 350165.0312 - val_mae: 379.4243\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 257262.8438 - mae: 299.9232 - val_loss: 477288.3438 - val_mae: 383.2828\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 256963.3594 - mae: 292.6888 - val_loss: 343549.9688 - val_mae: 375.4269\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 256339.6875 - mae: 297.9443 - val_loss: 395799.5625 - val_mae: 375.8587\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 256030.2500 - mae: 292.4474 - val_loss: 388831.4688 - val_mae: 379.4041\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 255603.6406 - mae: 295.0330 - val_loss: 401438.4062 - val_mae: 382.8587\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 255529.9844 - mae: 296.0900 - val_loss: 440939.4688 - val_mae: 379.6212\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 255781.1875 - mae: 292.2997 - val_loss: 321785.4375 - val_mae: 373.0195\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 256197.7188 - mae: 299.6460 - val_loss: 503575.2812 - val_mae: 381.9407\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 257170.8750 - mae: 291.7719 - val_loss: 334794.8750 - val_mae: 378.9109\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 257364.6875 - mae: 302.1622 - val_loss: 515861.3125 - val_mae: 381.8123\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 257048.0469 - mae: 291.2650 - val_loss: 320703.0000 - val_mae: 371.9022\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 255367.1094 - mae: 298.8485 - val_loss: 398465.3750 - val_mae: 376.6558\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 254178.1250 - mae: 291.9885 - val_loss: 444552.9375 - val_mae: 382.5123\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 253851.4688 - mae: 292.6524 - val_loss: 362603.5312 - val_mae: 381.2241\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 254501.9219 - mae: 298.4404 - val_loss: 460811.7500 - val_mae: 381.2768\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 254637.2344 - mae: 291.5137 - val_loss: 333789.8125 - val_mae: 375.0527\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 254003.4688 - mae: 298.0575 - val_loss: 419802.2812 - val_mae: 379.4498\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 253043.6406 - mae: 291.8156 - val_loss: 417309.7500 - val_mae: 380.4376\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 252588.0625 - mae: 292.9265 - val_loss: 365526.3750 - val_mae: 376.1254\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 252698.8125 - mae: 294.8080 - val_loss: 414636.7500 - val_mae: 375.6360\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 252960.7969 - mae: 290.2643 - val_loss: 350119.5312 - val_mae: 374.9796\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 252663.8438 - mae: 295.9052 - val_loss: 444178.4062 - val_mae: 380.9317\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 252324.0938 - mae: 291.7118 - val_loss: 401425.8750 - val_mae: 379.7118\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 251997.9375 - mae: 293.5740 - val_loss: 381148.7188 - val_mae: 375.0225\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 251722.2344 - mae: 292.4478 - val_loss: 387408.0938 - val_mae: 373.7051\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 251598.2969 - mae: 291.0771 - val_loss: 379441.7500 - val_mae: 377.0224\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 251519.3750 - mae: 293.7791 - val_loss: 448209.2812 - val_mae: 379.5227\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 251576.1719 - mae: 290.4730 - val_loss: 351572.4375 - val_mae: 375.4070\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 251666.2344 - mae: 295.6243 - val_loss: 430996.6250 - val_mae: 376.4441\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 251814.1406 - mae: 289.5768 - val_loss: 345222.6875 - val_mae: 375.7553\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 251553.5000 - mae: 296.4522 - val_loss: 463117.0938 - val_mae: 383.1795\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 250957.0312 - mae: 291.0168 - val_loss: 393838.0625 - val_mae: 383.3217\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 250585.7031 - mae: 295.0685 - val_loss: 416156.3438 - val_mae: 379.9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 250352.1250 - mae: 290.9071 - val_loss: 362629.3125 - val_mae: 375.9223\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 250071.3594 - mae: 293.7699 - val_loss: 409395.9062 - val_mae: 376.9371\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 249763.9531 - mae: 290.5717 - val_loss: 403919.1562 - val_mae: 377.7607\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 249487.7812 - mae: 291.6184 - val_loss: 394758.5938 - val_mae: 375.7711\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 249332.7500 - mae: 291.1135 - val_loss: 390446.8438 - val_mae: 375.5767\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 249071.7344 - mae: 290.9655 - val_loss: 390990.1250 - val_mae: 379.6714\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 249038.5000 - mae: 292.9887 - val_loss: 473050.4688 - val_mae: 382.8569\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 249414.1406 - mae: 289.7424 - val_loss: 344029.0625 - val_mae: 378.5488\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 250542.0625 - mae: 297.6548 - val_loss: 532238.1250 - val_mae: 380.0341\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 253625.2344 - mae: 289.0901 - val_loss: 299000.8750 - val_mae: 374.5818\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 257446.6562 - mae: 307.9485 - val_loss: 805670.8750 - val_mae: 398.1201\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 262722.7500 - mae: 292.1003 - val_loss: 308057.0312 - val_mae: 377.3737\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 255073.9844 - mae: 305.5639 - val_loss: 414356.5312 - val_mae: 373.8813\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 248765.7969 - mae: 287.7272 - val_loss: 448707.3750 - val_mae: 375.6406\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 249424.3594 - mae: 287.5503 - val_loss: 312189.9688 - val_mae: 376.1765\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 252681.7969 - mae: 302.2888 - val_loss: 567662.1875 - val_mae: 383.9870\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 250298.1406 - mae: 288.1597 - val_loss: 412349.5312 - val_mae: 376.2203\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 247142.2344 - mae: 289.0699 - val_loss: 307937.3750 - val_mae: 369.2510\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 249931.4219 - mae: 298.1078 - val_loss: 508038.4688 - val_mae: 374.7527\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 251224.0469 - mae: 286.5221 - val_loss: 352084.9062 - val_mae: 369.3082\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 246882.7812 - mae: 290.9841 - val_loss: 338758.5625 - val_mae: 372.7002\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 248275.5781 - mae: 295.2651 - val_loss: 571847.5625 - val_mae: 380.1954\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 250411.1562 - mae: 287.3223 - val_loss: 345171.4688 - val_mae: 370.0327\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 246940.1719 - mae: 292.7685 - val_loss: 340929.9062 - val_mae: 369.7563\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 246476.7500 - mae: 293.0473 - val_loss: 527794.7500 - val_mae: 377.9573\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 248199.0000 - mae: 286.7392 - val_loss: 362797.6562 - val_mae: 373.4735\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 246094.7188 - mae: 292.5018 - val_loss: 373315.4375 - val_mae: 373.5022\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 245613.7656 - mae: 291.0574 - val_loss: 479743.1562 - val_mae: 376.6051\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 246818.6562 - mae: 286.6695 - val_loss: 346329.7500 - val_mae: 372.9199\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 245640.9062 - mae: 293.3621 - val_loss: 407562.1250 - val_mae: 376.3100\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 244742.0938 - mae: 288.9377 - val_loss: 469687.1562 - val_mae: 378.7303\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 245268.6406 - mae: 287.5129 - val_loss: 356073.2188 - val_mae: 374.2415\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 245635.3438 - mae: 293.0215 - val_loss: 417370.0312 - val_mae: 371.3846\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 244732.5156 - mae: 286.1701 - val_loss: 376298.8125 - val_mae: 369.6066\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 243828.0000 - mae: 287.8081 - val_loss: 365687.0000 - val_mae: 372.2542\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 244035.2656 - mae: 290.7749 - val_loss: 469836.7188 - val_mae: 378.0009\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 244236.3750 - mae: 286.9768 - val_loss: 387640.3438 - val_mae: 375.5384\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 243689.2812 - mae: 289.7164 - val_loss: 379883.1250 - val_mae: 374.3328\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 243272.4688 - mae: 289.4801 - val_loss: 448636.2500 - val_mae: 376.2736\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 243379.7500 - mae: 286.4159 - val_loss: 375298.2812 - val_mae: 374.7822\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 243267.1875 - mae: 290.8852 - val_loss: 442035.2500 - val_mae: 375.7911\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 242748.1250 - mae: 286.4805 - val_loss: 413671.8750 - val_mae: 372.8729\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 242491.9531 - mae: 286.2866 - val_loss: 358003.3438 - val_mae: 370.6841\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 242691.5312 - mae: 290.2843 - val_loss: 450480.4375 - val_mae: 375.8127\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 242563.6875 - mae: 285.7274 - val_loss: 385318.1875 - val_mae: 376.6745\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 241710.0781 - mae: 289.9507 - val_loss: 413887.2812 - val_mae: 379.7625\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 241543.3594 - mae: 289.0580 - val_loss: 480770.9062 - val_mae: 381.7696\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 241604.4688 - mae: 287.0645 - val_loss: 377197.4062 - val_mae: 376.0180\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 241531.7969 - mae: 291.0142 - val_loss: 434692.2188 - val_mae: 374.1335\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 241014.3594 - mae: 285.4781 - val_loss: 386960.5312 - val_mae: 371.4576\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 240481.8594 - mae: 287.1260 - val_loss: 383698.7812 - val_mae: 373.6591\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 240532.3281 - mae: 288.7766 - val_loss: 486285.0000 - val_mae: 380.2415\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 240685.3281 - mae: 285.9114 - val_loss: 379852.7188 - val_mae: 377.2230\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 240600.9688 - mae: 290.8948 - val_loss: 444133.1875 - val_mae: 377.5512\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 240095.0000 - mae: 285.8930 - val_loss: 395476.3125 - val_mae: 375.8810\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 239577.9375 - mae: 287.7521 - val_loss: 405028.9688 - val_mae: 377.9330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 239356.7500 - mae: 288.2573 - val_loss: 488651.9062 - val_mae: 379.7672\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 239760.9062 - mae: 285.3412 - val_loss: 369122.6875 - val_mae: 374.2295\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 239836.5312 - mae: 290.2736 - val_loss: 434940.7812 - val_mae: 373.7058\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 239448.4844 - mae: 284.2664 - val_loss: 382694.0312 - val_mae: 373.6977\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 238758.8125 - mae: 287.6690 - val_loss: 409398.5000 - val_mae: 377.4966\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 238308.6406 - mae: 286.9902 - val_loss: 465773.2188 - val_mae: 380.8568\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 238328.9531 - mae: 285.9402 - val_loss: 382373.7188 - val_mae: 377.3695\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 238268.0000 - mae: 289.3259 - val_loss: 438630.3750 - val_mae: 377.8502\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 238259.9844 - mae: 285.5453 - val_loss: 362001.2812 - val_mae: 372.2114\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 237723.4219 - mae: 288.7628 - val_loss: 505592.0312 - val_mae: 383.4547\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 237545.5625 - mae: 285.8112 - val_loss: 406751.5312 - val_mae: 375.0264\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 237294.5156 - mae: 286.5766 - val_loss: 374055.0000 - val_mae: 366.9450\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 237053.8125 - mae: 284.7281 - val_loss: 376629.9375 - val_mae: 371.0522\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 236690.3281 - mae: 286.4061 - val_loss: 465601.3125 - val_mae: 382.6734\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 236528.1562 - mae: 286.3877 - val_loss: 451977.3125 - val_mae: 382.0248\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 236258.3906 - mae: 286.1424 - val_loss: 371649.8750 - val_mae: 374.5697\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 236115.8438 - mae: 287.9330 - val_loss: 429456.0938 - val_mae: 375.9240\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 236144.2188 - mae: 284.2385 - val_loss: 392512.4375 - val_mae: 377.7382\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 236045.4219 - mae: 288.2257 - val_loss: 497473.0000 - val_mae: 380.8397\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 235845.7969 - mae: 284.0598 - val_loss: 362143.0312 - val_mae: 372.1099\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 235834.8438 - mae: 288.4807 - val_loss: 445888.2188 - val_mae: 374.4180\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 235798.1406 - mae: 282.9431 - val_loss: 376737.3750 - val_mae: 375.8569\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 235180.7031 - mae: 288.3287 - val_loss: 490648.9375 - val_mae: 382.2852\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 234807.9375 - mae: 284.0050 - val_loss: 415259.0625 - val_mae: 380.7030\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 234236.2500 - mae: 286.2976 - val_loss: 423879.5625 - val_mae: 378.6588\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 234003.2188 - mae: 284.2435 - val_loss: 412700.8438 - val_mae: 378.9855\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 233677.1094 - mae: 285.2627 - val_loss: 451921.2188 - val_mae: 380.0898\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 233555.6250 - mae: 283.7043 - val_loss: 407359.0312 - val_mae: 378.1603\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 233391.2656 - mae: 285.8493 - val_loss: 456065.2812 - val_mae: 376.5707\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 233745.7969 - mae: 282.5927 - val_loss: 364193.9688 - val_mae: 375.0426\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 234301.3281 - mae: 288.6483 - val_loss: 535371.6250 - val_mae: 380.8275\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 234959.6719 - mae: 282.3143 - val_loss: 364037.6250 - val_mae: 380.1927\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 235406.9844 - mae: 291.1795 - val_loss: 554480.2500 - val_mae: 380.4876\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 236222.5156 - mae: 281.7302 - val_loss: 343529.4375 - val_mae: 375.9378\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 235129.7188 - mae: 291.1910 - val_loss: 495058.0625 - val_mae: 378.8127\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 233608.9219 - mae: 281.5702 - val_loss: 409953.6562 - val_mae: 379.7659\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 232000.7812 - mae: 284.9781 - val_loss: 416632.4375 - val_mae: 381.0335\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 231865.3438 - mae: 285.3368 - val_loss: 513200.8750 - val_mae: 380.0099\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 232655.7500 - mae: 281.5468 - val_loss: 345361.4375 - val_mae: 374.2398\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 233636.5469 - mae: 290.0306 - val_loss: 522313.1875 - val_mae: 374.9721\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 235244.0469 - mae: 281.0897 - val_loss: 339646.0000 - val_mae: 375.2104\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 234648.5312 - mae: 291.5988 - val_loss: 578454.7500 - val_mae: 380.2242\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 234773.8125 - mae: 281.2333 - val_loss: 364129.2188 - val_mae: 376.1972\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 231714.7656 - mae: 288.1650 - val_loss: 435900.8438 - val_mae: 377.8978\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 229937.4531 - mae: 282.0566 - val_loss: 482901.0938 - val_mae: 380.0371\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 230084.7969 - mae: 281.4555 - val_loss: 374828.1875 - val_mae: 379.7649\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 231542.3438 - mae: 288.7210 - val_loss: 563955.9375 - val_mae: 378.4114\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 233163.9844 - mae: 280.0908 - val_loss: 341679.6562 - val_mae: 371.4292\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 231690.1875 - mae: 288.4279 - val_loss: 464612.7500 - val_mae: 373.1858\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 230390.6719 - mae: 279.5263 - val_loss: 414298.4688 - val_mae: 377.8890\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 228795.2656 - mae: 282.5444 - val_loss: 428308.3125 - val_mae: 383.4708\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 229143.7188 - mae: 284.4872 - val_loss: 560462.7500 - val_mae: 385.4472\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 229841.2969 - mae: 280.8044 - val_loss: 365399.9688 - val_mae: 377.6505\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 230301.9375 - mae: 287.9842 - val_loss: 493708.3125 - val_mae: 372.7479\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 231252.3594 - mae: 278.6969 - val_loss: 344964.8750 - val_mae: 370.0050\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 229836.2656 - mae: 286.7766 - val_loss: 491869.0938 - val_mae: 377.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 228304.0156 - mae: 279.6144 - val_loss: 454950.2812 - val_mae: 381.5977\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 227139.2188 - mae: 281.8638 - val_loss: 420690.8438 - val_mae: 381.0648\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 227101.9062 - mae: 283.1645 - val_loss: 484888.1875 - val_mae: 377.8457\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 228438.9219 - mae: 279.5315 - val_loss: 361417.1562 - val_mae: 376.5765\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 228937.1719 - mae: 287.5256 - val_loss: 563304.3750 - val_mae: 378.7747\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 229495.0938 - mae: 278.5602 - val_loss: 371926.3438 - val_mae: 375.3050\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 228463.3125 - mae: 285.8831 - val_loss: 470347.0312 - val_mae: 371.2921\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 227508.6250 - mae: 277.5708 - val_loss: 378375.0625 - val_mae: 371.1855\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 225892.5938 - mae: 281.8310 - val_loss: 426220.5312 - val_mae: 380.7072\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 225592.3750 - mae: 281.9583 - val_loss: 567180.0000 - val_mae: 388.2497\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 226238.5625 - mae: 280.2120 - val_loss: 395280.6562 - val_mae: 381.6031\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 226790.5000 - mae: 285.7339 - val_loss: 488344.6250 - val_mae: 373.8770\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 227078.8750 - mae: 277.6226 - val_loss: 359764.7188 - val_mae: 371.2050\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 226234.4688 - mae: 284.3309 - val_loss: 500710.3750 - val_mae: 376.8293\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 225475.1562 - mae: 277.7301 - val_loss: 437809.0938 - val_mae: 378.7657\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 224398.8281 - mae: 280.0112 - val_loss: 422235.5625 - val_mae: 378.2754\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 224050.9375 - mae: 280.5176 - val_loss: 482081.0625 - val_mae: 379.7129\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 224701.1719 - mae: 278.6488 - val_loss: 395787.7812 - val_mae: 379.6952\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 225003.8750 - mae: 284.0477 - val_loss: 567798.3125 - val_mae: 381.0883\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 225753.4219 - mae: 277.7248 - val_loss: 368416.6250 - val_mae: 376.5223\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 226039.4219 - mae: 285.6246 - val_loss: 540138.6875 - val_mae: 373.7021\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 226794.4688 - mae: 275.9800 - val_loss: 354337.8750 - val_mae: 368.8804\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 224394.2812 - mae: 283.2313 - val_loss: 468361.7188 - val_mae: 378.5905\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 222718.8438 - mae: 277.7376 - val_loss: 516778.1875 - val_mae: 387.3319\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 222738.5781 - mae: 279.3652 - val_loss: 430504.6250 - val_mae: 385.1884\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 223225.4375 - mae: 282.8263 - val_loss: 525333.3750 - val_mae: 376.4683\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 224458.2344 - mae: 276.4289 - val_loss: 342227.2812 - val_mae: 370.2476\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 224909.5469 - mae: 285.5438 - val_loss: 572409.5000 - val_mae: 374.5224\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 225989.6562 - mae: 276.0241 - val_loss: 389748.2188 - val_mae: 376.8355\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 223702.0312 - mae: 283.0839 - val_loss: 531069.6875 - val_mae: 378.0261\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 222174.2812 - mae: 276.1551 - val_loss: 412937.9688 - val_mae: 376.6852\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 220674.8750 - mae: 279.1845 - val_loss: 409637.9375 - val_mae: 381.0570\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 221211.9375 - mae: 281.1662 - val_loss: 597918.5000 - val_mae: 386.2594\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 222393.6094 - mae: 276.8202 - val_loss: 402371.3438 - val_mae: 384.3628\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 223492.5469 - mae: 284.1630 - val_loss: 546051.7500 - val_mae: 373.8621\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 224673.5000 - mae: 274.9309 - val_loss: 340726.7188 - val_mae: 365.8849\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 222342.4375 - mae: 282.5349 - val_loss: 474329.7500 - val_mae: 374.4904\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 219978.7344 - mae: 275.1940 - val_loss: 521829.8125 - val_mae: 386.2488\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 219208.8594 - mae: 277.9622 - val_loss: 465047.6562 - val_mae: 386.6278\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 219696.2500 - mae: 280.1182 - val_loss: 519451.6562 - val_mae: 377.6637\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 220822.0156 - mae: 275.3929 - val_loss: 348213.5312 - val_mae: 371.3498\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 221284.3750 - mae: 283.6771 - val_loss: 567984.3750 - val_mae: 376.8363\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 222150.2812 - mae: 274.8704 - val_loss: 410903.8125 - val_mae: 380.3123\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 220198.2812 - mae: 281.2415 - val_loss: 526136.9375 - val_mae: 379.4497\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 218376.6562 - mae: 275.1839 - val_loss: 442308.3125 - val_mae: 377.0538\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 217830.8438 - mae: 276.3914 - val_loss: 417736.8438 - val_mae: 376.6430\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 217863.2656 - mae: 277.6760 - val_loss: 515419.0312 - val_mae: 379.9108\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 218126.5000 - mae: 274.8177 - val_loss: 426977.5000 - val_mae: 381.9551\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 218335.3125 - mae: 279.6219 - val_loss: 542749.5625 - val_mae: 378.1960\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 218739.5156 - mae: 274.1038 - val_loss: 385749.9688 - val_mae: 374.9678\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 218216.5469 - mae: 280.2201 - val_loss: 513145.2188 - val_mae: 375.4395\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 217881.1250 - mae: 273.8255 - val_loss: 435898.4688 - val_mae: 380.1652\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 216784.8594 - mae: 278.0201 - val_loss: 514696.1875 - val_mae: 380.9648\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 216091.0781 - mae: 274.8969 - val_loss: 452844.2500 - val_mae: 376.0195\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 216091.6875 - mae: 274.8596 - val_loss: 408833.8125 - val_mae: 376.4120\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 216402.2812 - mae: 277.5705 - val_loss: 537252.5000 - val_mae: 379.7898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 216957.8281 - mae: 273.8097 - val_loss: 419323.2812 - val_mae: 385.4830\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 218073.2344 - mae: 281.0028 - val_loss: 613287.2500 - val_mae: 381.6866\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 220663.9844 - mae: 273.9184 - val_loss: 354668.2500 - val_mae: 377.4422\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 220472.9688 - mae: 284.6393 - val_loss: 665839.8750 - val_mae: 383.2798\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 221626.6719 - mae: 273.7843 - val_loss: 410332.3125 - val_mae: 381.0338\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 217002.0312 - mae: 280.0611 - val_loss: 480091.4375 - val_mae: 375.6688\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 214391.8906 - mae: 273.7047 - val_loss: 505601.6250 - val_mae: 373.2291\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 215218.6719 - mae: 272.6830 - val_loss: 379174.3438 - val_mae: 377.1357\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 216723.8750 - mae: 280.8058 - val_loss: 625221.0000 - val_mae: 380.6583\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 218405.2188 - mae: 273.1568 - val_loss: 395790.9375 - val_mae: 381.1075\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 216433.3906 - mae: 280.8519 - val_loss: 543095.9375 - val_mae: 374.5724\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 215651.3750 - mae: 271.8473 - val_loss: 407512.9688 - val_mae: 372.9984\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 213988.1719 - mae: 276.1978 - val_loss: 464263.4688 - val_mae: 375.1169\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 212971.2969 - mae: 273.1995 - val_loss: 536868.0625 - val_mae: 377.5599\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 213256.3281 - mae: 272.4616 - val_loss: 404871.6562 - val_mae: 380.6568\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 214778.5469 - mae: 279.2482 - val_loss: 576569.1250 - val_mae: 379.4239\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 215746.7188 - mae: 272.2627 - val_loss: 394664.7188 - val_mae: 378.7839\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 214684.6250 - mae: 279.3546 - val_loss: 569952.4375 - val_mae: 374.4188\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 214697.3281 - mae: 271.1930 - val_loss: 399722.6250 - val_mae: 372.8071\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 212944.7812 - mae: 276.4073 - val_loss: 476307.1250 - val_mae: 370.0900\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 211945.0156 - mae: 271.1657 - val_loss: 456562.3438 - val_mae: 376.6252\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 211057.3750 - mae: 273.4792 - val_loss: 498776.0312 - val_mae: 380.7265\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 211226.7188 - mae: 273.6269 - val_loss: 521609.9375 - val_mae: 379.3636\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 210850.9375 - mae: 272.6625 - val_loss: 427502.6875 - val_mae: 376.3519\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 211051.9844 - mae: 275.1504 - val_loss: 504148.0312 - val_mae: 371.3159\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 211828.5312 - mae: 270.3825 - val_loss: 394493.1875 - val_mae: 376.6060\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 212647.9062 - mae: 278.2188 - val_loss: 620654.3125 - val_mae: 377.9966\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 213043.5781 - mae: 270.4888 - val_loss: 410643.3438 - val_mae: 378.4111\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 212478.3281 - mae: 277.4760 - val_loss: 537126.5000 - val_mae: 371.7126\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 212312.3594 - mae: 269.6611 - val_loss: 393079.9062 - val_mae: 375.6681\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 211685.1719 - mae: 277.2577 - val_loss: 569732.1250 - val_mae: 378.2856\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 211018.6094 - mae: 270.6043 - val_loss: 457501.6250 - val_mae: 381.7786\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 210043.6875 - mae: 274.6407 - val_loss: 500138.5000 - val_mae: 373.6277\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 209462.1250 - mae: 270.2213 - val_loss: 420728.0938 - val_mae: 369.3646\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 208658.6562 - mae: 272.1107 - val_loss: 448886.2812 - val_mae: 371.8198\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 208337.1094 - mae: 271.2821 - val_loss: 520126.5625 - val_mae: 378.4953\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 208580.4688 - mae: 271.3998 - val_loss: 506699.2188 - val_mae: 380.4106\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 207986.1875 - mae: 272.1218 - val_loss: 508794.0625 - val_mae: 371.3624\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 207964.1094 - mae: 269.2110 - val_loss: 392758.7812 - val_mae: 368.4463\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 208801.5469 - mae: 273.9436 - val_loss: 508647.3750 - val_mae: 369.9739\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 208797.7500 - mae: 268.4122 - val_loss: 435064.2188 - val_mae: 382.4371\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 209012.2656 - mae: 275.3956 - val_loss: 626429.5000 - val_mae: 382.7000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 209926.8906 - mae: 270.1118 - val_loss: 411314.6250 - val_mae: 381.7767\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 210167.8906 - mae: 277.2573 - val_loss: 601468.5625 - val_mae: 371.8944\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 213504.0000 - mae: 268.3123 - val_loss: 356179.2500 - val_mae: 376.1768\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 215128.7031 - mae: 281.8180 - val_loss: 691373.1250 - val_mae: 376.7694\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 217498.2031 - mae: 268.8975 - val_loss: 382300.1250 - val_mae: 381.0325\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 211546.4375 - mae: 279.6536 - val_loss: 567700.3125 - val_mae: 380.0727\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 207705.5469 - mae: 269.3722 - val_loss: 515797.5938 - val_mae: 379.9040\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 206594.4531 - mae: 270.6859 - val_loss: 436389.2812 - val_mae: 378.7579\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 207369.9844 - mae: 273.9557 - val_loss: 621049.4375 - val_mae: 371.8702\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 209752.9688 - mae: 267.4568 - val_loss: 367086.3125 - val_mae: 369.4663\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 210759.4219 - mae: 276.7231 - val_loss: 560609.5000 - val_mae: 368.1751\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 208898.1875 - mae: 266.6711 - val_loss: 443368.5625 - val_mae: 378.3982\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 205539.4844 - mae: 271.8472 - val_loss: 505143.5938 - val_mae: 381.7018\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 204671.4062 - mae: 269.7433 - val_loss: 537279.4375 - val_mae: 381.1071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 205042.1719 - mae: 269.1303 - val_loss: 440728.2500 - val_mae: 379.8763\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 205520.1094 - mae: 272.9760 - val_loss: 586442.4375 - val_mae: 368.2424\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 206678.1719 - mae: 266.2659 - val_loss: 380800.7500 - val_mae: 365.7396\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 207153.1719 - mae: 273.3578 - val_loss: 530306.3125 - val_mae: 362.0456\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 206007.1094 - mae: 265.4880 - val_loss: 437993.0625 - val_mae: 373.7267\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 204113.6094 - mae: 270.5701 - val_loss: 524830.1875 - val_mae: 378.7022\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 203119.5156 - mae: 268.2567 - val_loss: 529874.1875 - val_mae: 380.8118\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 203447.4062 - mae: 268.3440 - val_loss: 437005.9688 - val_mae: 380.3881\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 203787.5625 - mae: 271.9688 - val_loss: 554160.3125 - val_mae: 370.9010\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 204669.4219 - mae: 265.4465 - val_loss: 409610.4688 - val_mae: 371.9305\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 204413.9844 - mae: 271.7226 - val_loss: 554035.0000 - val_mae: 365.1399\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 204375.3125 - mae: 264.9406 - val_loss: 417808.0000 - val_mae: 370.6274\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 203227.8750 - mae: 270.8343 - val_loss: 543581.4375 - val_mae: 369.2143\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 202592.9062 - mae: 265.4683 - val_loss: 450833.5312 - val_mae: 376.8865\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 201734.5469 - mae: 269.9028 - val_loss: 525677.4375 - val_mae: 374.4209\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 201422.4375 - mae: 266.4912 - val_loss: 472230.7812 - val_mae: 374.2395\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 200616.0938 - mae: 267.6040 - val_loss: 499472.6562 - val_mae: 367.5170\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 200663.1406 - mae: 265.3695 - val_loss: 448302.1875 - val_mae: 367.5876\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 200514.5469 - mae: 266.9794 - val_loss: 503291.2188 - val_mae: 367.1991\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 200234.7344 - mae: 264.9159 - val_loss: 459358.1562 - val_mae: 375.1562\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 200298.6562 - mae: 267.9532 - val_loss: 538401.4375 - val_mae: 372.8156\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 200402.6250 - mae: 265.5076 - val_loss: 452165.1562 - val_mae: 374.1884\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 200044.4375 - mae: 268.3662 - val_loss: 528328.8125 - val_mae: 364.2579\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 200523.9375 - mae: 263.8066 - val_loss: 409747.9688 - val_mae: 367.4624\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 200880.3125 - mae: 269.9213 - val_loss: 583081.5625 - val_mae: 362.2936\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 202477.9688 - mae: 262.8320 - val_loss: 393269.0938 - val_mae: 369.7617\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 201722.9219 - mae: 271.5179 - val_loss: 605941.5000 - val_mae: 370.7853\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 202903.4219 - mae: 263.4149 - val_loss: 412011.7812 - val_mae: 382.3062\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 202855.2656 - mae: 273.8321 - val_loss: 659485.7500 - val_mae: 377.3520\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 203621.2969 - mae: 263.8588 - val_loss: 406920.3438 - val_mae: 377.8625\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 201561.2344 - mae: 272.1036 - val_loss: 554050.3750 - val_mae: 364.5159\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 199311.7812 - mae: 262.3683 - val_loss: 448526.8438 - val_mae: 366.6544\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 197059.8438 - mae: 265.3913 - val_loss: 466084.4062 - val_mae: 369.5928\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 196611.6406 - mae: 265.0796 - val_loss: 567759.3125 - val_mae: 369.4678\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 198091.6406 - mae: 263.0835 - val_loss: 414625.3125 - val_mae: 379.1682\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 200398.7656 - mae: 271.5924 - val_loss: 638328.0000 - val_mae: 371.6208\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 205053.9375 - mae: 263.8757 - val_loss: 380683.4375 - val_mae: 382.5629\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 206118.8906 - mae: 277.1254 - val_loss: 739903.7500 - val_mae: 375.2311\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 212605.3750 - mae: 264.8859 - val_loss: 377408.1250 - val_mae: 377.9255\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 203762.8125 - mae: 275.0334 - val_loss: 556220.6875 - val_mae: 364.4072\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 197088.8125 - mae: 261.3325 - val_loss: 532766.1250 - val_mae: 371.4714\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 195636.2031 - mae: 263.0128 - val_loss: 442481.0938 - val_mae: 384.3264\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 198922.3906 - mae: 270.1189 - val_loss: 701450.0000 - val_mae: 379.9187\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 205764.6875 - mae: 264.1224 - val_loss: 384843.0312 - val_mae: 380.2617\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 203349.2188 - mae: 275.0837 - val_loss: 588659.1875 - val_mae: 367.1893\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 201553.1719 - mae: 261.4676 - val_loss: 440167.0312 - val_mae: 373.6870\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 195200.2188 - mae: 266.5117 - val_loss: 510425.0000 - val_mae: 377.3825\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 194038.4062 - mae: 264.3453 - val_loss: 657271.7500 - val_mae: 373.4610\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 197362.1719 - mae: 261.2886 - val_loss: 399776.2500 - val_mae: 375.4994\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 197788.7969 - mae: 270.1524 - val_loss: 531597.6250 - val_mae: 362.7085\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 196366.3438 - mae: 259.7224 - val_loss: 450050.2500 - val_mae: 370.5372\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 193558.5625 - mae: 264.4300 - val_loss: 529155.6250 - val_mae: 375.1968\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 192852.1094 - mae: 262.5767 - val_loss: 603504.3125 - val_mae: 372.9714\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 193775.1094 - mae: 260.9209 - val_loss: 427493.0938 - val_mae: 377.5777\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 194578.1250 - mae: 267.0613 - val_loss: 531228.8125 - val_mae: 366.5735\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 195344.3906 - mae: 260.1340 - val_loss: 435144.4688 - val_mae: 374.9230\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 193509.8281 - mae: 265.7091 - val_loss: 567919.2500 - val_mae: 370.5132\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 191612.9219 - mae: 261.1594 - val_loss: 562845.4375 - val_mae: 367.7466\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 191695.1875 - mae: 260.8629 - val_loss: 428011.5938 - val_mae: 372.4859\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 193445.2812 - mae: 265.7512 - val_loss: 556317.5000 - val_mae: 363.9312\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 197313.6094 - mae: 259.5624 - val_loss: 402656.9688 - val_mae: 381.0551\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 197130.1719 - mae: 270.7637 - val_loss: 665542.3125 - val_mae: 379.5694\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 196120.7344 - mae: 260.9754 - val_loss: 500724.4375 - val_mae: 384.0961\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 191950.1719 - mae: 264.1086 - val_loss: 503159.0625 - val_mae: 367.1980\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 190730.9688 - mae: 260.0546 - val_loss: 480865.5938 - val_mae: 357.8944\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 191495.2188 - mae: 258.5179 - val_loss: 418110.2812 - val_mae: 372.0817\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 191877.8750 - mae: 265.1925 - val_loss: 611903.3125 - val_mae: 374.8626\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 192026.7031 - mae: 259.4613 - val_loss: 515007.9688 - val_mae: 385.1507\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 190816.7344 - mae: 263.3585 - val_loss: 536983.0625 - val_mae: 371.3752\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 189136.2500 - mae: 259.8254 - val_loss: 479404.3438 - val_mae: 359.8997\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 188639.3125 - mae: 258.9573 - val_loss: 425955.4375 - val_mae: 365.4662\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 191108.7812 - mae: 263.6153 - val_loss: 593712.5000 - val_mae: 361.4048\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 194027.5312 - mae: 258.1360 - val_loss: 437394.4688 - val_mae: 383.7099\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 194518.8281 - mae: 267.6722 - val_loss: 636595.8750 - val_mae: 375.5456\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 196621.4375 - mae: 259.6851 - val_loss: 429492.9688 - val_mae: 386.3894\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 194208.7031 - mae: 268.5412 - val_loss: 598875.5625 - val_mae: 370.1354\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 191853.9375 - mae: 257.6013 - val_loss: 472292.6250 - val_mae: 372.7662\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 188149.4531 - mae: 260.9969 - val_loss: 494444.7500 - val_mae: 366.1614\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 187272.1250 - mae: 258.7003 - val_loss: 541713.5625 - val_mae: 361.3272\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 188689.9062 - mae: 256.9054 - val_loss: 440244.1250 - val_mae: 375.9331\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 189162.8750 - mae: 263.1586 - val_loss: 573031.5000 - val_mae: 372.9716\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 188883.6250 - mae: 257.5037 - val_loss: 492760.1250 - val_mae: 382.1848\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 187369.5000 - mae: 261.0149 - val_loss: 528208.0000 - val_mae: 372.9640\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 186311.6406 - mae: 257.9435 - val_loss: 531842.4375 - val_mae: 361.4900\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 187585.7656 - mae: 256.4363 - val_loss: 432968.8750 - val_mae: 372.2580\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 188886.5469 - mae: 262.6160 - val_loss: 584932.6250 - val_mae: 363.8876\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 190919.5625 - mae: 256.3557 - val_loss: 456332.1875 - val_mae: 387.2851\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 190957.5469 - mae: 264.9464 - val_loss: 669438.5625 - val_mae: 379.0919\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 191796.0000 - mae: 257.8028 - val_loss: 461217.2812 - val_mae: 386.0732\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 188534.7812 - mae: 263.1997 - val_loss: 544566.4375 - val_mae: 363.3470\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 187791.1875 - mae: 254.9276 - val_loss: 446604.2500 - val_mae: 374.2084\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 186342.2500 - mae: 260.7228 - val_loss: 541504.7500 - val_mae: 364.8970\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 184543.1719 - mae: 255.6559 - val_loss: 528571.1250 - val_mae: 371.1549\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 183450.9062 - mae: 256.8863 - val_loss: 508343.3750 - val_mae: 371.2162\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 183450.0156 - mae: 257.1005 - val_loss: 526397.4375 - val_mae: 365.1903\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 184057.5312 - mae: 255.6162 - val_loss: 459781.4062 - val_mae: 375.0999\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 183949.9844 - mae: 259.5999 - val_loss: 566329.2500 - val_mae: 369.4296\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 183666.6250 - mae: 255.4825 - val_loss: 508473.6250 - val_mae: 378.3331\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 182796.6562 - mae: 257.7183 - val_loss: 536057.6875 - val_mae: 366.1542\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 182278.0938 - mae: 255.1376 - val_loss: 486660.8438 - val_mae: 365.0057\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 181999.0781 - mae: 255.7899 - val_loss: 491573.9688 - val_mae: 363.6433\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 181898.3125 - mae: 254.9932 - val_loss: 500911.2500 - val_mae: 375.5196\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 182264.1875 - mae: 256.9366 - val_loss: 604460.8750 - val_mae: 371.3142\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 184136.7500 - mae: 254.9105 - val_loss: 460477.5312 - val_mae: 391.4874\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 189142.7812 - mae: 264.7757 - val_loss: 685272.4375 - val_mae: 374.3162\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 201990.0625 - mae: 260.3625 - val_loss: 423567.6562 - val_mae: 385.5768\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 194825.2812 - mae: 270.6940 - val_loss: 595282.8750 - val_mae: 361.9673\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 188657.1250 - mae: 254.2654 - val_loss: 520653.8750 - val_mae: 376.2417\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 181540.2969 - mae: 256.2623 - val_loss: 521123.5312 - val_mae: 388.1762\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 183228.0938 - mae: 258.7149 - val_loss: 691739.6250 - val_mae: 378.0936\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 190267.5781 - mae: 255.6540 - val_loss: 431391.7812 - val_mae: 386.2618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 188974.2969 - mae: 266.6661 - val_loss: 549048.4375 - val_mae: 361.7822\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 185917.8125 - mae: 253.4981 - val_loss: 486976.2500 - val_mae: 375.7721\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 179978.9531 - mae: 256.8495 - val_loss: 547421.2500 - val_mae: 380.4978\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 179597.7500 - mae: 256.3356 - val_loss: 660999.5000 - val_mae: 372.2277\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 183871.9375 - mae: 254.3702 - val_loss: 441668.4062 - val_mae: 384.7266\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 188106.6562 - mae: 265.1933 - val_loss: 585753.8750 - val_mae: 361.7071\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 193036.7344 - mae: 256.0099 - val_loss: 433445.8750 - val_mae: 374.1568\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 182553.2500 - mae: 260.4004 - val_loss: 548094.0000 - val_mae: 371.4545\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 177872.1250 - mae: 253.6463 - val_loss: 690655.5000 - val_mae: 380.9898\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 180362.0625 - mae: 254.0276 - val_loss: 507169.8438 - val_mae: 393.3237\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 182934.0625 - mae: 260.2960 - val_loss: 582596.9375 - val_mae: 364.1015\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 185249.5156 - mae: 253.3442 - val_loss: 435000.6250 - val_mae: 368.4053\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 179984.2344 - mae: 258.8360 - val_loss: 506772.7188 - val_mae: 362.9109\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 176740.1250 - mae: 253.4580 - val_loss: 656884.6250 - val_mae: 374.2015\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 177723.6094 - mae: 254.2083 - val_loss: 536211.8125 - val_mae: 391.4516\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 181026.7188 - mae: 258.8687 - val_loss: 584673.7500 - val_mae: 362.3750\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 182744.7500 - mae: 252.6092 - val_loss: 428387.7500 - val_mae: 368.9660\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 179257.7188 - mae: 258.9579 - val_loss: 493046.8438 - val_mae: 363.1454\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 176031.2969 - mae: 252.5451 - val_loss: 619963.0625 - val_mae: 379.0187\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 176102.7031 - mae: 253.4009 - val_loss: 579942.5000 - val_mae: 394.5402\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 178190.0000 - mae: 256.9186 - val_loss: 636787.0625 - val_mae: 373.0168\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 181915.7500 - mae: 252.7498 - val_loss: 435229.0938 - val_mae: 377.7594\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 181057.4531 - mae: 261.2309 - val_loss: 511794.9375 - val_mae: 352.5136\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 180597.0938 - mae: 250.8206 - val_loss: 496603.7812 - val_mae: 371.7254\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 175044.1094 - mae: 254.0963 - val_loss: 565761.0000 - val_mae: 381.7584\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 174406.8906 - mae: 254.5194 - val_loss: 686287.8125 - val_mae: 377.9705\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 180149.2500 - mae: 253.5515 - val_loss: 465778.7812 - val_mae: 387.7070\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 183039.3750 - mae: 262.6045 - val_loss: 574374.4375 - val_mae: 362.0031\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 189061.7188 - mae: 254.8509 - val_loss: 443383.2812 - val_mae: 374.9476\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 177151.7188 - mae: 258.5471 - val_loss: 540875.6875 - val_mae: 374.4949\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 173126.9219 - mae: 252.5793 - val_loss: 751230.4375 - val_mae: 382.2501\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 178571.8906 - mae: 252.5737 - val_loss: 509178.2812 - val_mae: 395.9841\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 179808.3906 - mae: 260.2699 - val_loss: 550330.8125 - val_mae: 359.3680\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 177881.9688 - mae: 250.6408 - val_loss: 450531.3438 - val_mae: 361.1258\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 172051.6719 - mae: 254.1439 - val_loss: 486160.8438 - val_mae: 372.1444\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 172493.0312 - mae: 254.4904 - val_loss: 696609.2500 - val_mae: 378.7672\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 178406.7344 - mae: 252.7330 - val_loss: 525321.0000 - val_mae: 400.8831\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 180358.5312 - mae: 260.5261 - val_loss: 628637.8750 - val_mae: 373.0844\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 180429.0000 - mae: 253.1998 - val_loss: 463268.6250 - val_mae: 373.3054\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 173158.9688 - mae: 255.5805 - val_loss: 494889.2812 - val_mae: 368.8287\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 170456.8594 - mae: 252.1618 - val_loss: 656970.5625 - val_mae: 371.8427\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 174870.6875 - mae: 251.0194 - val_loss: 537410.2500 - val_mae: 395.6516\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 175509.1094 - mae: 256.8404 - val_loss: 617480.9375 - val_mae: 372.2249\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 174630.9219 - mae: 250.7069 - val_loss: 485213.8125 - val_mae: 370.7130\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 170363.6875 - mae: 252.8047 - val_loss: 494457.7188 - val_mae: 371.7246\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 169089.0312 - mae: 252.4415 - val_loss: 628252.0625 - val_mae: 366.8689\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 173471.0312 - mae: 250.5510 - val_loss: 521012.7812 - val_mae: 389.1441\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 174583.9219 - mae: 256.3911 - val_loss: 606192.3750 - val_mae: 365.3251\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 174927.5625 - mae: 249.9912 - val_loss: 479507.8750 - val_mae: 375.1042\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 170360.2188 - mae: 254.4953 - val_loss: 518999.7812 - val_mae: 365.6638\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 168425.0781 - mae: 250.0563 - val_loss: 573351.7500 - val_mae: 369.9802\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 167751.0469 - mae: 250.0195 - val_loss: 563992.6875 - val_mae: 383.6254\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 168865.9375 - mae: 252.2846 - val_loss: 600625.5000 - val_mae: 364.3354\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 170208.3906 - mae: 249.5188 - val_loss: 484001.5000 - val_mae: 374.9919\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 169201.3438 - mae: 253.8418 - val_loss: 530738.0625 - val_mae: 362.8153\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 168344.0000 - mae: 248.6049 - val_loss: 526953.6875 - val_mae: 376.4880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 167167.2969 - mae: 251.3615 - val_loss: 606887.9375 - val_mae: 373.1707\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 165802.5312 - mae: 249.5837 - val_loss: 566495.1875 - val_mae: 374.7718\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 166238.4375 - mae: 250.4861 - val_loss: 528447.8750 - val_mae: 365.5136\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 165241.1562 - mae: 249.2070 - val_loss: 512096.0312 - val_mae: 362.8146\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 165023.4531 - mae: 249.7061 - val_loss: 529253.2500 - val_mae: 370.3602\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 165086.2500 - mae: 250.0796 - val_loss: 581107.3750 - val_mae: 374.4773\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 164427.8594 - mae: 249.1493 - val_loss: 585677.0625 - val_mae: 376.4951\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 164716.0156 - mae: 249.2714 - val_loss: 544451.9375 - val_mae: 371.9128\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 164483.5625 - mae: 249.0832 - val_loss: 526042.0000 - val_mae: 359.8642\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 164647.4688 - mae: 247.8363 - val_loss: 495460.4375 - val_mae: 375.3443\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 166248.3281 - mae: 252.9813 - val_loss: 625602.7500 - val_mae: 365.8766\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 173663.6719 - mae: 249.8568 - val_loss: 507934.5625 - val_mae: 392.5817\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 174542.4688 - mae: 259.0215 - val_loss: 659035.0625 - val_mae: 371.2161\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 177142.0938 - mae: 251.4953 - val_loss: 492425.4375 - val_mae: 380.4276\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 166622.8438 - mae: 253.6450 - val_loss: 527399.9375 - val_mae: 364.0325\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 163154.0781 - mae: 247.4294 - val_loss: 579484.6875 - val_mae: 370.5237\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 163035.7500 - mae: 247.8911 - val_loss: 556520.1875 - val_mae: 386.4625\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 164730.9219 - mae: 251.3225 - val_loss: 636438.7500 - val_mae: 369.2494\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 167625.4375 - mae: 248.2798 - val_loss: 501554.7812 - val_mae: 377.6200\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 165506.7031 - mae: 253.1162 - val_loss: 547866.0625 - val_mae: 362.6481\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 165129.4531 - mae: 246.8626 - val_loss: 531325.5625 - val_mae: 382.4341\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 162942.0625 - mae: 251.0445 - val_loss: 625466.0000 - val_mae: 374.3613\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 162012.4219 - mae: 247.6115 - val_loss: 589413.1250 - val_mae: 381.1756\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 161024.8906 - mae: 248.6206 - val_loss: 562583.7500 - val_mae: 365.7684\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 160206.5781 - mae: 246.6691 - val_loss: 525127.6250 - val_mae: 366.3330\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 159832.6250 - mae: 247.7397 - val_loss: 545755.7500 - val_mae: 364.0421\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 159623.0312 - mae: 246.4455 - val_loss: 569579.3750 - val_mae: 374.6489\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 159612.8906 - mae: 247.2336 - val_loss: 613107.3125 - val_mae: 373.6973\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 159625.0312 - mae: 246.4361 - val_loss: 551569.8750 - val_mae: 386.1655\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 162224.3750 - mae: 251.0249 - val_loss: 600730.1250 - val_mae: 361.6185\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 167107.3438 - mae: 246.8081 - val_loss: 501954.3750 - val_mae: 381.0863\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 167043.4219 - mae: 255.9651 - val_loss: 602841.6875 - val_mae: 361.6094\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 170624.5625 - mae: 247.7923 - val_loss: 523414.2812 - val_mae: 381.8172\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 162466.7344 - mae: 251.7220 - val_loss: 597903.8750 - val_mae: 373.7822\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 158748.3906 - mae: 246.1669 - val_loss: 618149.1250 - val_mae: 376.0920\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 158571.6406 - mae: 246.3556 - val_loss: 549532.0625 - val_mae: 385.4099\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 160412.8594 - mae: 250.4653 - val_loss: 604249.4375 - val_mae: 366.4506\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 166088.7031 - mae: 247.3316 - val_loss: 511314.5000 - val_mae: 381.0310\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 164789.0000 - mae: 254.8153 - val_loss: 599377.6250 - val_mae: 359.5646\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 169718.0938 - mae: 247.4443 - val_loss: 517123.9062 - val_mae: 380.7715\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 161106.5156 - mae: 252.0742 - val_loss: 579498.5625 - val_mae: 378.6038\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 156673.8281 - mae: 246.6120 - val_loss: 686965.0625 - val_mae: 383.0909\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 160223.1250 - mae: 246.0018 - val_loss: 565975.9375 - val_mae: 393.4612\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 163401.2656 - mae: 253.0658 - val_loss: 618595.0000 - val_mae: 367.9307\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 165389.4219 - mae: 246.5687 - val_loss: 510118.4688 - val_mae: 377.6023\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 159432.1719 - mae: 251.8288 - val_loss: 545766.0000 - val_mae: 361.6559\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 157753.0000 - mae: 244.8185 - val_loss: 606695.1250 - val_mae: 375.2916\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 155648.3125 - mae: 245.1497 - val_loss: 609332.5000 - val_mae: 398.4385\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 160405.3281 - mae: 251.3960 - val_loss: 717621.3750 - val_mae: 385.8559\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 169292.9219 - mae: 250.4736 - val_loss: 541199.8125 - val_mae: 391.5596\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 164828.7031 - mae: 256.6498 - val_loss: 556960.4375 - val_mae: 352.4516\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 162206.0156 - mae: 244.2331 - val_loss: 532494.6250 - val_mae: 368.0385\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 156336.3281 - mae: 246.5165 - val_loss: 583638.1250 - val_mae: 393.5595\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 157943.5312 - mae: 250.0952 - val_loss: 791211.2500 - val_mae: 392.2043\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 168913.8281 - mae: 249.7390 - val_loss: 573661.8750 - val_mae: 399.6881\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 159912.2969 - mae: 253.4325 - val_loss: 559588.3750 - val_mae: 363.2269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 155219.1719 - mae: 243.4593 - val_loss: 548591.9375 - val_mae: 364.5847\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 153708.6406 - mae: 244.0187 - val_loss: 575129.1250 - val_mae: 393.2163\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 157405.9844 - mae: 251.0733 - val_loss: 777672.5000 - val_mae: 386.7686\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 165193.9062 - mae: 247.7628 - val_loss: 574371.2500 - val_mae: 395.2997\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 156789.3281 - mae: 251.1691 - val_loss: 556988.5000 - val_mae: 364.2517\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 152638.8125 - mae: 243.2519 - val_loss: 555575.9375 - val_mae: 364.1182\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 151913.6094 - mae: 243.4908 - val_loss: 579185.5625 - val_mae: 391.9404\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 156469.1719 - mae: 250.6879 - val_loss: 755613.5625 - val_mae: 385.4998\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 167260.2344 - mae: 250.0172 - val_loss: 581002.7500 - val_mae: 394.3597\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 156747.5469 - mae: 251.1876 - val_loss: 575356.9375 - val_mae: 366.7490\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 151682.2812 - mae: 242.5299 - val_loss: 576025.8750 - val_mae: 370.8370\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 151028.5156 - mae: 242.6570 - val_loss: 589845.0625 - val_mae: 392.8808\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 152770.5781 - mae: 248.1046 - val_loss: 697239.9375 - val_mae: 382.7418\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 154493.4844 - mae: 243.5510 - val_loss: 603663.6875 - val_mae: 388.9291\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 151163.0000 - mae: 246.5190 - val_loss: 595033.4375 - val_mae: 374.3159\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 148986.7344 - mae: 242.7989 - val_loss: 587994.8750 - val_mae: 372.8578\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 148570.9219 - mae: 242.8042 - val_loss: 594073.7500 - val_mae: 385.8929\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 149591.0938 - mae: 245.7221 - val_loss: 657716.5000 - val_mae: 375.1187\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 152513.7344 - mae: 242.8268 - val_loss: 591488.6875 - val_mae: 391.9116\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 152402.7188 - mae: 248.5888 - val_loss: 626238.3750 - val_mae: 372.2843\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 151551.7969 - mae: 241.4424 - val_loss: 578315.3125 - val_mae: 382.5069\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 148679.9219 - mae: 245.4994 - val_loss: 600201.4375 - val_mae: 373.3746\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 148029.5312 - mae: 241.3835 - val_loss: 615096.8125 - val_mae: 384.9469\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 147063.4219 - mae: 243.0075 - val_loss: 637044.5000 - val_mae: 387.1565\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 146569.3438 - mae: 242.8236 - val_loss: 632613.6875 - val_mae: 381.8929\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 146664.8438 - mae: 241.9589 - val_loss: 599228.7500 - val_mae: 388.7965\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 148798.2969 - mae: 246.2582 - val_loss: 629879.9375 - val_mae: 368.1432\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 153952.8125 - mae: 242.1217 - val_loss: 573836.5000 - val_mae: 391.3959\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 151565.2344 - mae: 250.1973 - val_loss: 621404.2500 - val_mae: 368.8298\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 152485.6719 - mae: 241.1759 - val_loss: 598910.3125 - val_mae: 391.9376\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 148076.5781 - mae: 246.1018 - val_loss: 644380.6250 - val_mae: 388.4958\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 145806.2656 - mae: 242.0782 - val_loss: 677645.1250 - val_mae: 387.0593\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 147229.8906 - mae: 241.3260 - val_loss: 616620.1875 - val_mae: 400.3400\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 149900.2500 - mae: 248.2551 - val_loss: 647093.6875 - val_mae: 368.2483\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 155522.4219 - mae: 242.0079 - val_loss: 565178.9375 - val_mae: 385.7278\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 148425.4219 - mae: 247.6364 - val_loss: 590814.6875 - val_mae: 381.1298\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 144825.7031 - mae: 243.0096 - val_loss: 711000.6875 - val_mae: 390.0801\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 150466.7969 - mae: 242.1862 - val_loss: 662443.2500 - val_mae: 415.1789\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 152039.4844 - mae: 250.4574 - val_loss: 706633.4375 - val_mae: 381.2507\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 155735.1875 - mae: 243.0502 - val_loss: 571983.3125 - val_mae: 386.4771\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 147209.0938 - mae: 247.4297 - val_loss: 584041.3125 - val_mae: 384.4483\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 144789.9062 - mae: 244.7595 - val_loss: 716569.7500 - val_mae: 389.9229\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 150586.4375 - mae: 242.0571 - val_loss: 674166.8750 - val_mae: 416.6548\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 151496.3594 - mae: 250.5444 - val_loss: 718046.0625 - val_mae: 386.6684\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 150144.7969 - mae: 241.3642 - val_loss: 593688.1875 - val_mae: 383.8306\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 143881.9844 - mae: 244.0394 - val_loss: 591192.8125 - val_mae: 378.4301\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 142629.7344 - mae: 243.0288 - val_loss: 674045.8750 - val_mae: 379.4631\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 146610.1719 - mae: 239.6180 - val_loss: 680325.7500 - val_mae: 409.7235\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 147542.5469 - mae: 247.5654 - val_loss: 748612.3750 - val_mae: 389.2147\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 147926.3125 - mae: 240.5736 - val_loss: 626306.2500 - val_mae: 393.3068\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 142590.3281 - mae: 243.9998 - val_loss: 602564.0000 - val_mae: 379.7846\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 140398.1250 - mae: 240.8504 - val_loss: 637834.1250 - val_mae: 376.3319\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 141364.2969 - mae: 237.7616 - val_loss: 651451.0000 - val_mae: 400.2873\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 143202.7812 - mae: 245.2033 - val_loss: 716223.6875 - val_mae: 384.5876\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 146227.0781 - mae: 239.5788 - val_loss: 633075.0625 - val_mae: 397.6418\n",
      "Epoch 999/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step - loss: 142639.8281 - mae: 245.2202 - val_loss: 628121.6875 - val_mae: 372.5312\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 139193.0000 - mae: 237.6135 - val_loss: 632822.7500 - val_mae: 378.5518\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(250, input_dim=features.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "history = model.fit(features, target, epochs=1000, batch_size=500, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839407184620139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original=[]\n",
    "predicted = []\n",
    "for x in target['Supplier Quote(including GST)']:\n",
    "    original.append(x)\n",
    "\n",
    "for x in predictions:\n",
    "    predicted.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for x in range(len(original)):\n",
    "    diff.append(predicted[x] - original[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Preds'] = predicted\n",
    "df['Margin Of Error'] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Trip type</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Distance in kms</th>\n",
       "      <th>Travel time minutes</th>\n",
       "      <th>Total time elapsed(hours)</th>\n",
       "      <th>Supplier Quote(including GST)</th>\n",
       "      <th>Number of MiniBus</th>\n",
       "      <th>Number of Large MiniBus</th>\n",
       "      <th>Number of Small Coach</th>\n",
       "      <th>Number of Medium Coach</th>\n",
       "      <th>Number of Large Coach</th>\n",
       "      <th>Extra Large Coach</th>\n",
       "      <th>Preds</th>\n",
       "      <th>Margin Of Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>23.183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>431.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477.276703</td>\n",
       "      <td>46.026703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.554</td>\n",
       "      <td>36</td>\n",
       "      <td>5.37</td>\n",
       "      <td>517.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>434.088654</td>\n",
       "      <td>-83.411346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>110.210</td>\n",
       "      <td>84</td>\n",
       "      <td>7.45</td>\n",
       "      <td>889.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>508.222321</td>\n",
       "      <td>-380.817679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>15.513</td>\n",
       "      <td>25</td>\n",
       "      <td>7.72</td>\n",
       "      <td>1518.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1061.236816</td>\n",
       "      <td>-456.763184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>14.301</td>\n",
       "      <td>26</td>\n",
       "      <td>3.18</td>\n",
       "      <td>490.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>716.483459</td>\n",
       "      <td>226.483459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20.852</td>\n",
       "      <td>23</td>\n",
       "      <td>7.43</td>\n",
       "      <td>530.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>548.592407</td>\n",
       "      <td>18.592407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>224.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363.570648</td>\n",
       "      <td>138.820648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>19.468</td>\n",
       "      <td>28</td>\n",
       "      <td>2.98</td>\n",
       "      <td>500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363.570648</td>\n",
       "      <td>-136.429352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>115.055</td>\n",
       "      <td>103</td>\n",
       "      <td>9.85</td>\n",
       "      <td>985.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270.754395</td>\n",
       "      <td>285.754395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>164.195</td>\n",
       "      <td>143</td>\n",
       "      <td>12.18</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1334.495483</td>\n",
       "      <td>434.495483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vehicle class  Trip type  Passengers  Distance in kms  \\\n",
       "0                0          0          35           23.183   \n",
       "1                0          1          25           32.554   \n",
       "2                0          1          15          110.210   \n",
       "3                0          1          70           15.513   \n",
       "4                0          1          53           14.301   \n",
       "..             ...        ...         ...              ...   \n",
       "448              0          1          30           20.852   \n",
       "449              0          1          25           19.468   \n",
       "450              0          1          25           19.468   \n",
       "451              0          1          45          115.055   \n",
       "452              0          1          50          164.195   \n",
       "\n",
       "     Travel time minutes  Total time elapsed(hours)  \\\n",
       "0                     21                       0.35   \n",
       "1                     36                       5.37   \n",
       "2                     84                       7.45   \n",
       "3                     25                       7.72   \n",
       "4                     26                       3.18   \n",
       "..                   ...                        ...   \n",
       "448                   23                       7.43   \n",
       "449                   28                       2.98   \n",
       "450                   28                       2.98   \n",
       "451                  103                       9.85   \n",
       "452                  143                      12.18   \n",
       "\n",
       "     Supplier Quote(including GST)  Number of MiniBus  \\\n",
       "0                           431.25                  0   \n",
       "1                           517.50                  0   \n",
       "2                           889.04                  0   \n",
       "3                          1518.00                  0   \n",
       "4                           490.00                  0   \n",
       "..                             ...                ...   \n",
       "448                         530.00                  0   \n",
       "449                         224.75                  0   \n",
       "450                         500.00                  0   \n",
       "451                         985.00                  0   \n",
       "452                         900.00                  0   \n",
       "\n",
       "     Number of Large MiniBus  Number of Small Coach  Number of Medium Coach  \\\n",
       "0                          0                      1                       0   \n",
       "1                          0                      1                       0   \n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          0                      0                       0   \n",
       "..                       ...                    ...                     ...   \n",
       "448                        0                      1                       0   \n",
       "449                        0                      1                       0   \n",
       "450                        0                      1                       0   \n",
       "451                        0                      0                       0   \n",
       "452                        0                      0                       0   \n",
       "\n",
       "     Number of Large Coach  Extra Large Coach        Preds  Margin Of Error  \n",
       "0                        0                  0   477.276703        46.026703  \n",
       "1                        0                  0   434.088654       -83.411346  \n",
       "2                        0                  0   508.222321      -380.817679  \n",
       "3                        0                  1  1061.236816      -456.763184  \n",
       "4                        0                  1   716.483459       226.483459  \n",
       "..                     ...                ...          ...              ...  \n",
       "448                      0                  0   548.592407        18.592407  \n",
       "449                      0                  0   363.570648       138.820648  \n",
       "450                      0                  0   363.570648      -136.429352  \n",
       "451                      1                  0  1270.754395       285.754395  \n",
       "452                      0                  1  1334.495483       434.495483  \n",
       "\n",
       "[453 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266.46537883430125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for x in df['Margin Of Error']:\n",
    "    sum = sum + np.abs(x)\n",
    "\n",
    "sum/len(df['Margin Of Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"NN_predictor_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NN_predictor_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('NN_predictor_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"NN_predictor_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[548.6052]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params = [[Vehicle class,Trip type,Passengers,Distance in kms,Travel time minutes,Total time elapsed(hours),Number of Large Coach]]\n",
    "loaded_model.predict([[0,1,30,20.85,23,7.43,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
